'use strict';

require('webrtc-adapter');
var runtime = require('@protobuf-ts/runtime');
var runtimeRpc = require('@protobuf-ts/runtime-rpc');
var axios = require('axios');
var twirpTransport = require('@protobuf-ts/twirp-transport');
var rxjs = require('rxjs');
var SDP = require('sdp-transform');
var uaParserJs = require('ua-parser-js');
var WebSocket = require('isomorphic-ws');
var https = require('https');
var base64Js = require('base64-js');

function _interopNamespaceDefault(e) {
    var n = Object.create(null);
    if (e) {
        Object.keys(e).forEach(function (k) {
            if (k !== 'default') {
                var d = Object.getOwnPropertyDescriptor(e, k);
                Object.defineProperty(n, k, d.get ? d : {
                    enumerable: true,
                    get: function () { return e[k]; }
                });
            }
        });
    }
    n.default = e;
    return Object.freeze(n);
}

var SDP__namespace = /*#__PURE__*/_interopNamespaceDefault(SDP);

/**
 * @export
 */
const AudioSettingsDefaultDeviceEnum = {
    SPEAKER: 'speaker',
    EARPIECE: 'earpiece',
};
/**
 * @export
 */
const AudioSettingsRequestDefaultDeviceEnum = {
    SPEAKER: 'speaker',
    EARPIECE: 'earpiece',
};
/**
 * @export
 */
const CreateDeviceRequestPushProviderEnum = {
    FIREBASE: 'firebase',
    APN: 'apn',
    HUAWEI: 'huawei',
    XIAOMI: 'xiaomi',
};
/**
 * @export
 */
const NoiseCancellationSettingsModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const NoiseCancellationSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * All possibility of string to use
 * @export
 */
const OwnCapability = {
    BLOCK_USERS: 'block-users',
    CREATE_CALL: 'create-call',
    CREATE_REACTION: 'create-reaction',
    ENABLE_NOISE_CANCELLATION: 'enable-noise-cancellation',
    END_CALL: 'end-call',
    JOIN_BACKSTAGE: 'join-backstage',
    JOIN_CALL: 'join-call',
    JOIN_ENDED_CALL: 'join-ended-call',
    MUTE_USERS: 'mute-users',
    PIN_FOR_EVERYONE: 'pin-for-everyone',
    READ_CALL: 'read-call',
    REMOVE_CALL_MEMBER: 'remove-call-member',
    SCREENSHARE: 'screenshare',
    SEND_AUDIO: 'send-audio',
    SEND_VIDEO: 'send-video',
    START_BROADCAST_CALL: 'start-broadcast-call',
    START_RECORD_CALL: 'start-record-call',
    START_TRANSCRIPTION_CALL: 'start-transcription-call',
    STOP_BROADCAST_CALL: 'stop-broadcast-call',
    STOP_RECORD_CALL: 'stop-record-call',
    STOP_TRANSCRIPTION_CALL: 'stop-transcription-call',
    UPDATE_CALL: 'update-call',
    UPDATE_CALL_MEMBER: 'update-call-member',
    UPDATE_CALL_PERMISSIONS: 'update-call-permissions',
    UPDATE_CALL_SETTINGS: 'update-call-settings',
};
/**
 * @export
 */
const RecordSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const RecordSettingsRequestQualityEnum = {
    _360P: '360p',
    _480P: '480p',
    _720P: '720p',
    _1080P: '1080p',
    _1440P: '1440p',
};
/**
 * @export
 */
const TranscriptionSettingsModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const TranscriptionSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const VideoSettingsCameraFacingEnum = {
    FRONT: 'front',
    BACK: 'back',
    EXTERNAL: 'external',
};
/**
 * @export
 */
const VideoSettingsRequestCameraFacingEnum = {
    FRONT: 'front',
    BACK: 'back',
    EXTERNAL: 'external',
};

class ErrorFromResponse extends Error {
}

/**
 * `NullValue` is a singleton enumeration to represent the null value for the
 * `Value` type union.
 *
 *  The JSON representation for `NullValue` is JSON `null`.
 *
 * @generated from protobuf enum google.protobuf.NullValue
 */
var NullValue;
(function (NullValue) {
    /**
     * Null value.
     *
     * @generated from protobuf enum value: NULL_VALUE = 0;
     */
    NullValue[NullValue["NULL_VALUE"] = 0] = "NULL_VALUE";
})(NullValue || (NullValue = {}));
// @generated message type with reflection information, may provide speed optimized methods
class Struct$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Struct', [
            {
                no: 1,
                name: 'fields',
                kind: 'map',
                K: 9 /*ScalarType.STRING*/,
                V: { kind: 'message', T: () => Value },
            },
        ]);
    }
    /**
     * Encode `Struct` to JSON object.
     */
    internalJsonWrite(message, options) {
        let json = {};
        for (let [k, v] of Object.entries(message.fields)) {
            json[k] = Value.toJson(v);
        }
        return json;
    }
    /**
     * Decode `Struct` from JSON object.
     */
    internalJsonRead(json, options, target) {
        if (!runtime.isJsonObject(json))
            throw new globalThis.Error('Unable to parse message ' +
                this.typeName +
                ' from JSON ' +
                runtime.typeofJsonValue(json) +
                '.');
        if (!target)
            target = this.create();
        for (let [k, v] of globalThis.Object.entries(json)) {
            target.fields[k] = Value.fromJson(v);
        }
        return target;
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.fields = {};
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* map<string, google.protobuf.Value> fields */ 1:
                    this.binaryReadMap1(message.fields, reader, options);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    binaryReadMap1(map, reader, options) {
        let len = reader.uint32(), end = reader.pos + len, key, val;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case 1:
                    key = reader.string();
                    break;
                case 2:
                    val = Value.internalBinaryRead(reader, reader.uint32(), options);
                    break;
                default:
                    throw new globalThis.Error('unknown map entry field for field google.protobuf.Struct.fields');
            }
        }
        map[key ?? ''] = val ?? Value.create();
    }
    internalBinaryWrite(message, writer, options) {
        /* map<string, google.protobuf.Value> fields = 1; */
        for (let k of globalThis.Object.keys(message.fields)) {
            writer
                .tag(1, runtime.WireType.LengthDelimited)
                .fork()
                .tag(1, runtime.WireType.LengthDelimited)
                .string(k);
            writer.tag(2, runtime.WireType.LengthDelimited).fork();
            Value.internalBinaryWrite(message.fields[k], writer, options);
            writer.join().join();
        }
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Struct
 */
const Struct = new Struct$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Value$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Value', [
            {
                no: 1,
                name: 'null_value',
                kind: 'enum',
                oneof: 'kind',
                T: () => ['google.protobuf.NullValue', NullValue],
            },
            {
                no: 2,
                name: 'number_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 1 /*ScalarType.DOUBLE*/,
            },
            {
                no: 3,
                name: 'string_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'bool_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 5,
                name: 'struct_value',
                kind: 'message',
                oneof: 'kind',
                T: () => Struct,
            },
            {
                no: 6,
                name: 'list_value',
                kind: 'message',
                oneof: 'kind',
                T: () => ListValue,
            },
        ]);
    }
    /**
     * Encode `Value` to JSON value.
     */
    internalJsonWrite(message, options) {
        if (message.kind.oneofKind === undefined)
            throw new globalThis.Error();
        switch (message.kind.oneofKind) {
            case undefined:
                throw new globalThis.Error();
            case 'boolValue':
                return message.kind.boolValue;
            case 'nullValue':
                return null;
            case 'numberValue':
                let numberValue = message.kind.numberValue;
                if (typeof numberValue == 'number' && !Number.isFinite(numberValue))
                    throw new globalThis.Error();
                return numberValue;
            case 'stringValue':
                return message.kind.stringValue;
            case 'listValue':
                let listValueField = this.fields.find((f) => f.no === 6);
                if (listValueField?.kind !== 'message')
                    throw new globalThis.Error();
                return listValueField.T().toJson(message.kind.listValue);
            case 'structValue':
                let structValueField = this.fields.find((f) => f.no === 5);
                if (structValueField?.kind !== 'message')
                    throw new globalThis.Error();
                return structValueField.T().toJson(message.kind.structValue);
        }
    }
    /**
     * Decode `Value` from JSON value.
     */
    internalJsonRead(json, options, target) {
        if (!target)
            target = this.create();
        switch (typeof json) {
            case 'number':
                target.kind = { oneofKind: 'numberValue', numberValue: json };
                break;
            case 'string':
                target.kind = { oneofKind: 'stringValue', stringValue: json };
                break;
            case 'boolean':
                target.kind = { oneofKind: 'boolValue', boolValue: json };
                break;
            case 'object':
                if (json === null) {
                    target.kind = {
                        oneofKind: 'nullValue',
                        nullValue: NullValue.NULL_VALUE,
                    };
                }
                else if (globalThis.Array.isArray(json)) {
                    target.kind = {
                        oneofKind: 'listValue',
                        listValue: ListValue.fromJson(json),
                    };
                }
                else {
                    target.kind = {
                        oneofKind: 'structValue',
                        structValue: Struct.fromJson(json),
                    };
                }
                break;
            default:
                throw new globalThis.Error('Unable to parse ' +
                    this.typeName +
                    ' from JSON ' +
                    runtime.typeofJsonValue(json));
        }
        return target;
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.kind = { oneofKind: undefined };
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* google.protobuf.NullValue null_value */ 1:
                    message.kind = {
                        oneofKind: 'nullValue',
                        nullValue: reader.int32(),
                    };
                    break;
                case /* double number_value */ 2:
                    message.kind = {
                        oneofKind: 'numberValue',
                        numberValue: reader.double(),
                    };
                    break;
                case /* string string_value */ 3:
                    message.kind = {
                        oneofKind: 'stringValue',
                        stringValue: reader.string(),
                    };
                    break;
                case /* bool bool_value */ 4:
                    message.kind = {
                        oneofKind: 'boolValue',
                        boolValue: reader.bool(),
                    };
                    break;
                case /* google.protobuf.Struct struct_value */ 5:
                    message.kind = {
                        oneofKind: 'structValue',
                        structValue: Struct.internalBinaryRead(reader, reader.uint32(), options, message.kind.structValue),
                    };
                    break;
                case /* google.protobuf.ListValue list_value */ 6:
                    message.kind = {
                        oneofKind: 'listValue',
                        listValue: ListValue.internalBinaryRead(reader, reader.uint32(), options, message.kind.listValue),
                    };
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* google.protobuf.NullValue null_value = 1; */
        if (message.kind.oneofKind === 'nullValue')
            writer.tag(1, runtime.WireType.Varint).int32(message.kind.nullValue);
        /* double number_value = 2; */
        if (message.kind.oneofKind === 'numberValue')
            writer.tag(2, runtime.WireType.Bit64).double(message.kind.numberValue);
        /* string string_value = 3; */
        if (message.kind.oneofKind === 'stringValue')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.kind.stringValue);
        /* bool bool_value = 4; */
        if (message.kind.oneofKind === 'boolValue')
            writer.tag(4, runtime.WireType.Varint).bool(message.kind.boolValue);
        /* google.protobuf.Struct struct_value = 5; */
        if (message.kind.oneofKind === 'structValue')
            Struct.internalBinaryWrite(message.kind.structValue, writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        /* google.protobuf.ListValue list_value = 6; */
        if (message.kind.oneofKind === 'listValue')
            ListValue.internalBinaryWrite(message.kind.listValue, writer.tag(6, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Value
 */
const Value = new Value$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ListValue$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.ListValue', [
            {
                no: 1,
                name: 'values',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Value,
            },
        ]);
    }
    /**
     * Encode `ListValue` to JSON array.
     */
    internalJsonWrite(message, options) {
        return message.values.map((v) => Value.toJson(v));
    }
    /**
     * Decode `ListValue` from JSON array.
     */
    internalJsonRead(json, options, target) {
        if (!globalThis.Array.isArray(json))
            throw new globalThis.Error('Unable to parse ' +
                this.typeName +
                ' from JSON ' +
                runtime.typeofJsonValue(json));
        if (!target)
            target = this.create();
        let values = json.map((v) => Value.fromJson(v));
        target.values.push(...values);
        return target;
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.values = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated google.protobuf.Value values */ 1:
                    message.values.push(Value.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated google.protobuf.Value values = 1; */
        for (let i = 0; i < message.values.length; i++)
            Value.internalBinaryWrite(message.values[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.ListValue
 */
const ListValue = new ListValue$Type();

// @generated message type with reflection information, may provide speed optimized methods
class Timestamp$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Timestamp', [
            { no: 1, name: 'seconds', kind: 'scalar', T: 3 /*ScalarType.INT64*/ },
            { no: 2, name: 'nanos', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
        ]);
    }
    /**
     * Creates a new `Timestamp` for the current time.
     */
    now() {
        const msg = this.create();
        const ms = Date.now();
        msg.seconds = runtime.PbLong.from(Math.floor(ms / 1000)).toString();
        msg.nanos = (ms % 1000) * 1000000;
        return msg;
    }
    /**
     * Converts a `Timestamp` to a JavaScript Date.
     */
    toDate(message) {
        return new Date(runtime.PbLong.from(message.seconds).toNumber() * 1000 +
            Math.ceil(message.nanos / 1000000));
    }
    /**
     * Converts a JavaScript Date to a `Timestamp`.
     */
    fromDate(date) {
        const msg = this.create();
        const ms = date.getTime();
        msg.seconds = runtime.PbLong.from(Math.floor(ms / 1000)).toString();
        msg.nanos = (ms % 1000) * 1000000;
        return msg;
    }
    /**
     * In JSON format, the `Timestamp` type is encoded as a string
     * in the RFC 3339 format.
     */
    internalJsonWrite(message, options) {
        let ms = runtime.PbLong.from(message.seconds).toNumber() * 1000;
        if (ms < Date.parse('0001-01-01T00:00:00Z') ||
            ms > Date.parse('9999-12-31T23:59:59Z'))
            throw new Error('Unable to encode Timestamp to JSON. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.');
        if (message.nanos < 0)
            throw new Error('Unable to encode invalid Timestamp to JSON. Nanos must not be negative.');
        let z = 'Z';
        if (message.nanos > 0) {
            let nanosStr = (message.nanos + 1000000000).toString().substring(1);
            if (nanosStr.substring(3) === '000000')
                z = '.' + nanosStr.substring(0, 3) + 'Z';
            else if (nanosStr.substring(6) === '000')
                z = '.' + nanosStr.substring(0, 6) + 'Z';
            else
                z = '.' + nanosStr + 'Z';
        }
        return new Date(ms).toISOString().replace('.000Z', z);
    }
    /**
     * In JSON format, the `Timestamp` type is encoded as a string
     * in the RFC 3339 format.
     */
    internalJsonRead(json, options, target) {
        if (typeof json !== 'string')
            throw new Error('Unable to parse Timestamp from JSON ' + runtime.typeofJsonValue(json) + '.');
        let matches = json.match(/^([0-9]{4})-([0-9]{2})-([0-9]{2})T([0-9]{2}):([0-9]{2}):([0-9]{2})(?:Z|\.([0-9]{3,9})Z|([+-][0-9][0-9]:[0-9][0-9]))$/);
        if (!matches)
            throw new Error('Unable to parse Timestamp from JSON. Invalid format.');
        let ms = Date.parse(matches[1] +
            '-' +
            matches[2] +
            '-' +
            matches[3] +
            'T' +
            matches[4] +
            ':' +
            matches[5] +
            ':' +
            matches[6] +
            (matches[8] ? matches[8] : 'Z'));
        if (Number.isNaN(ms))
            throw new Error('Unable to parse Timestamp from JSON. Invalid value.');
        if (ms < Date.parse('0001-01-01T00:00:00Z') ||
            ms > Date.parse('9999-12-31T23:59:59Z'))
            throw new globalThis.Error('Unable to parse Timestamp from JSON. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.');
        if (!target)
            target = this.create();
        target.seconds = runtime.PbLong.from(ms / 1000).toString();
        target.nanos = 0;
        if (matches[7])
            target.nanos =
                parseInt('1' + matches[7] + '0'.repeat(9 - matches[7].length)) -
                    1000000000;
        return target;
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.seconds = '0';
        message.nanos = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* int64 seconds */ 1:
                    message.seconds = reader.int64().toString();
                    break;
                case /* int32 nanos */ 2:
                    message.nanos = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* int64 seconds = 1; */
        if (message.seconds !== '0')
            writer.tag(1, runtime.WireType.Varint).int64(message.seconds);
        /* int32 nanos = 2; */
        if (message.nanos !== 0)
            writer.tag(2, runtime.WireType.Varint).int32(message.nanos);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Timestamp
 */
const Timestamp = new Timestamp$Type();

/**
 * @generated from protobuf enum stream.video.sfu.models.PeerType
 */
var PeerType;
(function (PeerType) {
    /**
     * todo fix me (marcelo)
     *
     * @generated from protobuf enum value: PEER_TYPE_PUBLISHER_UNSPECIFIED = 0;
     */
    PeerType[PeerType["PUBLISHER_UNSPECIFIED"] = 0] = "PUBLISHER_UNSPECIFIED";
    /**
     * @generated from protobuf enum value: PEER_TYPE_SUBSCRIBER = 1;
     */
    PeerType[PeerType["SUBSCRIBER"] = 1] = "SUBSCRIBER";
})(PeerType || (PeerType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.ConnectionQuality
 */
var ConnectionQuality;
(function (ConnectionQuality) {
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_UNSPECIFIED = 0;
     */
    ConnectionQuality[ConnectionQuality["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_POOR = 1;
     */
    ConnectionQuality[ConnectionQuality["POOR"] = 1] = "POOR";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_GOOD = 2;
     */
    ConnectionQuality[ConnectionQuality["GOOD"] = 2] = "GOOD";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_EXCELLENT = 3;
     */
    ConnectionQuality[ConnectionQuality["EXCELLENT"] = 3] = "EXCELLENT";
})(ConnectionQuality || (ConnectionQuality = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.VideoQuality
 */
var VideoQuality;
(function (VideoQuality) {
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_LOW_UNSPECIFIED = 0;
     */
    VideoQuality[VideoQuality["LOW_UNSPECIFIED"] = 0] = "LOW_UNSPECIFIED";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_MID = 1;
     */
    VideoQuality[VideoQuality["MID"] = 1] = "MID";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_HIGH = 2;
     */
    VideoQuality[VideoQuality["HIGH"] = 2] = "HIGH";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_OFF = 3;
     */
    VideoQuality[VideoQuality["OFF"] = 3] = "OFF";
})(VideoQuality || (VideoQuality = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.TrackType
 */
var TrackType;
(function (TrackType) {
    /**
     * @generated from protobuf enum value: TRACK_TYPE_UNSPECIFIED = 0;
     */
    TrackType[TrackType["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_AUDIO = 1;
     */
    TrackType[TrackType["AUDIO"] = 1] = "AUDIO";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_VIDEO = 2;
     */
    TrackType[TrackType["VIDEO"] = 2] = "VIDEO";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_SCREEN_SHARE = 3;
     */
    TrackType[TrackType["SCREEN_SHARE"] = 3] = "SCREEN_SHARE";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_SCREEN_SHARE_AUDIO = 4;
     */
    TrackType[TrackType["SCREEN_SHARE_AUDIO"] = 4] = "SCREEN_SHARE_AUDIO";
})(TrackType || (TrackType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.ErrorCode
 */
var ErrorCode;
(function (ErrorCode) {
    /**
     * @generated from protobuf enum value: ERROR_CODE_UNSPECIFIED = 0;
     */
    ErrorCode[ErrorCode["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_NOT_FOUND = 100;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_NOT_FOUND"] = 100] = "PUBLISH_TRACK_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACKS_MISMATCH = 101;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACKS_MISMATCH"] = 101] = "PUBLISH_TRACKS_MISMATCH";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_OUT_OF_ORDER = 102;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_OUT_OF_ORDER"] = 102] = "PUBLISH_TRACK_OUT_OF_ORDER";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND = 103;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND"] = 103] = "PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_LIVE_ENDED = 104;
     */
    ErrorCode[ErrorCode["LIVE_ENDED"] = 104] = "LIVE_ENDED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_NOT_FOUND = 200;
     */
    ErrorCode[ErrorCode["PARTICIPANT_NOT_FOUND"] = 200] = "PARTICIPANT_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATING_OUT = 201;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATING_OUT"] = 201] = "PARTICIPANT_MIGRATING_OUT";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATION_FAILED = 202;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATION_FAILED"] = 202] = "PARTICIPANT_MIGRATION_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATING = 203;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATING"] = 203] = "PARTICIPANT_MIGRATING";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_RECONNECT_FAILED = 204;
     */
    ErrorCode[ErrorCode["PARTICIPANT_RECONNECT_FAILED"] = 204] = "PARTICIPANT_RECONNECT_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MEDIA_TRANSPORT_FAILURE = 205;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MEDIA_TRANSPORT_FAILURE"] = 205] = "PARTICIPANT_MEDIA_TRANSPORT_FAILURE";
    /**
     * @generated from protobuf enum value: ERROR_CODE_CALL_NOT_FOUND = 300;
     */
    ErrorCode[ErrorCode["CALL_NOT_FOUND"] = 300] = "CALL_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_REQUEST_VALIDATION_FAILED = 400;
     */
    ErrorCode[ErrorCode["REQUEST_VALIDATION_FAILED"] = 400] = "REQUEST_VALIDATION_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_UNAUTHENTICATED = 401;
     */
    ErrorCode[ErrorCode["UNAUTHENTICATED"] = 401] = "UNAUTHENTICATED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PERMISSION_DENIED = 403;
     */
    ErrorCode[ErrorCode["PERMISSION_DENIED"] = 403] = "PERMISSION_DENIED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_TOO_MANY_REQUESTS = 429;
     */
    ErrorCode[ErrorCode["TOO_MANY_REQUESTS"] = 429] = "TOO_MANY_REQUESTS";
    /**
     * @generated from protobuf enum value: ERROR_CODE_INTERNAL_SERVER_ERROR = 500;
     */
    ErrorCode[ErrorCode["INTERNAL_SERVER_ERROR"] = 500] = "INTERNAL_SERVER_ERROR";
    /**
     * @generated from protobuf enum value: ERROR_CODE_SFU_SHUTTING_DOWN = 600;
     */
    ErrorCode[ErrorCode["SFU_SHUTTING_DOWN"] = 600] = "SFU_SHUTTING_DOWN";
    /**
     * @generated from protobuf enum value: ERROR_CODE_SFU_FULL = 700;
     */
    ErrorCode[ErrorCode["SFU_FULL"] = 700] = "SFU_FULL";
})(ErrorCode || (ErrorCode = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.SdkType
 */
var SdkType;
(function (SdkType) {
    /**
     * @generated from protobuf enum value: SDK_TYPE_UNSPECIFIED = 0;
     */
    SdkType[SdkType["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: SDK_TYPE_REACT = 1;
     */
    SdkType[SdkType["REACT"] = 1] = "REACT";
    /**
     * @generated from protobuf enum value: SDK_TYPE_ANGULAR = 2;
     */
    SdkType[SdkType["ANGULAR"] = 2] = "ANGULAR";
    /**
     * @generated from protobuf enum value: SDK_TYPE_ANDROID = 3;
     */
    SdkType[SdkType["ANDROID"] = 3] = "ANDROID";
    /**
     * @generated from protobuf enum value: SDK_TYPE_IOS = 4;
     */
    SdkType[SdkType["IOS"] = 4] = "IOS";
    /**
     * @generated from protobuf enum value: SDK_TYPE_FLUTTER = 5;
     */
    SdkType[SdkType["FLUTTER"] = 5] = "FLUTTER";
    /**
     * @generated from protobuf enum value: SDK_TYPE_REACT_NATIVE = 6;
     */
    SdkType[SdkType["REACT_NATIVE"] = 6] = "REACT_NATIVE";
    /**
     * @generated from protobuf enum value: SDK_TYPE_UNITY = 7;
     */
    SdkType[SdkType["UNITY"] = 7] = "UNITY";
})(SdkType || (SdkType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.TrackUnpublishReason
 */
var TrackUnpublishReason;
(function (TrackUnpublishReason) {
    /**
     * Default value which is used when the specific reason
     * for muting the track is not known.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_UNSPECIFIED = 0;
     */
    TrackUnpublishReason[TrackUnpublishReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * Represents user muting their tracks.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_USER_MUTED = 1;
     */
    TrackUnpublishReason[TrackUnpublishReason["USER_MUTED"] = 1] = "USER_MUTED";
    /**
     * Represents muting the track because the permission to
     * publish the track has been revoked.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_PERMISSION_REVOKED = 2;
     */
    TrackUnpublishReason[TrackUnpublishReason["PERMISSION_REVOKED"] = 2] = "PERMISSION_REVOKED";
    /**
     * Represents muting the track due to moderation actions.
     * This is different from permission revoked because the
     * participant can unmute themselves here whereas in case
     * of "permission revoke" it is not possible until the
     * call permissions are updated.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_MODERATION = 3;
     */
    TrackUnpublishReason[TrackUnpublishReason["MODERATION"] = 3] = "MODERATION";
})(TrackUnpublishReason || (TrackUnpublishReason = {}));
/**
 * GoAwayReason represents the reason for the SFU to
 * disconnect the client.
 *
 * @generated from protobuf enum stream.video.sfu.models.GoAwayReason
 */
var GoAwayReason;
(function (GoAwayReason) {
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_UNSPECIFIED = 0;
     */
    GoAwayReason[GoAwayReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_SHUTTING_DOWN = 1;
     */
    GoAwayReason[GoAwayReason["SHUTTING_DOWN"] = 1] = "SHUTTING_DOWN";
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_REBALANCE = 2;
     */
    GoAwayReason[GoAwayReason["REBALANCE"] = 2] = "REBALANCE";
})(GoAwayReason || (GoAwayReason = {}));
/**
 * CallEndedReason represents the reason for the call to end.
 *
 * @generated from protobuf enum stream.video.sfu.models.CallEndedReason
 */
var CallEndedReason;
(function (CallEndedReason) {
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_UNSPECIFIED = 0;
     */
    CallEndedReason[CallEndedReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_ENDED = 1;
     */
    CallEndedReason[CallEndedReason["ENDED"] = 1] = "ENDED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_LIVE_ENDED = 2;
     */
    CallEndedReason[CallEndedReason["LIVE_ENDED"] = 2] = "LIVE_ENDED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_KICKED = 3;
     */
    CallEndedReason[CallEndedReason["KICKED"] = 3] = "KICKED";
})(CallEndedReason || (CallEndedReason = {}));
/**
 * WebsocketReconnectStrategy defines the ws strategies available for handling reconnections.
 *
 * @generated from protobuf enum stream.video.sfu.models.WebsocketReconnectStrategy
 */
var WebsocketReconnectStrategy;
(function (WebsocketReconnectStrategy) {
    /**
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_UNSPECIFIED = 0;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * Sent after reaching the maximum reconnection attempts, leading to permanent disconnect.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_DISCONNECT = 1;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["DISCONNECT"] = 1] = "DISCONNECT";
    /**
     * SDK should maintaining existing publisher/subscriber pc instances
     * and establish a new WebSocket connection.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_FAST = 2;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["FAST"] = 2] = "FAST";
    /**
     * SDK should drop existing pc instances and creates a fresh WebSocket connection,
     * ensuring a clean state for the reconnection.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_CLEAN = 3;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["CLEAN"] = 3] = "CLEAN";
    /**
     * SDK should obtain new credentials from the coordinator, drops existing pc instances, and initializes
     * a completely new WebSocket connection, ensuring a comprehensive reset.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_FULL = 4;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["FULL"] = 4] = "FULL";
    /**
     * SDK should migrate to a new SFU instance
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_MIGRATE = 5;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["MIGRATE"] = 5] = "MIGRATE";
})(WebsocketReconnectStrategy || (WebsocketReconnectStrategy = {}));
// @generated message type with reflection information, may provide speed optimized methods
class CallState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.CallState', [
            {
                no: 1,
                name: 'participants',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Participant,
            },
            { no: 2, name: 'started_at', kind: 'message', T: () => Timestamp },
            {
                no: 3,
                name: 'participant_count',
                kind: 'message',
                T: () => ParticipantCount,
            },
            {
                no: 4,
                name: 'pins',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Pin,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.participants = [];
        message.pins = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated stream.video.sfu.models.Participant participants */ 1:
                    message.participants.push(Participant.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* google.protobuf.Timestamp started_at */ 2:
                    message.startedAt = Timestamp.internalBinaryRead(reader, reader.uint32(), options, message.startedAt);
                    break;
                case /* stream.video.sfu.models.ParticipantCount participant_count */ 3:
                    message.participantCount = ParticipantCount.internalBinaryRead(reader, reader.uint32(), options, message.participantCount);
                    break;
                case /* repeated stream.video.sfu.models.Pin pins */ 4:
                    message.pins.push(Pin.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated stream.video.sfu.models.Participant participants = 1; */
        for (let i = 0; i < message.participants.length; i++)
            Participant.internalBinaryWrite(message.participants[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* google.protobuf.Timestamp started_at = 2; */
        if (message.startedAt)
            Timestamp.internalBinaryWrite(message.startedAt, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.ParticipantCount participant_count = 3; */
        if (message.participantCount)
            ParticipantCount.internalBinaryWrite(message.participantCount, writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        /* repeated stream.video.sfu.models.Pin pins = 4; */
        for (let i = 0; i < message.pins.length; i++)
            Pin.internalBinaryWrite(message.pins[i], writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.CallState
 */
const CallState$1 = new CallState$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantCount$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ParticipantCount', [
            { no: 1, name: 'total', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 2, name: 'anonymous', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.total = 0;
        message.anonymous = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* uint32 total */ 1:
                    message.total = reader.uint32();
                    break;
                case /* uint32 anonymous */ 2:
                    message.anonymous = reader.uint32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint32 total = 1; */
        if (message.total !== 0)
            writer.tag(1, runtime.WireType.Varint).uint32(message.total);
        /* uint32 anonymous = 2; */
        if (message.anonymous !== 0)
            writer.tag(2, runtime.WireType.Varint).uint32(message.anonymous);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ParticipantCount
 */
const ParticipantCount = new ParticipantCount$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Pin$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Pin', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Pin
 */
const Pin = new Pin$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Participant$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Participant', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'published_tracks',
                kind: 'enum',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'joined_at', kind: 'message', T: () => Timestamp },
            {
                no: 5,
                name: 'track_lookup_prefix',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 6,
                name: 'connection_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ConnectionQuality',
                    ConnectionQuality,
                    'CONNECTION_QUALITY_',
                ],
            },
            { no: 7, name: 'is_speaking', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            {
                no: 8,
                name: 'is_dominant_speaker',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            { no: 9, name: 'audio_level', kind: 'scalar', T: 2 /*ScalarType.FLOAT*/ },
            { no: 10, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 11, name: 'image', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 12, name: 'custom', kind: 'message', T: () => Struct },
            {
                no: 13,
                name: 'roles',
                kind: 'scalar',
                repeat: 2 /*RepeatType.UNPACKED*/,
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.publishedTracks = [];
        message.trackLookupPrefix = '';
        message.connectionQuality = 0;
        message.isSpeaking = false;
        message.isDominantSpeaker = false;
        message.audioLevel = 0;
        message.name = '';
        message.image = '';
        message.roles = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* repeated stream.video.sfu.models.TrackType published_tracks */ 3:
                    if (wireType === runtime.WireType.LengthDelimited)
                        for (let e = reader.int32() + reader.pos; reader.pos < e;)
                            message.publishedTracks.push(reader.int32());
                    else
                        message.publishedTracks.push(reader.int32());
                    break;
                case /* google.protobuf.Timestamp joined_at */ 4:
                    message.joinedAt = Timestamp.internalBinaryRead(reader, reader.uint32(), options, message.joinedAt);
                    break;
                case /* string track_lookup_prefix */ 5:
                    message.trackLookupPrefix = reader.string();
                    break;
                case /* stream.video.sfu.models.ConnectionQuality connection_quality */ 6:
                    message.connectionQuality = reader.int32();
                    break;
                case /* bool is_speaking */ 7:
                    message.isSpeaking = reader.bool();
                    break;
                case /* bool is_dominant_speaker */ 8:
                    message.isDominantSpeaker = reader.bool();
                    break;
                case /* float audio_level */ 9:
                    message.audioLevel = reader.float();
                    break;
                case /* string name */ 10:
                    message.name = reader.string();
                    break;
                case /* string image */ 11:
                    message.image = reader.string();
                    break;
                case /* google.protobuf.Struct custom */ 12:
                    message.custom = Struct.internalBinaryRead(reader, reader.uint32(), options, message.custom);
                    break;
                case /* repeated string roles */ 13:
                    message.roles.push(reader.string());
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* repeated stream.video.sfu.models.TrackType published_tracks = 3; */
        if (message.publishedTracks.length) {
            writer.tag(3, runtime.WireType.LengthDelimited).fork();
            for (let i = 0; i < message.publishedTracks.length; i++)
                writer.int32(message.publishedTracks[i]);
            writer.join();
        }
        /* google.protobuf.Timestamp joined_at = 4; */
        if (message.joinedAt)
            Timestamp.internalBinaryWrite(message.joinedAt, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        /* string track_lookup_prefix = 5; */
        if (message.trackLookupPrefix !== '')
            writer.tag(5, runtime.WireType.LengthDelimited).string(message.trackLookupPrefix);
        /* stream.video.sfu.models.ConnectionQuality connection_quality = 6; */
        if (message.connectionQuality !== 0)
            writer.tag(6, runtime.WireType.Varint).int32(message.connectionQuality);
        /* bool is_speaking = 7; */
        if (message.isSpeaking !== false)
            writer.tag(7, runtime.WireType.Varint).bool(message.isSpeaking);
        /* bool is_dominant_speaker = 8; */
        if (message.isDominantSpeaker !== false)
            writer.tag(8, runtime.WireType.Varint).bool(message.isDominantSpeaker);
        /* float audio_level = 9; */
        if (message.audioLevel !== 0)
            writer.tag(9, runtime.WireType.Bit32).float(message.audioLevel);
        /* string name = 10; */
        if (message.name !== '')
            writer.tag(10, runtime.WireType.LengthDelimited).string(message.name);
        /* string image = 11; */
        if (message.image !== '')
            writer.tag(11, runtime.WireType.LengthDelimited).string(message.image);
        /* google.protobuf.Struct custom = 12; */
        if (message.custom)
            Struct.internalBinaryWrite(message.custom, writer.tag(12, runtime.WireType.LengthDelimited).fork(), options).join();
        /* repeated string roles = 13; */
        for (let i = 0; i < message.roles.length; i++)
            writer.tag(13, runtime.WireType.LengthDelimited).string(message.roles[i]);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Participant
 */
const Participant = new Participant$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StreamQuality$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.StreamQuality', [
            {
                no: 1,
                name: 'video_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.VideoQuality',
                    VideoQuality,
                    'VIDEO_QUALITY_',
                ],
            },
            { no: 2, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.videoQuality = 0;
        message.userId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.VideoQuality video_quality */ 1:
                    message.videoQuality = reader.int32();
                    break;
                case /* string user_id */ 2:
                    message.userId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.VideoQuality video_quality = 1; */
        if (message.videoQuality !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.videoQuality);
        /* string user_id = 2; */
        if (message.userId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.userId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.StreamQuality
 */
const StreamQuality = new StreamQuality$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoDimension$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.VideoDimension', [
            { no: 1, name: 'width', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 2, name: 'height', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.width = 0;
        message.height = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* uint32 width */ 1:
                    message.width = reader.uint32();
                    break;
                case /* uint32 height */ 2:
                    message.height = reader.uint32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint32 width = 1; */
        if (message.width !== 0)
            writer.tag(1, runtime.WireType.Varint).uint32(message.width);
        /* uint32 height = 2; */
        if (message.height !== 0)
            writer.tag(2, runtime.WireType.Varint).uint32(message.height);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.VideoDimension
 */
const VideoDimension = new VideoDimension$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoLayer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.VideoLayer', [
            { no: 1, name: 'rid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'video_dimension',
                kind: 'message',
                T: () => VideoDimension,
            },
            { no: 4, name: 'bitrate', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 5, name: 'fps', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            {
                no: 6,
                name: 'quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.VideoQuality',
                    VideoQuality,
                    'VIDEO_QUALITY_',
                ],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.rid = '';
        message.bitrate = 0;
        message.fps = 0;
        message.quality = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string rid */ 1:
                    message.rid = reader.string();
                    break;
                case /* stream.video.sfu.models.VideoDimension video_dimension */ 2:
                    message.videoDimension = VideoDimension.internalBinaryRead(reader, reader.uint32(), options, message.videoDimension);
                    break;
                case /* uint32 bitrate */ 4:
                    message.bitrate = reader.uint32();
                    break;
                case /* uint32 fps */ 5:
                    message.fps = reader.uint32();
                    break;
                case /* stream.video.sfu.models.VideoQuality quality */ 6:
                    message.quality = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string rid = 1; */
        if (message.rid !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.rid);
        /* stream.video.sfu.models.VideoDimension video_dimension = 2; */
        if (message.videoDimension)
            VideoDimension.internalBinaryWrite(message.videoDimension, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* uint32 bitrate = 4; */
        if (message.bitrate !== 0)
            writer.tag(4, runtime.WireType.Varint).uint32(message.bitrate);
        /* uint32 fps = 5; */
        if (message.fps !== 0)
            writer.tag(5, runtime.WireType.Varint).uint32(message.fps);
        /* stream.video.sfu.models.VideoQuality quality = 6; */
        if (message.quality !== 0)
            writer.tag(6, runtime.WireType.Varint).int32(message.quality);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.VideoLayer
 */
const VideoLayer = new VideoLayer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Codec$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Codec', [
            {
                no: 1,
                name: 'payload_type',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            { no: 2, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'fmtp_line', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 4,
                name: 'clock_rate',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            {
                no: 5,
                name: 'encoding_parameters',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 6,
                name: 'feedbacks',
                kind: 'scalar',
                repeat: 2 /*RepeatType.UNPACKED*/,
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.payloadType = 0;
        message.name = '';
        message.fmtpLine = '';
        message.clockRate = 0;
        message.encodingParameters = '';
        message.feedbacks = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* uint32 payload_type */ 1:
                    message.payloadType = reader.uint32();
                    break;
                case /* string name */ 2:
                    message.name = reader.string();
                    break;
                case /* string fmtp_line */ 3:
                    message.fmtpLine = reader.string();
                    break;
                case /* uint32 clock_rate */ 4:
                    message.clockRate = reader.uint32();
                    break;
                case /* string encoding_parameters */ 5:
                    message.encodingParameters = reader.string();
                    break;
                case /* repeated string feedbacks */ 6:
                    message.feedbacks.push(reader.string());
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* uint32 payload_type = 1; */
        if (message.payloadType !== 0)
            writer.tag(1, runtime.WireType.Varint).uint32(message.payloadType);
        /* string name = 2; */
        if (message.name !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.name);
        /* string fmtp_line = 3; */
        if (message.fmtpLine !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.fmtpLine);
        /* uint32 clock_rate = 4; */
        if (message.clockRate !== 0)
            writer.tag(4, runtime.WireType.Varint).uint32(message.clockRate);
        /* string encoding_parameters = 5; */
        if (message.encodingParameters !== '')
            writer
                .tag(5, runtime.WireType.LengthDelimited)
                .string(message.encodingParameters);
        /* repeated string feedbacks = 6; */
        for (let i = 0; i < message.feedbacks.length; i++)
            writer.tag(6, runtime.WireType.LengthDelimited).string(message.feedbacks[i]);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Codec
 */
const Codec = new Codec$Type();
// @generated message type with reflection information, may provide speed optimized methods
let ICETrickle$Type$1 = class ICETrickle$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ICETrickle', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            {
                no: 2,
                name: 'ice_candidate',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 3, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.peerType = 0;
        message.iceCandidate = '';
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.PeerType peer_type */ 1:
                    message.peerType = reader.int32();
                    break;
                case /* string ice_candidate */ 2:
                    message.iceCandidate = reader.string();
                    break;
                case /* string session_id */ 3:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.PeerType peer_type = 1; */
        if (message.peerType !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.peerType);
        /* string ice_candidate = 2; */
        if (message.iceCandidate !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.iceCandidate);
        /* string session_id = 3; */
        if (message.sessionId !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
};
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ICETrickle
 */
const ICETrickle$1 = new ICETrickle$Type$1();
// @generated message type with reflection information, may provide speed optimized methods
class TrackInfo$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.TrackInfo', [
            { no: 1, name: 'track_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 5,
                name: 'layers',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoLayer,
            },
            { no: 6, name: 'mid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 7, name: 'dtx', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 8, name: 'stereo', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 9, name: 'red', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.trackId = '';
        message.trackType = 0;
        message.layers = [];
        message.mid = '';
        message.dtx = false;
        message.stereo = false;
        message.red = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string track_id */ 1:
                    message.trackId = reader.string();
                    break;
                case /* stream.video.sfu.models.TrackType track_type */ 2:
                    message.trackType = reader.int32();
                    break;
                case /* repeated stream.video.sfu.models.VideoLayer layers */ 5:
                    message.layers.push(VideoLayer.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* string mid */ 6:
                    message.mid = reader.string();
                    break;
                case /* bool dtx */ 7:
                    message.dtx = reader.bool();
                    break;
                case /* bool stereo */ 8:
                    message.stereo = reader.bool();
                    break;
                case /* bool red */ 9:
                    message.red = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string track_id = 1; */
        if (message.trackId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.trackId);
        /* stream.video.sfu.models.TrackType track_type = 2; */
        if (message.trackType !== 0)
            writer.tag(2, runtime.WireType.Varint).int32(message.trackType);
        /* repeated stream.video.sfu.models.VideoLayer layers = 5; */
        for (let i = 0; i < message.layers.length; i++)
            VideoLayer.internalBinaryWrite(message.layers[i], writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        /* string mid = 6; */
        if (message.mid !== '')
            writer.tag(6, runtime.WireType.LengthDelimited).string(message.mid);
        /* bool dtx = 7; */
        if (message.dtx !== false)
            writer.tag(7, runtime.WireType.Varint).bool(message.dtx);
        /* bool stereo = 8; */
        if (message.stereo !== false)
            writer.tag(8, runtime.WireType.Varint).bool(message.stereo);
        /* bool red = 9; */
        if (message.red !== false)
            writer.tag(9, runtime.WireType.Varint).bool(message.red);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.TrackInfo
 */
const TrackInfo = new TrackInfo$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Call$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Call', [
            { no: 1, name: 'type', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'created_by_user_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'host_user_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 5, name: 'custom', kind: 'message', T: () => Struct },
            { no: 6, name: 'created_at', kind: 'message', T: () => Timestamp },
            { no: 7, name: 'updated_at', kind: 'message', T: () => Timestamp },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.type = '';
        message.id = '';
        message.createdByUserId = '';
        message.hostUserId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string type */ 1:
                    message.type = reader.string();
                    break;
                case /* string id */ 2:
                    message.id = reader.string();
                    break;
                case /* string created_by_user_id */ 3:
                    message.createdByUserId = reader.string();
                    break;
                case /* string host_user_id */ 4:
                    message.hostUserId = reader.string();
                    break;
                case /* google.protobuf.Struct custom */ 5:
                    message.custom = Struct.internalBinaryRead(reader, reader.uint32(), options, message.custom);
                    break;
                case /* google.protobuf.Timestamp created_at */ 6:
                    message.createdAt = Timestamp.internalBinaryRead(reader, reader.uint32(), options, message.createdAt);
                    break;
                case /* google.protobuf.Timestamp updated_at */ 7:
                    message.updatedAt = Timestamp.internalBinaryRead(reader, reader.uint32(), options, message.updatedAt);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string type = 1; */
        if (message.type !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.type);
        /* string id = 2; */
        if (message.id !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.id);
        /* string created_by_user_id = 3; */
        if (message.createdByUserId !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.createdByUserId);
        /* string host_user_id = 4; */
        if (message.hostUserId !== '')
            writer.tag(4, runtime.WireType.LengthDelimited).string(message.hostUserId);
        /* google.protobuf.Struct custom = 5; */
        if (message.custom)
            Struct.internalBinaryWrite(message.custom, writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        /* google.protobuf.Timestamp created_at = 6; */
        if (message.createdAt)
            Timestamp.internalBinaryWrite(message.createdAt, writer.tag(6, runtime.WireType.LengthDelimited).fork(), options).join();
        /* google.protobuf.Timestamp updated_at = 7; */
        if (message.updatedAt)
            Timestamp.internalBinaryWrite(message.updatedAt, writer.tag(7, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Call
 */
const Call$1 = new Call$Type();
// @generated message type with reflection information, may provide speed optimized methods
let Error$Type$1 = class Error$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Error', [
            {
                no: 1,
                name: 'code',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ErrorCode',
                    ErrorCode,
                    'ERROR_CODE_',
                ],
            },
            { no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'should_retry', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.code = 0;
        message.message = '';
        message.shouldRetry = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.ErrorCode code */ 1:
                    message.code = reader.int32();
                    break;
                case /* string message */ 2:
                    message.message = reader.string();
                    break;
                case /* bool should_retry */ 3:
                    message.shouldRetry = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.ErrorCode code = 1; */
        if (message.code !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.code);
        /* string message = 2; */
        if (message.message !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.message);
        /* bool should_retry = 3; */
        if (message.shouldRetry !== false)
            writer.tag(3, runtime.WireType.Varint).bool(message.shouldRetry);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
};
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Error
 */
const Error$2 = new Error$Type$1();
// @generated message type with reflection information, may provide speed optimized methods
class ClientDetails$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ClientDetails', [
            { no: 1, name: 'sdk', kind: 'message', T: () => Sdk },
            { no: 2, name: 'os', kind: 'message', T: () => OS },
            { no: 3, name: 'browser', kind: 'message', T: () => Browser },
            { no: 4, name: 'device', kind: 'message', T: () => Device },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Sdk sdk */ 1:
                    message.sdk = Sdk.internalBinaryRead(reader, reader.uint32(), options, message.sdk);
                    break;
                case /* stream.video.sfu.models.OS os */ 2:
                    message.os = OS.internalBinaryRead(reader, reader.uint32(), options, message.os);
                    break;
                case /* stream.video.sfu.models.Browser browser */ 3:
                    message.browser = Browser.internalBinaryRead(reader, reader.uint32(), options, message.browser);
                    break;
                case /* stream.video.sfu.models.Device device */ 4:
                    message.device = Device.internalBinaryRead(reader, reader.uint32(), options, message.device);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Sdk sdk = 1; */
        if (message.sdk)
            Sdk.internalBinaryWrite(message.sdk, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.OS os = 2; */
        if (message.os)
            OS.internalBinaryWrite(message.os, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.Browser browser = 3; */
        if (message.browser)
            Browser.internalBinaryWrite(message.browser, writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.Device device = 4; */
        if (message.device)
            Device.internalBinaryWrite(message.device, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ClientDetails
 */
const ClientDetails = new ClientDetails$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Sdk$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Sdk', [
            {
                no: 1,
                name: 'type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.SdkType', SdkType, 'SDK_TYPE_'],
            },
            { no: 2, name: 'major', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'minor', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: 'patch', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.type = 0;
        message.major = '';
        message.minor = '';
        message.patch = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.SdkType type */ 1:
                    message.type = reader.int32();
                    break;
                case /* string major */ 2:
                    message.major = reader.string();
                    break;
                case /* string minor */ 3:
                    message.minor = reader.string();
                    break;
                case /* string patch */ 4:
                    message.patch = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.SdkType type = 1; */
        if (message.type !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.type);
        /* string major = 2; */
        if (message.major !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.major);
        /* string minor = 3; */
        if (message.minor !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.minor);
        /* string patch = 4; */
        if (message.patch !== '')
            writer.tag(4, runtime.WireType.LengthDelimited).string(message.patch);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Sdk
 */
const Sdk = new Sdk$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OS$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.OS', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'architecture',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.name = '';
        message.version = '';
        message.architecture = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string name */ 1:
                    message.name = reader.string();
                    break;
                case /* string version */ 2:
                    message.version = reader.string();
                    break;
                case /* string architecture */ 3:
                    message.architecture = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string name = 1; */
        if (message.name !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.name);
        /* string version = 2; */
        if (message.version !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.version);
        /* string architecture = 3; */
        if (message.architecture !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.architecture);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.OS
 */
const OS = new OS$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Browser$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Browser', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.name = '';
        message.version = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string name */ 1:
                    message.name = reader.string();
                    break;
                case /* string version */ 2:
                    message.version = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string name = 1; */
        if (message.name !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.name);
        /* string version = 2; */
        if (message.version !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.version);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Browser
 */
const Browser = new Browser$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Device$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Device', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.name = '';
        message.version = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string name */ 1:
                    message.name = reader.string();
                    break;
                case /* string version */ 2:
                    message.version = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string name = 1; */
        if (message.name !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.name);
        /* string version = 2; */
        if (message.version !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.version);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Device
 */
const Device = new Device$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallGrants$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.CallGrants', [
            {
                no: 1,
                name: 'can_publish_audio',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 2,
                name: 'can_publish_video',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 3,
                name: 'can_screenshare',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.canPublishAudio = false;
        message.canPublishVideo = false;
        message.canScreenshare = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* bool can_publish_audio */ 1:
                    message.canPublishAudio = reader.bool();
                    break;
                case /* bool can_publish_video */ 2:
                    message.canPublishVideo = reader.bool();
                    break;
                case /* bool can_screenshare */ 3:
                    message.canScreenshare = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* bool can_publish_audio = 1; */
        if (message.canPublishAudio !== false)
            writer.tag(1, runtime.WireType.Varint).bool(message.canPublishAudio);
        /* bool can_publish_video = 2; */
        if (message.canPublishVideo !== false)
            writer.tag(2, runtime.WireType.Varint).bool(message.canPublishVideo);
        /* bool can_screenshare = 3; */
        if (message.canScreenshare !== false)
            writer.tag(3, runtime.WireType.Varint).bool(message.canScreenshare);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.CallGrants
 */
const CallGrants = new CallGrants$Type();

var models = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Browser: Browser,
    Call: Call$1,
    get CallEndedReason () { return CallEndedReason; },
    CallGrants: CallGrants,
    CallState: CallState$1,
    ClientDetails: ClientDetails,
    Codec: Codec,
    get ConnectionQuality () { return ConnectionQuality; },
    Device: Device,
    Error: Error$2,
    get ErrorCode () { return ErrorCode; },
    get GoAwayReason () { return GoAwayReason; },
    ICETrickle: ICETrickle$1,
    OS: OS,
    Participant: Participant,
    ParticipantCount: ParticipantCount,
    get PeerType () { return PeerType; },
    Pin: Pin,
    Sdk: Sdk,
    get SdkType () { return SdkType; },
    StreamQuality: StreamQuality,
    TrackInfo: TrackInfo,
    get TrackType () { return TrackType; },
    get TrackUnpublishReason () { return TrackUnpublishReason; },
    VideoDimension: VideoDimension,
    VideoLayer: VideoLayer,
    get VideoQuality () { return VideoQuality; },
    get WebsocketReconnectStrategy () { return WebsocketReconnectStrategy; }
});

/* eslint-disable */
// @generated by protobuf-ts 2.9.4 with parameter long_type_string,client_generic,server_none,eslint_disable
// @generated from protobuf file "video/sfu/signal_rpc/signal.proto" (package "stream.video.sfu.signal", syntax proto3)
// tslint:disable
// @generated message type with reflection information, may provide speed optimized methods
class StartNoiseCancellationRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StartNoiseCancellationRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 1:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 1; */
        if (message.sessionId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StartNoiseCancellationRequest
 */
const StartNoiseCancellationRequest = new StartNoiseCancellationRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StartNoiseCancellationResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StartNoiseCancellationResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 1:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 1; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StartNoiseCancellationResponse
 */
const StartNoiseCancellationResponse = new StartNoiseCancellationResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StopNoiseCancellationRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StopNoiseCancellationRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 1:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 1; */
        if (message.sessionId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StopNoiseCancellationRequest
 */
const StopNoiseCancellationRequest = new StopNoiseCancellationRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StopNoiseCancellationResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StopNoiseCancellationResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 1:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 1; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StopNoiseCancellationResponse
 */
const StopNoiseCancellationResponse = new StopNoiseCancellationResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendStatsRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendStatsRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'subscriber_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 3,
                name: 'publisher_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'webrtc_version',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 5, name: 'sdk', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 6,
                name: 'sdk_version',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        message.subscriberStats = '';
        message.publisherStats = '';
        message.webrtcVersion = '';
        message.sdk = '';
        message.sdkVersion = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 1:
                    message.sessionId = reader.string();
                    break;
                case /* string subscriber_stats */ 2:
                    message.subscriberStats = reader.string();
                    break;
                case /* string publisher_stats */ 3:
                    message.publisherStats = reader.string();
                    break;
                case /* string webrtc_version */ 4:
                    message.webrtcVersion = reader.string();
                    break;
                case /* string sdk */ 5:
                    message.sdk = reader.string();
                    break;
                case /* string sdk_version */ 6:
                    message.sdkVersion = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 1; */
        if (message.sessionId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* string subscriber_stats = 2; */
        if (message.subscriberStats !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.subscriberStats);
        /* string publisher_stats = 3; */
        if (message.publisherStats !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.publisherStats);
        /* string webrtc_version = 4; */
        if (message.webrtcVersion !== '')
            writer.tag(4, runtime.WireType.LengthDelimited).string(message.webrtcVersion);
        /* string sdk = 5; */
        if (message.sdk !== '')
            writer.tag(5, runtime.WireType.LengthDelimited).string(message.sdk);
        /* string sdk_version = 6; */
        if (message.sdkVersion !== '')
            writer.tag(6, runtime.WireType.LengthDelimited).string(message.sdkVersion);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendStatsRequest
 */
const SendStatsRequest = new SendStatsRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendStatsResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendStatsResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 1:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 1; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendStatsResponse
 */
const SendStatsResponse = new SendStatsResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestartRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICERestartRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        message.peerType = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 1:
                    message.sessionId = reader.string();
                    break;
                case /* stream.video.sfu.models.PeerType peer_type */ 2:
                    message.peerType = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 1; */
        if (message.sessionId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* stream.video.sfu.models.PeerType peer_type = 2; */
        if (message.peerType !== 0)
            writer.tag(2, runtime.WireType.Varint).int32(message.peerType);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICERestartRequest
 */
const ICERestartRequest = new ICERestartRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestartResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICERestartResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 1:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 1; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICERestartResponse
 */
const ICERestartResponse = new ICERestartResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateMuteStatesRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateMuteStatesRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'mute_states',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackMuteState,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        message.muteStates = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 1:
                    message.sessionId = reader.string();
                    break;
                case /* repeated stream.video.sfu.signal.TrackMuteState mute_states */ 3:
                    message.muteStates.push(TrackMuteState.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 1; */
        if (message.sessionId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* repeated stream.video.sfu.signal.TrackMuteState mute_states = 3; */
        for (let i = 0; i < message.muteStates.length; i++)
            TrackMuteState.internalBinaryWrite(message.muteStates[i], writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateMuteStatesRequest
 */
const UpdateMuteStatesRequest = new UpdateMuteStatesRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateMuteStatesResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateMuteStatesResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateMuteStatesResponse
 */
const UpdateMuteStatesResponse = new UpdateMuteStatesResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackMuteState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.TrackMuteState', [
            {
                no: 1,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 2, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.trackType = 0;
        message.muted = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.TrackType track_type */ 1:
                    message.trackType = reader.int32();
                    break;
                case /* bool muted */ 2:
                    message.muted = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.TrackType track_type = 1; */
        if (message.trackType !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.trackType);
        /* bool muted = 2; */
        if (message.muted !== false)
            writer.tag(2, runtime.WireType.Varint).bool(message.muted);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.TrackMuteState
 */
const TrackMuteState = new TrackMuteState$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioMuteChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.AudioMuteChanged', [
            { no: 1, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.muted = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* bool muted */ 1:
                    message.muted = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* bool muted = 1; */
        if (message.muted !== false)
            writer.tag(1, runtime.WireType.Varint).bool(message.muted);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.AudioMuteChanged
 */
new AudioMuteChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoMuteChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.VideoMuteChanged', [
            { no: 2, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.muted = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* bool muted */ 2:
                    message.muted = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* bool muted = 2; */
        if (message.muted !== false)
            writer.tag(2, runtime.WireType.Varint).bool(message.muted);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.VideoMuteChanged
 */
new VideoMuteChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateSubscriptionsRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateSubscriptionsRequest', [
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackSubscriptionDetails,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sessionId = '';
        message.tracks = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* repeated stream.video.sfu.signal.TrackSubscriptionDetails tracks */ 3:
                    message.tracks.push(TrackSubscriptionDetails.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* repeated stream.video.sfu.signal.TrackSubscriptionDetails tracks = 3; */
        for (let i = 0; i < message.tracks.length; i++)
            TrackSubscriptionDetails.internalBinaryWrite(message.tracks[i], writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateSubscriptionsRequest
 */
const UpdateSubscriptionsRequest = new UpdateSubscriptionsRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateSubscriptionsResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateSubscriptionsResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateSubscriptionsResponse
 */
const UpdateSubscriptionsResponse = new UpdateSubscriptionsResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackSubscriptionDetails$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.TrackSubscriptionDetails', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'dimension', kind: 'message', T: () => VideoDimension },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.trackType = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* stream.video.sfu.models.TrackType track_type */ 3:
                    message.trackType = reader.int32();
                    break;
                case /* stream.video.sfu.models.VideoDimension dimension */ 4:
                    message.dimension = VideoDimension.internalBinaryRead(reader, reader.uint32(), options, message.dimension);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* stream.video.sfu.models.TrackType track_type = 3; */
        if (message.trackType !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.trackType);
        /* stream.video.sfu.models.VideoDimension dimension = 4; */
        if (message.dimension)
            VideoDimension.internalBinaryWrite(message.dimension, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.TrackSubscriptionDetails
 */
const TrackSubscriptionDetails = new TrackSubscriptionDetails$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendAnswerRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendAnswerRequest', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            { no: 2, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.peerType = 0;
        message.sdp = '';
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.PeerType peer_type */ 1:
                    message.peerType = reader.int32();
                    break;
                case /* string sdp */ 2:
                    message.sdp = reader.string();
                    break;
                case /* string session_id */ 3:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.PeerType peer_type = 1; */
        if (message.peerType !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.peerType);
        /* string sdp = 2; */
        if (message.sdp !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sdp);
        /* string session_id = 3; */
        if (message.sessionId !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendAnswerRequest
 */
const SendAnswerRequest = new SendAnswerRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendAnswerResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendAnswerResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendAnswerResponse
 */
const SendAnswerResponse = new SendAnswerResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICETrickleResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICETrickleResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICETrickleResponse
 */
const ICETrickleResponse = new ICETrickleResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SetPublisherRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SetPublisherRequest', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackInfo,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sdp = '';
        message.sessionId = '';
        message.tracks = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string sdp */ 1:
                    message.sdp = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* repeated stream.video.sfu.models.TrackInfo tracks */ 3:
                    message.tracks.push(TrackInfo.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string sdp = 1; */
        if (message.sdp !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sdp);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* repeated stream.video.sfu.models.TrackInfo tracks = 3; */
        for (let i = 0; i < message.tracks.length; i++)
            TrackInfo.internalBinaryWrite(message.tracks[i], writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SetPublisherRequest
 */
const SetPublisherRequest = new SetPublisherRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SetPublisherResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SetPublisherResponse', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'ice_restart', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sdp = '';
        message.sessionId = '';
        message.iceRestart = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string sdp */ 1:
                    message.sdp = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* bool ice_restart */ 3:
                    message.iceRestart = reader.bool();
                    break;
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string sdp = 1; */
        if (message.sdp !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sdp);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* bool ice_restart = 3; */
        if (message.iceRestart !== false)
            writer.tag(3, runtime.WireType.Varint).bool(message.iceRestart);
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SetPublisherResponse
 */
const SetPublisherResponse = new SetPublisherResponse$Type();
/**
 * @generated ServiceType for protobuf service stream.video.sfu.signal.SignalServer
 */
const SignalServer = new runtimeRpc.ServiceType('stream.video.sfu.signal.SignalServer', [
    {
        name: 'SetPublisher',
        options: {},
        I: SetPublisherRequest,
        O: SetPublisherResponse,
    },
    {
        name: 'SendAnswer',
        options: {},
        I: SendAnswerRequest,
        O: SendAnswerResponse,
    },
    { name: 'IceTrickle', options: {}, I: ICETrickle$1, O: ICETrickleResponse },
    {
        name: 'UpdateSubscriptions',
        options: {},
        I: UpdateSubscriptionsRequest,
        O: UpdateSubscriptionsResponse,
    },
    {
        name: 'UpdateMuteStates',
        options: {},
        I: UpdateMuteStatesRequest,
        O: UpdateMuteStatesResponse,
    },
    {
        name: 'IceRestart',
        options: {},
        I: ICERestartRequest,
        O: ICERestartResponse,
    },
    {
        name: 'SendStats',
        options: {},
        I: SendStatsRequest,
        O: SendStatsResponse,
    },
    {
        name: 'StartNoiseCancellation',
        options: {},
        I: StartNoiseCancellationRequest,
        O: StartNoiseCancellationResponse,
    },
    {
        name: 'StopNoiseCancellation',
        options: {},
        I: StopNoiseCancellationRequest,
        O: StopNoiseCancellationResponse,
    },
]);

/**
 * @generated from protobuf enum stream.video.sfu.event.VideoLayerSetting.Priority
 */
var VideoLayerSetting_Priority;
(function (VideoLayerSetting_Priority) {
    /**
     * @generated from protobuf enum value: PRIORITY_HIGH_UNSPECIFIED = 0;
     */
    VideoLayerSetting_Priority[VideoLayerSetting_Priority["HIGH_UNSPECIFIED"] = 0] = "HIGH_UNSPECIFIED";
    /**
     * @generated from protobuf enum value: PRIORITY_LOW = 1;
     */
    VideoLayerSetting_Priority[VideoLayerSetting_Priority["LOW"] = 1] = "LOW";
    /**
     * @generated from protobuf enum value: PRIORITY_MEDIUM = 2;
     */
    VideoLayerSetting_Priority[VideoLayerSetting_Priority["MEDIUM"] = 2] = "MEDIUM";
    /**
     * @generated from protobuf enum value: PRIORITY_VERY_LOW = 3;
     */
    VideoLayerSetting_Priority[VideoLayerSetting_Priority["VERY_LOW"] = 3] = "VERY_LOW";
})(VideoLayerSetting_Priority || (VideoLayerSetting_Priority = {}));
// @generated message type with reflection information, may provide speed optimized methods
class SfuEvent$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SfuEvent', [
            {
                no: 1,
                name: 'subscriber_offer',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => SubscriberOffer,
            },
            {
                no: 2,
                name: 'publisher_answer',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => PublisherAnswer,
            },
            {
                no: 3,
                name: 'connection_quality_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ConnectionQualityChanged,
            },
            {
                no: 4,
                name: 'audio_level_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => AudioLevelChanged,
            },
            {
                no: 5,
                name: 'ice_trickle',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ICETrickle$1,
            },
            {
                no: 6,
                name: 'change_publish_quality',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ChangePublishQuality,
            },
            {
                no: 10,
                name: 'participant_joined',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantJoined,
            },
            {
                no: 11,
                name: 'participant_left',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantLeft,
            },
            {
                no: 12,
                name: 'dominant_speaker_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => DominantSpeakerChanged,
            },
            {
                no: 13,
                name: 'join_response',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => JoinResponse,
            },
            {
                no: 14,
                name: 'health_check_response',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => HealthCheckResponse,
            },
            {
                no: 16,
                name: 'track_published',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => TrackPublished,
            },
            {
                no: 17,
                name: 'track_unpublished',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => TrackUnpublished,
            },
            {
                no: 18,
                name: 'error',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => Error$1,
            },
            {
                no: 19,
                name: 'call_grants_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => CallGrantsUpdated,
            },
            {
                no: 20,
                name: 'go_away',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => GoAway,
            },
            {
                no: 21,
                name: 'ice_restart',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ICERestart,
            },
            {
                no: 22,
                name: 'pins_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => PinsChanged,
            },
            {
                no: 23,
                name: 'call_ended',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => CallEnded,
            },
            {
                no: 24,
                name: 'participant_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantUpdated,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.eventPayload = { oneofKind: undefined };
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.event.SubscriberOffer subscriber_offer */ 1:
                    message.eventPayload = {
                        oneofKind: 'subscriberOffer',
                        subscriberOffer: SubscriberOffer.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.subscriberOffer),
                    };
                    break;
                case /* stream.video.sfu.event.PublisherAnswer publisher_answer */ 2:
                    message.eventPayload = {
                        oneofKind: 'publisherAnswer',
                        publisherAnswer: PublisherAnswer.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.publisherAnswer),
                    };
                    break;
                case /* stream.video.sfu.event.ConnectionQualityChanged connection_quality_changed */ 3:
                    message.eventPayload = {
                        oneofKind: 'connectionQualityChanged',
                        connectionQualityChanged: ConnectionQualityChanged.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.connectionQualityChanged),
                    };
                    break;
                case /* stream.video.sfu.event.AudioLevelChanged audio_level_changed */ 4:
                    message.eventPayload = {
                        oneofKind: 'audioLevelChanged',
                        audioLevelChanged: AudioLevelChanged.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.audioLevelChanged),
                    };
                    break;
                case /* stream.video.sfu.models.ICETrickle ice_trickle */ 5:
                    message.eventPayload = {
                        oneofKind: 'iceTrickle',
                        iceTrickle: ICETrickle$1.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.iceTrickle),
                    };
                    break;
                case /* stream.video.sfu.event.ChangePublishQuality change_publish_quality */ 6:
                    message.eventPayload = {
                        oneofKind: 'changePublishQuality',
                        changePublishQuality: ChangePublishQuality.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.changePublishQuality),
                    };
                    break;
                case /* stream.video.sfu.event.ParticipantJoined participant_joined */ 10:
                    message.eventPayload = {
                        oneofKind: 'participantJoined',
                        participantJoined: ParticipantJoined.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.participantJoined),
                    };
                    break;
                case /* stream.video.sfu.event.ParticipantLeft participant_left */ 11:
                    message.eventPayload = {
                        oneofKind: 'participantLeft',
                        participantLeft: ParticipantLeft.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.participantLeft),
                    };
                    break;
                case /* stream.video.sfu.event.DominantSpeakerChanged dominant_speaker_changed */ 12:
                    message.eventPayload = {
                        oneofKind: 'dominantSpeakerChanged',
                        dominantSpeakerChanged: DominantSpeakerChanged.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.dominantSpeakerChanged),
                    };
                    break;
                case /* stream.video.sfu.event.JoinResponse join_response */ 13:
                    message.eventPayload = {
                        oneofKind: 'joinResponse',
                        joinResponse: JoinResponse.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.joinResponse),
                    };
                    break;
                case /* stream.video.sfu.event.HealthCheckResponse health_check_response */ 14:
                    message.eventPayload = {
                        oneofKind: 'healthCheckResponse',
                        healthCheckResponse: HealthCheckResponse.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.healthCheckResponse),
                    };
                    break;
                case /* stream.video.sfu.event.TrackPublished track_published */ 16:
                    message.eventPayload = {
                        oneofKind: 'trackPublished',
                        trackPublished: TrackPublished.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.trackPublished),
                    };
                    break;
                case /* stream.video.sfu.event.TrackUnpublished track_unpublished */ 17:
                    message.eventPayload = {
                        oneofKind: 'trackUnpublished',
                        trackUnpublished: TrackUnpublished.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.trackUnpublished),
                    };
                    break;
                case /* stream.video.sfu.event.Error error */ 18:
                    message.eventPayload = {
                        oneofKind: 'error',
                        error: Error$1.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.error),
                    };
                    break;
                case /* stream.video.sfu.event.CallGrantsUpdated call_grants_updated */ 19:
                    message.eventPayload = {
                        oneofKind: 'callGrantsUpdated',
                        callGrantsUpdated: CallGrantsUpdated.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.callGrantsUpdated),
                    };
                    break;
                case /* stream.video.sfu.event.GoAway go_away */ 20:
                    message.eventPayload = {
                        oneofKind: 'goAway',
                        goAway: GoAway.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.goAway),
                    };
                    break;
                case /* stream.video.sfu.event.ICERestart ice_restart */ 21:
                    message.eventPayload = {
                        oneofKind: 'iceRestart',
                        iceRestart: ICERestart.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.iceRestart),
                    };
                    break;
                case /* stream.video.sfu.event.PinsChanged pins_updated */ 22:
                    message.eventPayload = {
                        oneofKind: 'pinsUpdated',
                        pinsUpdated: PinsChanged.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.pinsUpdated),
                    };
                    break;
                case /* stream.video.sfu.event.CallEnded call_ended */ 23:
                    message.eventPayload = {
                        oneofKind: 'callEnded',
                        callEnded: CallEnded.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.callEnded),
                    };
                    break;
                case /* stream.video.sfu.event.ParticipantUpdated participant_updated */ 24:
                    message.eventPayload = {
                        oneofKind: 'participantUpdated',
                        participantUpdated: ParticipantUpdated.internalBinaryRead(reader, reader.uint32(), options, message.eventPayload.participantUpdated),
                    };
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.event.SubscriberOffer subscriber_offer = 1; */
        if (message.eventPayload.oneofKind === 'subscriberOffer')
            SubscriberOffer.internalBinaryWrite(message.eventPayload.subscriberOffer, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.PublisherAnswer publisher_answer = 2; */
        if (message.eventPayload.oneofKind === 'publisherAnswer')
            PublisherAnswer.internalBinaryWrite(message.eventPayload.publisherAnswer, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ConnectionQualityChanged connection_quality_changed = 3; */
        if (message.eventPayload.oneofKind === 'connectionQualityChanged')
            ConnectionQualityChanged.internalBinaryWrite(message.eventPayload.connectionQualityChanged, writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.AudioLevelChanged audio_level_changed = 4; */
        if (message.eventPayload.oneofKind === 'audioLevelChanged')
            AudioLevelChanged.internalBinaryWrite(message.eventPayload.audioLevelChanged, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.ICETrickle ice_trickle = 5; */
        if (message.eventPayload.oneofKind === 'iceTrickle')
            ICETrickle$1.internalBinaryWrite(message.eventPayload.iceTrickle, writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ChangePublishQuality change_publish_quality = 6; */
        if (message.eventPayload.oneofKind === 'changePublishQuality')
            ChangePublishQuality.internalBinaryWrite(message.eventPayload.changePublishQuality, writer.tag(6, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ParticipantJoined participant_joined = 10; */
        if (message.eventPayload.oneofKind === 'participantJoined')
            ParticipantJoined.internalBinaryWrite(message.eventPayload.participantJoined, writer.tag(10, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ParticipantLeft participant_left = 11; */
        if (message.eventPayload.oneofKind === 'participantLeft')
            ParticipantLeft.internalBinaryWrite(message.eventPayload.participantLeft, writer.tag(11, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.DominantSpeakerChanged dominant_speaker_changed = 12; */
        if (message.eventPayload.oneofKind === 'dominantSpeakerChanged')
            DominantSpeakerChanged.internalBinaryWrite(message.eventPayload.dominantSpeakerChanged, writer.tag(12, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.JoinResponse join_response = 13; */
        if (message.eventPayload.oneofKind === 'joinResponse')
            JoinResponse.internalBinaryWrite(message.eventPayload.joinResponse, writer.tag(13, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.HealthCheckResponse health_check_response = 14; */
        if (message.eventPayload.oneofKind === 'healthCheckResponse')
            HealthCheckResponse.internalBinaryWrite(message.eventPayload.healthCheckResponse, writer.tag(14, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.TrackPublished track_published = 16; */
        if (message.eventPayload.oneofKind === 'trackPublished')
            TrackPublished.internalBinaryWrite(message.eventPayload.trackPublished, writer.tag(16, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.TrackUnpublished track_unpublished = 17; */
        if (message.eventPayload.oneofKind === 'trackUnpublished')
            TrackUnpublished.internalBinaryWrite(message.eventPayload.trackUnpublished, writer.tag(17, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.Error error = 18; */
        if (message.eventPayload.oneofKind === 'error')
            Error$1.internalBinaryWrite(message.eventPayload.error, writer.tag(18, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.CallGrantsUpdated call_grants_updated = 19; */
        if (message.eventPayload.oneofKind === 'callGrantsUpdated')
            CallGrantsUpdated.internalBinaryWrite(message.eventPayload.callGrantsUpdated, writer.tag(19, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.GoAway go_away = 20; */
        if (message.eventPayload.oneofKind === 'goAway')
            GoAway.internalBinaryWrite(message.eventPayload.goAway, writer.tag(20, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ICERestart ice_restart = 21; */
        if (message.eventPayload.oneofKind === 'iceRestart')
            ICERestart.internalBinaryWrite(message.eventPayload.iceRestart, writer.tag(21, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.PinsChanged pins_updated = 22; */
        if (message.eventPayload.oneofKind === 'pinsUpdated')
            PinsChanged.internalBinaryWrite(message.eventPayload.pinsUpdated, writer.tag(22, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.CallEnded call_ended = 23; */
        if (message.eventPayload.oneofKind === 'callEnded')
            CallEnded.internalBinaryWrite(message.eventPayload.callEnded, writer.tag(23, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.ParticipantUpdated participant_updated = 24; */
        if (message.eventPayload.oneofKind === 'participantUpdated')
            ParticipantUpdated.internalBinaryWrite(message.eventPayload.participantUpdated, writer.tag(24, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SfuEvent
 */
const SfuEvent = new SfuEvent$Type();
// @generated message type with reflection information, may provide speed optimized methods
class PinsChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.PinsChanged', [
            {
                no: 1,
                name: 'pins',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Pin,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.pins = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated stream.video.sfu.models.Pin pins */ 1:
                    message.pins.push(Pin.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated stream.video.sfu.models.Pin pins = 1; */
        for (let i = 0; i < message.pins.length; i++)
            Pin.internalBinaryWrite(message.pins[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.PinsChanged
 */
const PinsChanged = new PinsChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Error$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.Error', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
            {
                no: 5,
                name: 'reconnect_strategy',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.WebsocketReconnectStrategy',
                    WebsocketReconnectStrategy,
                    'WEBSOCKET_RECONNECT_STRATEGY_',
                ],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.reconnectStrategy = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.Error error */ 4:
                    message.error = Error$2.internalBinaryRead(reader, reader.uint32(), options, message.error);
                    break;
                case /* stream.video.sfu.models.WebsocketReconnectStrategy reconnect_strategy */ 5:
                    message.reconnectStrategy = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.Error error = 4; */
        if (message.error)
            Error$2.internalBinaryWrite(message.error, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.WebsocketReconnectStrategy reconnect_strategy = 5; */
        if (message.reconnectStrategy !== 0)
            writer.tag(5, runtime.WireType.Varint).int32(message.reconnectStrategy);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.Error
 */
const Error$1 = new Error$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICETrickle$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ICETrickle', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            {
                no: 2,
                name: 'ice_candidate',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.peerType = 0;
        message.iceCandidate = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.PeerType peer_type */ 1:
                    message.peerType = reader.int32();
                    break;
                case /* string ice_candidate */ 2:
                    message.iceCandidate = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.PeerType peer_type = 1; */
        if (message.peerType !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.peerType);
        /* string ice_candidate = 2; */
        if (message.iceCandidate !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.iceCandidate);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ICETrickle
 */
const ICETrickle = new ICETrickle$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestart$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ICERestart', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.peerType = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.PeerType peer_type */ 1:
                    message.peerType = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.PeerType peer_type = 1; */
        if (message.peerType !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.peerType);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ICERestart
 */
const ICERestart = new ICERestart$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SfuRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SfuRequest', [
            {
                no: 1,
                name: 'join_request',
                kind: 'message',
                oneof: 'requestPayload',
                T: () => JoinRequest,
            },
            {
                no: 2,
                name: 'health_check_request',
                kind: 'message',
                oneof: 'requestPayload',
                T: () => HealthCheckRequest,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.requestPayload = { oneofKind: undefined };
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.event.JoinRequest join_request */ 1:
                    message.requestPayload = {
                        oneofKind: 'joinRequest',
                        joinRequest: JoinRequest.internalBinaryRead(reader, reader.uint32(), options, message.requestPayload.joinRequest),
                    };
                    break;
                case /* stream.video.sfu.event.HealthCheckRequest health_check_request */ 2:
                    message.requestPayload = {
                        oneofKind: 'healthCheckRequest',
                        healthCheckRequest: HealthCheckRequest.internalBinaryRead(reader, reader.uint32(), options, message.requestPayload.healthCheckRequest),
                    };
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.event.JoinRequest join_request = 1; */
        if (message.requestPayload.oneofKind === 'joinRequest')
            JoinRequest.internalBinaryWrite(message.requestPayload.joinRequest, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.HealthCheckRequest health_check_request = 2; */
        if (message.requestPayload.oneofKind === 'healthCheckRequest')
            HealthCheckRequest.internalBinaryWrite(message.requestPayload.healthCheckRequest, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SfuRequest
 */
const SfuRequest = new SfuRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class HealthCheckRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.HealthCheckRequest', []);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        return target ?? this.create();
    }
    internalBinaryWrite(message, writer, options) {
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.HealthCheckRequest
 */
const HealthCheckRequest = new HealthCheckRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class HealthCheckResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.HealthCheckResponse', [
            {
                no: 1,
                name: 'participant_count',
                kind: 'message',
                T: () => ParticipantCount,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.ParticipantCount participant_count */ 1:
                    message.participantCount = ParticipantCount.internalBinaryRead(reader, reader.uint32(), options, message.participantCount);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.ParticipantCount participant_count = 1; */
        if (message.participantCount)
            ParticipantCount.internalBinaryWrite(message.participantCount, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.HealthCheckResponse
 */
const HealthCheckResponse = new HealthCheckResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackPublished$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.TrackPublished', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.type = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* stream.video.sfu.models.TrackType type */ 3:
                    message.type = reader.int32();
                    break;
                case /* stream.video.sfu.models.Participant participant */ 4:
                    message.participant = Participant.internalBinaryRead(reader, reader.uint32(), options, message.participant);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* stream.video.sfu.models.TrackType type = 3; */
        if (message.type !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.type);
        /* stream.video.sfu.models.Participant participant = 4; */
        if (message.participant)
            Participant.internalBinaryWrite(message.participant, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.TrackPublished
 */
const TrackPublished = new TrackPublished$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackUnpublished$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.TrackUnpublished', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 4,
                name: 'cause',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackUnpublishReason',
                    TrackUnpublishReason,
                    'TRACK_UNPUBLISH_REASON_',
                ],
            },
            { no: 5, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.type = 0;
        message.cause = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* stream.video.sfu.models.TrackType type */ 3:
                    message.type = reader.int32();
                    break;
                case /* stream.video.sfu.models.TrackUnpublishReason cause */ 4:
                    message.cause = reader.int32();
                    break;
                case /* stream.video.sfu.models.Participant participant */ 5:
                    message.participant = Participant.internalBinaryRead(reader, reader.uint32(), options, message.participant);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* stream.video.sfu.models.TrackType type = 3; */
        if (message.type !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.type);
        /* stream.video.sfu.models.TrackUnpublishReason cause = 4; */
        if (message.cause !== 0)
            writer.tag(4, runtime.WireType.Varint).int32(message.cause);
        /* stream.video.sfu.models.Participant participant = 5; */
        if (message.participant)
            Participant.internalBinaryWrite(message.participant, writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.TrackUnpublished
 */
const TrackUnpublished = new TrackUnpublished$Type();
// @generated message type with reflection information, may provide speed optimized methods
class JoinRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.JoinRequest', [
            { no: 1, name: 'token', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'subscriber_sdp',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'client_details',
                kind: 'message',
                T: () => ClientDetails,
            },
            { no: 5, name: 'migration', kind: 'message', T: () => Migration },
            {
                no: 6,
                name: 'fast_reconnect',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.token = '';
        message.sessionId = '';
        message.subscriberSdp = '';
        message.fastReconnect = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string token */ 1:
                    message.token = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* string subscriber_sdp */ 3:
                    message.subscriberSdp = reader.string();
                    break;
                case /* stream.video.sfu.models.ClientDetails client_details */ 4:
                    message.clientDetails = ClientDetails.internalBinaryRead(reader, reader.uint32(), options, message.clientDetails);
                    break;
                case /* stream.video.sfu.event.Migration migration */ 5:
                    message.migration = Migration.internalBinaryRead(reader, reader.uint32(), options, message.migration);
                    break;
                case /* bool fast_reconnect */ 6:
                    message.fastReconnect = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string token = 1; */
        if (message.token !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.token);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* string subscriber_sdp = 3; */
        if (message.subscriberSdp !== '')
            writer.tag(3, runtime.WireType.LengthDelimited).string(message.subscriberSdp);
        /* stream.video.sfu.models.ClientDetails client_details = 4; */
        if (message.clientDetails)
            ClientDetails.internalBinaryWrite(message.clientDetails, writer.tag(4, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.event.Migration migration = 5; */
        if (message.migration)
            Migration.internalBinaryWrite(message.migration, writer.tag(5, runtime.WireType.LengthDelimited).fork(), options).join();
        /* bool fast_reconnect = 6; */
        if (message.fastReconnect !== false)
            writer.tag(6, runtime.WireType.Varint).bool(message.fastReconnect);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.JoinRequest
 */
const JoinRequest = new JoinRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Migration$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.Migration', [
            {
                no: 1,
                name: 'from_sfu_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 2,
                name: 'announced_tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackInfo,
            },
            {
                no: 3,
                name: 'subscriptions',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackSubscriptionDetails,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.fromSfuId = '';
        message.announcedTracks = [];
        message.subscriptions = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string from_sfu_id */ 1:
                    message.fromSfuId = reader.string();
                    break;
                case /* repeated stream.video.sfu.models.TrackInfo announced_tracks */ 2:
                    message.announcedTracks.push(TrackInfo.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* repeated stream.video.sfu.signal.TrackSubscriptionDetails subscriptions */ 3:
                    message.subscriptions.push(TrackSubscriptionDetails.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string from_sfu_id = 1; */
        if (message.fromSfuId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.fromSfuId);
        /* repeated stream.video.sfu.models.TrackInfo announced_tracks = 2; */
        for (let i = 0; i < message.announcedTracks.length; i++)
            TrackInfo.internalBinaryWrite(message.announcedTracks[i], writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* repeated stream.video.sfu.signal.TrackSubscriptionDetails subscriptions = 3; */
        for (let i = 0; i < message.subscriptions.length; i++)
            TrackSubscriptionDetails.internalBinaryWrite(message.subscriptions[i], writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.Migration
 */
const Migration = new Migration$Type();
// @generated message type with reflection information, may provide speed optimized methods
class JoinResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.JoinResponse', [
            { no: 1, name: 'call_state', kind: 'message', T: () => CallState$1 },
            { no: 2, name: 'reconnected', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.reconnected = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.CallState call_state */ 1:
                    message.callState = CallState$1.internalBinaryRead(reader, reader.uint32(), options, message.callState);
                    break;
                case /* bool reconnected */ 2:
                    message.reconnected = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.CallState call_state = 1; */
        if (message.callState)
            CallState$1.internalBinaryWrite(message.callState, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* bool reconnected = 2; */
        if (message.reconnected !== false)
            writer.tag(2, runtime.WireType.Varint).bool(message.reconnected);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.JoinResponse
 */
const JoinResponse = new JoinResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantJoined$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantJoined', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.callCid = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string call_cid */ 1:
                    message.callCid = reader.string();
                    break;
                case /* stream.video.sfu.models.Participant participant */ 2:
                    message.participant = Participant.internalBinaryRead(reader, reader.uint32(), options, message.participant);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string call_cid = 1; */
        if (message.callCid !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.callCid);
        /* stream.video.sfu.models.Participant participant = 2; */
        if (message.participant)
            Participant.internalBinaryWrite(message.participant, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantJoined
 */
const ParticipantJoined = new ParticipantJoined$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantLeft$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantLeft', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.callCid = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string call_cid */ 1:
                    message.callCid = reader.string();
                    break;
                case /* stream.video.sfu.models.Participant participant */ 2:
                    message.participant = Participant.internalBinaryRead(reader, reader.uint32(), options, message.participant);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string call_cid = 1; */
        if (message.callCid !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.callCid);
        /* stream.video.sfu.models.Participant participant = 2; */
        if (message.participant)
            Participant.internalBinaryWrite(message.participant, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantLeft
 */
const ParticipantLeft = new ParticipantLeft$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantUpdated$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantUpdated', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.callCid = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string call_cid */ 1:
                    message.callCid = reader.string();
                    break;
                case /* stream.video.sfu.models.Participant participant */ 2:
                    message.participant = Participant.internalBinaryRead(reader, reader.uint32(), options, message.participant);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string call_cid = 1; */
        if (message.callCid !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.callCid);
        /* stream.video.sfu.models.Participant participant = 2; */
        if (message.participant)
            Participant.internalBinaryWrite(message.participant, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantUpdated
 */
const ParticipantUpdated = new ParticipantUpdated$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SubscriberOffer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SubscriberOffer', [
            { no: 1, name: 'ice_restart', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 2, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.iceRestart = false;
        message.sdp = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* bool ice_restart */ 1:
                    message.iceRestart = reader.bool();
                    break;
                case /* string sdp */ 2:
                    message.sdp = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* bool ice_restart = 1; */
        if (message.iceRestart !== false)
            writer.tag(1, runtime.WireType.Varint).bool(message.iceRestart);
        /* string sdp = 2; */
        if (message.sdp !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sdp);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SubscriberOffer
 */
const SubscriberOffer = new SubscriberOffer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class PublisherAnswer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.PublisherAnswer', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.sdp = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string sdp */ 1:
                    message.sdp = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string sdp = 1; */
        if (message.sdp !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.sdp);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.PublisherAnswer
 */
const PublisherAnswer = new PublisherAnswer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ConnectionQualityChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ConnectionQualityChanged', [
            {
                no: 1,
                name: 'connection_quality_updates',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => ConnectionQualityInfo,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.connectionQualityUpdates = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated stream.video.sfu.event.ConnectionQualityInfo connection_quality_updates */ 1:
                    message.connectionQualityUpdates.push(ConnectionQualityInfo.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated stream.video.sfu.event.ConnectionQualityInfo connection_quality_updates = 1; */
        for (let i = 0; i < message.connectionQualityUpdates.length; i++)
            ConnectionQualityInfo.internalBinaryWrite(message.connectionQualityUpdates[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ConnectionQualityChanged
 */
const ConnectionQualityChanged = new ConnectionQualityChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ConnectionQualityInfo$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ConnectionQualityInfo', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'connection_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ConnectionQuality',
                    ConnectionQuality,
                    'CONNECTION_QUALITY_',
                ],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.connectionQuality = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* stream.video.sfu.models.ConnectionQuality connection_quality */ 3:
                    message.connectionQuality = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* stream.video.sfu.models.ConnectionQuality connection_quality = 3; */
        if (message.connectionQuality !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.connectionQuality);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ConnectionQualityInfo
 */
const ConnectionQualityInfo = new ConnectionQualityInfo$Type();
// @generated message type with reflection information, may provide speed optimized methods
class DominantSpeakerChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.DominantSpeakerChanged', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.DominantSpeakerChanged
 */
const DominantSpeakerChanged = new DominantSpeakerChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioLevel$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioLevel', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'level', kind: 'scalar', T: 2 /*ScalarType.FLOAT*/ },
            { no: 4, name: 'is_speaking', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.userId = '';
        message.sessionId = '';
        message.level = 0;
        message.isSpeaking = false;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string user_id */ 1:
                    message.userId = reader.string();
                    break;
                case /* string session_id */ 2:
                    message.sessionId = reader.string();
                    break;
                case /* float level */ 3:
                    message.level = reader.float();
                    break;
                case /* bool is_speaking */ 4:
                    message.isSpeaking = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string user_id = 1; */
        if (message.userId !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.userId);
        /* string session_id = 2; */
        if (message.sessionId !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.sessionId);
        /* float level = 3; */
        if (message.level !== 0)
            writer.tag(3, runtime.WireType.Bit32).float(message.level);
        /* bool is_speaking = 4; */
        if (message.isSpeaking !== false)
            writer.tag(4, runtime.WireType.Varint).bool(message.isSpeaking);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioLevel
 */
const AudioLevel = new AudioLevel$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioLevelChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioLevelChanged', [
            {
                no: 1,
                name: 'audio_levels',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => AudioLevel,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.audioLevels = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated stream.video.sfu.event.AudioLevel audio_levels */ 1:
                    message.audioLevels.push(AudioLevel.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated stream.video.sfu.event.AudioLevel audio_levels = 1; */
        for (let i = 0; i < message.audioLevels.length; i++)
            AudioLevel.internalBinaryWrite(message.audioLevels[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioLevelChanged
 */
const AudioLevelChanged = new AudioLevelChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioMediaRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioMediaRequest', [
            {
                no: 1,
                name: 'channel_count',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.channelCount = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* int32 channel_count */ 1:
                    message.channelCount = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* int32 channel_count = 1; */
        if (message.channelCount !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.channelCount);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioMediaRequest
 */
const AudioMediaRequest = new AudioMediaRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioSender$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioSender', [
            {
                no: 1,
                name: 'media_request',
                kind: 'message',
                T: () => AudioMediaRequest,
            },
            { no: 2, name: 'codec', kind: 'message', T: () => Codec },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.event.AudioMediaRequest media_request */ 1:
                    message.mediaRequest = AudioMediaRequest.internalBinaryRead(reader, reader.uint32(), options, message.mediaRequest);
                    break;
                case /* stream.video.sfu.models.Codec codec */ 2:
                    message.codec = Codec.internalBinaryRead(reader, reader.uint32(), options, message.codec);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.event.AudioMediaRequest media_request = 1; */
        if (message.mediaRequest)
            AudioMediaRequest.internalBinaryWrite(message.mediaRequest, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.Codec codec = 2; */
        if (message.codec)
            Codec.internalBinaryWrite(message.codec, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioSender
 */
const AudioSender = new AudioSender$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoMediaRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.VideoMediaRequest', [
            {
                no: 1,
                name: 'ideal_height',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
            { no: 2, name: 'ideal_width', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
            {
                no: 3,
                name: 'ideal_frame_rate',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.idealHeight = 0;
        message.idealWidth = 0;
        message.idealFrameRate = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* int32 ideal_height */ 1:
                    message.idealHeight = reader.int32();
                    break;
                case /* int32 ideal_width */ 2:
                    message.idealWidth = reader.int32();
                    break;
                case /* int32 ideal_frame_rate */ 3:
                    message.idealFrameRate = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* int32 ideal_height = 1; */
        if (message.idealHeight !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.idealHeight);
        /* int32 ideal_width = 2; */
        if (message.idealWidth !== 0)
            writer.tag(2, runtime.WireType.Varint).int32(message.idealWidth);
        /* int32 ideal_frame_rate = 3; */
        if (message.idealFrameRate !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.idealFrameRate);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.VideoMediaRequest
 */
const VideoMediaRequest = new VideoMediaRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoLayerSetting$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.VideoLayerSetting', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'active', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 3, name: 'max_bitrate', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
            {
                no: 4,
                name: 'scale_resolution_down_by',
                kind: 'scalar',
                T: 2 /*ScalarType.FLOAT*/,
            },
            {
                no: 5,
                name: 'priority',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.event.VideoLayerSetting.Priority',
                    VideoLayerSetting_Priority,
                    'PRIORITY_',
                ],
            },
            { no: 6, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 7,
                name: 'max_framerate',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.name = '';
        message.active = false;
        message.maxBitrate = 0;
        message.scaleResolutionDownBy = 0;
        message.priority = 0;
        message.maxFramerate = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string name */ 1:
                    message.name = reader.string();
                    break;
                case /* bool active */ 2:
                    message.active = reader.bool();
                    break;
                case /* int32 max_bitrate */ 3:
                    message.maxBitrate = reader.int32();
                    break;
                case /* float scale_resolution_down_by */ 4:
                    message.scaleResolutionDownBy = reader.float();
                    break;
                case /* stream.video.sfu.event.VideoLayerSetting.Priority priority */ 5:
                    message.priority = reader.int32();
                    break;
                case /* stream.video.sfu.models.Codec codec */ 6:
                    message.codec = Codec.internalBinaryRead(reader, reader.uint32(), options, message.codec);
                    break;
                case /* uint32 max_framerate */ 7:
                    message.maxFramerate = reader.uint32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string name = 1; */
        if (message.name !== '')
            writer.tag(1, runtime.WireType.LengthDelimited).string(message.name);
        /* bool active = 2; */
        if (message.active !== false)
            writer.tag(2, runtime.WireType.Varint).bool(message.active);
        /* int32 max_bitrate = 3; */
        if (message.maxBitrate !== 0)
            writer.tag(3, runtime.WireType.Varint).int32(message.maxBitrate);
        /* float scale_resolution_down_by = 4; */
        if (message.scaleResolutionDownBy !== 0)
            writer.tag(4, runtime.WireType.Bit32).float(message.scaleResolutionDownBy);
        /* stream.video.sfu.event.VideoLayerSetting.Priority priority = 5; */
        if (message.priority !== 0)
            writer.tag(5, runtime.WireType.Varint).int32(message.priority);
        /* stream.video.sfu.models.Codec codec = 6; */
        if (message.codec)
            Codec.internalBinaryWrite(message.codec, writer.tag(6, runtime.WireType.LengthDelimited).fork(), options).join();
        /* uint32 max_framerate = 7; */
        if (message.maxFramerate !== 0)
            writer.tag(7, runtime.WireType.Varint).uint32(message.maxFramerate);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.VideoLayerSetting
 */
const VideoLayerSetting = new VideoLayerSetting$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoSender$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.VideoSender', [
            {
                no: 1,
                name: 'media_request',
                kind: 'message',
                T: () => VideoMediaRequest,
            },
            { no: 2, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 3,
                name: 'layers',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoLayerSetting,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.layers = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.event.VideoMediaRequest media_request */ 1:
                    message.mediaRequest = VideoMediaRequest.internalBinaryRead(reader, reader.uint32(), options, message.mediaRequest);
                    break;
                case /* stream.video.sfu.models.Codec codec */ 2:
                    message.codec = Codec.internalBinaryRead(reader, reader.uint32(), options, message.codec);
                    break;
                case /* repeated stream.video.sfu.event.VideoLayerSetting layers */ 3:
                    message.layers.push(VideoLayerSetting.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.event.VideoMediaRequest media_request = 1; */
        if (message.mediaRequest)
            VideoMediaRequest.internalBinaryWrite(message.mediaRequest, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* stream.video.sfu.models.Codec codec = 2; */
        if (message.codec)
            Codec.internalBinaryWrite(message.codec, writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        /* repeated stream.video.sfu.event.VideoLayerSetting layers = 3; */
        for (let i = 0; i < message.layers.length; i++)
            VideoLayerSetting.internalBinaryWrite(message.layers[i], writer.tag(3, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.VideoSender
 */
const VideoSender = new VideoSender$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ChangePublishQuality$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ChangePublishQuality', [
            {
                no: 1,
                name: 'audio_senders',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => AudioSender,
            },
            {
                no: 2,
                name: 'video_senders',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoSender,
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.audioSenders = [];
        message.videoSenders = [];
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* repeated stream.video.sfu.event.AudioSender audio_senders */ 1:
                    message.audioSenders.push(AudioSender.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* repeated stream.video.sfu.event.VideoSender video_senders */ 2:
                    message.videoSenders.push(VideoSender.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* repeated stream.video.sfu.event.AudioSender audio_senders = 1; */
        for (let i = 0; i < message.audioSenders.length; i++)
            AudioSender.internalBinaryWrite(message.audioSenders[i], writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* repeated stream.video.sfu.event.VideoSender video_senders = 2; */
        for (let i = 0; i < message.videoSenders.length; i++)
            VideoSender.internalBinaryWrite(message.videoSenders[i], writer.tag(2, runtime.WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ChangePublishQuality
 */
const ChangePublishQuality = new ChangePublishQuality$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallGrantsUpdated$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.CallGrantsUpdated', [
            { no: 1, name: 'current_grants', kind: 'message', T: () => CallGrants },
            { no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.message = '';
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.CallGrants current_grants */ 1:
                    message.currentGrants = CallGrants.internalBinaryRead(reader, reader.uint32(), options, message.currentGrants);
                    break;
                case /* string message */ 2:
                    message.message = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.CallGrants current_grants = 1; */
        if (message.currentGrants)
            CallGrants.internalBinaryWrite(message.currentGrants, writer.tag(1, runtime.WireType.LengthDelimited).fork(), options).join();
        /* string message = 2; */
        if (message.message !== '')
            writer.tag(2, runtime.WireType.LengthDelimited).string(message.message);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.CallGrantsUpdated
 */
const CallGrantsUpdated = new CallGrantsUpdated$Type();
// @generated message type with reflection information, may provide speed optimized methods
class GoAway$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.GoAway', [
            {
                no: 1,
                name: 'reason',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.GoAwayReason',
                    GoAwayReason,
                    'GO_AWAY_REASON_',
                ],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.reason = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.GoAwayReason reason */ 1:
                    message.reason = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.GoAwayReason reason = 1; */
        if (message.reason !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.reason);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.GoAway
 */
const GoAway = new GoAway$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallEnded$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.CallEnded', [
            {
                no: 1,
                name: 'reason',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.CallEndedReason',
                    CallEndedReason,
                    'CALL_ENDED_REASON_',
                ],
            },
        ]);
    }
    create(value) {
        const message = globalThis.Object.create(this.messagePrototype);
        message.reason = 0;
        if (value !== undefined)
            runtime.reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* stream.video.sfu.models.CallEndedReason reason */ 1:
                    message.reason = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === 'throw')
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? runtime.UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* stream.video.sfu.models.CallEndedReason reason = 1; */
        if (message.reason !== 0)
            writer.tag(1, runtime.WireType.Varint).int32(message.reason);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? runtime.UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.CallEnded
 */
const CallEnded = new CallEnded$Type();

var events = /*#__PURE__*/Object.freeze({
    __proto__: null,
    AudioLevel: AudioLevel,
    AudioLevelChanged: AudioLevelChanged,
    AudioMediaRequest: AudioMediaRequest,
    AudioSender: AudioSender,
    CallEnded: CallEnded,
    CallGrantsUpdated: CallGrantsUpdated,
    ChangePublishQuality: ChangePublishQuality,
    ConnectionQualityChanged: ConnectionQualityChanged,
    ConnectionQualityInfo: ConnectionQualityInfo,
    DominantSpeakerChanged: DominantSpeakerChanged,
    Error: Error$1,
    GoAway: GoAway,
    HealthCheckRequest: HealthCheckRequest,
    HealthCheckResponse: HealthCheckResponse,
    ICERestart: ICERestart,
    ICETrickle: ICETrickle,
    JoinRequest: JoinRequest,
    JoinResponse: JoinResponse,
    Migration: Migration,
    ParticipantJoined: ParticipantJoined,
    ParticipantLeft: ParticipantLeft,
    ParticipantUpdated: ParticipantUpdated,
    PinsChanged: PinsChanged,
    PublisherAnswer: PublisherAnswer,
    SfuEvent: SfuEvent,
    SfuRequest: SfuRequest,
    SubscriberOffer: SubscriberOffer,
    TrackPublished: TrackPublished,
    TrackUnpublished: TrackUnpublished,
    VideoLayerSetting: VideoLayerSetting,
    get VideoLayerSetting_Priority () { return VideoLayerSetting_Priority; },
    VideoMediaRequest: VideoMediaRequest,
    VideoSender: VideoSender
});

exports.VisibilityState = void 0;
(function (VisibilityState) {
    VisibilityState["UNKNOWN"] = "UNKNOWN";
    VisibilityState["VISIBLE"] = "VISIBLE";
    VisibilityState["INVISIBLE"] = "INVISIBLE";
})(exports.VisibilityState || (exports.VisibilityState = {}));
exports.DebounceType = void 0;
(function (DebounceType) {
    DebounceType[DebounceType["IMMEDIATE"] = 20] = "IMMEDIATE";
    DebounceType[DebounceType["FAST"] = 100] = "FAST";
    DebounceType[DebounceType["MEDIUM"] = 600] = "MEDIUM";
    DebounceType[DebounceType["SLOW"] = 1200] = "SLOW";
})(exports.DebounceType || (exports.DebounceType = {}));

/**
 * @generated from protobuf service stream.video.sfu.signal.SignalServer
 */
class SignalServerClient {
    constructor(_transport) {
        this._transport = _transport;
        this.typeName = SignalServer.typeName;
        this.methods = SignalServer.methods;
        this.options = SignalServer.options;
    }
    /**
     * SetPublisher sends the WebRTC offer for the peer connection used to publish A/V
     *
     * @generated from protobuf rpc: SetPublisher(stream.video.sfu.signal.SetPublisherRequest) returns (stream.video.sfu.signal.SetPublisherResponse);
     */
    setPublisher(input, options) {
        const method = this.methods[0], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * answer is sent by the client to the SFU after receiving a subscriber_offer.
     *
     * @generated from protobuf rpc: SendAnswer(stream.video.sfu.signal.SendAnswerRequest) returns (stream.video.sfu.signal.SendAnswerResponse);
     */
    sendAnswer(input, options) {
        const method = this.methods[1], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * SendICECandidate sends an ICE candidate to the client
     *
     * @generated from protobuf rpc: IceTrickle(stream.video.sfu.models.ICETrickle) returns (stream.video.sfu.signal.ICETrickleResponse);
     */
    iceTrickle(input, options) {
        const method = this.methods[2], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * UpdateSubscribers is used to notify the SFU about the list of video subscriptions
     * TODO: sync subscriptions based on this + update tracks using the dimension info sent by the user
     *
     * @generated from protobuf rpc: UpdateSubscriptions(stream.video.sfu.signal.UpdateSubscriptionsRequest) returns (stream.video.sfu.signal.UpdateSubscriptionsResponse);
     */
    updateSubscriptions(input, options) {
        const method = this.methods[3], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: UpdateMuteStates(stream.video.sfu.signal.UpdateMuteStatesRequest) returns (stream.video.sfu.signal.UpdateMuteStatesResponse);
     */
    updateMuteStates(input, options) {
        const method = this.methods[4], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: IceRestart(stream.video.sfu.signal.ICERestartRequest) returns (stream.video.sfu.signal.ICERestartResponse);
     */
    iceRestart(input, options) {
        const method = this.methods[5], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: SendStats(stream.video.sfu.signal.SendStatsRequest) returns (stream.video.sfu.signal.SendStatsResponse);
     */
    sendStats(input, options) {
        const method = this.methods[6], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: StartNoiseCancellation(stream.video.sfu.signal.StartNoiseCancellationRequest) returns (stream.video.sfu.signal.StartNoiseCancellationResponse);
     */
    startNoiseCancellation(input, options) {
        const method = this.methods[7], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: StopNoiseCancellation(stream.video.sfu.signal.StopNoiseCancellationRequest) returns (stream.video.sfu.signal.StopNoiseCancellationResponse);
     */
    stopNoiseCancellation(input, options) {
        const method = this.methods[8], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
}

const defaultOptions = {
    baseUrl: '',
    sendJson: true,
    timeout: 5 * 1000, // ms.
    jsonOptions: {
        ignoreUnknownFields: true,
    },
};
const withHeaders = (headers) => {
    return {
        interceptUnary(next, method, input, options) {
            options.meta = { ...options.meta, ...headers };
            return next(method, input, options);
        },
    };
};
/**
 * Creates new SignalServerClient instance.
 *
 * @param options the twirp options.
 */
const createSignalClient = (options) => {
    const transport = new twirpTransport.TwirpFetchTransport({
        ...defaultOptions,
        ...options,
    });
    return new SignalServerClient(transport);
};

/**
 * Checks whether we are using React Native
 */
const isReactNative = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.product?.toLowerCase() === 'reactnative';
};

// log levels, sorted by verbosity
const logLevels = Object.freeze({
    trace: 0,
    debug: 1,
    info: 2,
    warn: 3,
    error: 4,
});
let logger$4;
let level = 'info';
const logToConsole = (logLevel, message, ...args) => {
    let logMethod;
    switch (logLevel) {
        case 'error':
            if (isReactNative()) {
                message = `ERROR: ${message}`;
                logMethod = console.info;
                break;
            }
            logMethod = console.error;
            break;
        case 'warn':
            if (isReactNative()) {
                message = `WARN: ${message}`;
                logMethod = console.info;
                break;
            }
            logMethod = console.warn;
            break;
        case 'info':
            logMethod = console.info;
            break;
        case 'trace':
            logMethod = console.trace;
            break;
        default:
            logMethod = console.log;
            break;
    }
    logMethod(message, ...args);
};
const setLogger = (l, lvl) => {
    logger$4 = l;
    if (lvl) {
        setLogLevel(lvl);
    }
};
const setLogLevel = (l) => {
    level = l;
};
const getLogger = (withTags) => {
    const loggerMethod = logger$4 || logToConsole;
    const tags = (withTags || []).join(':');
    const result = (logLevel, message, ...args) => {
        if (logLevels[logLevel] >= logLevels[level]) {
            loggerMethod(logLevel, `[${tags}]: ${message}`, ...args);
        }
    };
    return result;
};

const getPreferredCodecs = (kind, preferredCodec, codecToRemove) => {
    const logger = getLogger(['codecs']);
    if (!('getCapabilities' in RTCRtpReceiver)) {
        logger('warn', 'RTCRtpReceiver.getCapabilities is not supported');
        return;
    }
    const cap = RTCRtpReceiver.getCapabilities(kind);
    if (!cap)
        return;
    const matched = [];
    const partialMatched = [];
    const unmatched = [];
    cap.codecs.forEach((c) => {
        const codec = c.mimeType.toLowerCase();
        logger('debug', `Found supported codec: ${codec}`);
        const shouldRemoveCodec = codecToRemove && codec === `${kind}/${codecToRemove.toLowerCase()}`;
        if (shouldRemoveCodec)
            return;
        const matchesCodec = codec === `${kind}/${preferredCodec.toLowerCase()}`;
        if (!matchesCodec) {
            unmatched.push(c);
            return;
        }
        // for h264 codecs that have sdpFmtpLine available, use only if the
        // profile-level-id is 42e01f for cross-browser compatibility
        if (codec === 'h264') {
            if (c.sdpFmtpLine && c.sdpFmtpLine.includes('profile-level-id=42e01f')) {
                matched.push(c);
            }
            else {
                partialMatched.push(c);
            }
            return;
        }
        matched.push(c);
    });
    return [...matched, ...partialMatched, ...unmatched];
};
const getGenericSdp = async (direction) => {
    const tempPc = new RTCPeerConnection();
    tempPc.addTransceiver('video', { direction });
    tempPc.addTransceiver('audio', { direction });
    const offer = await tempPc.createOffer();
    let sdp = offer.sdp ?? '';
    tempPc.getTransceivers().forEach((t) => {
        t.stop();
    });
    tempPc.close();
    return sdp;
};

const sfuEventKinds = {
    subscriberOffer: undefined,
    publisherAnswer: undefined,
    connectionQualityChanged: undefined,
    audioLevelChanged: undefined,
    iceTrickle: undefined,
    changePublishQuality: undefined,
    participantJoined: undefined,
    participantLeft: undefined,
    dominantSpeakerChanged: undefined,
    joinResponse: undefined,
    healthCheckResponse: undefined,
    trackPublished: undefined,
    trackUnpublished: undefined,
    error: undefined,
    callGrantsUpdated: undefined,
    goAway: undefined,
    iceRestart: undefined,
    pinsUpdated: undefined,
    callEnded: undefined,
    participantUpdated: undefined,
};
const isSfuEvent = (eventName) => {
    return Object.prototype.hasOwnProperty.call(sfuEventKinds, eventName);
};
class Dispatcher {
    constructor() {
        this.logger = getLogger(['Dispatcher']);
        this.subscribers = {};
        this.dispatch = (message) => {
            const eventKind = message.eventPayload.oneofKind;
            if (!eventKind)
                return;
            const payload = message.eventPayload[eventKind];
            this.logger('debug', `Dispatching ${eventKind}`, payload);
            const listeners = this.subscribers[eventKind];
            if (!listeners)
                return;
            for (const fn of listeners) {
                try {
                    fn(payload);
                }
                catch (e) {
                    this.logger('warn', 'Listener failed with error', e);
                }
            }
        };
        this.on = (eventName, fn) => {
            var _a;
            ((_a = this.subscribers)[eventName] ?? (_a[eventName] = [])).push(fn);
            return () => {
                this.off(eventName, fn);
            };
        };
        this.off = (eventName, fn) => {
            this.subscribers[eventName] = (this.subscribers[eventName] || []).filter((f) => f !== fn);
        };
        this.offAll = (eventName) => {
            if (eventName) {
                this.subscribers[eventName] = [];
            }
            else {
                this.subscribers = {};
            }
        };
    }
}

/**
 * A buffer for ICE Candidates. Used for ICE Trickle:
 * - https://bloggeek.me/webrtcglossary/trickle-ice/
 */
class IceTrickleBuffer {
    constructor() {
        this.subscriberCandidates = new rxjs.ReplaySubject();
        this.publisherCandidates = new rxjs.ReplaySubject();
        this.logger = getLogger(['sfu-client']);
        this.push = (iceTrickle) => {
            if (iceTrickle.peerType === PeerType.SUBSCRIBER) {
                this.subscriberCandidates.next(iceTrickle);
            }
            else if (iceTrickle.peerType === PeerType.PUBLISHER_UNSPECIFIED) {
                this.publisherCandidates.next(iceTrickle);
            }
            else {
                this.logger('warn', `ICETrickle, Unknown peer type`, iceTrickle);
            }
        };
    }
}

function getIceCandidate(candidate) {
    if (!candidate.usernameFragment) {
        // react-native-webrtc doesn't include usernameFragment in the candidate
        const splittedCandidate = candidate.candidate.split(' ');
        const ufragIndex = splittedCandidate.findIndex((s) => s === 'ufrag') + 1;
        const usernameFragment = splittedCandidate[ufragIndex];
        return JSON.stringify({ ...candidate, usernameFragment });
    }
    else {
        return JSON.stringify(candidate.toJSON());
    }
}

let sdkInfo;
let osInfo;
let deviceInfo;
let webRtcInfo;
const setSdkInfo = (info) => {
    sdkInfo = info;
};
const getSdkInfo = () => {
    return sdkInfo;
};
const setOSInfo = (info) => {
    osInfo = info;
};
const getOSInfo = () => {
    return osInfo;
};
const setDeviceInfo = (info) => {
    deviceInfo = info;
};
const getDeviceInfo = () => {
    return deviceInfo;
};
const getWebRTCInfo = () => {
    return webRtcInfo;
};
const setWebRTCInfo = (info) => {
    webRtcInfo = info;
};
const getClientDetails = () => {
    if (isReactNative()) {
        // Since RN doesn't support web, sharing browser info is not required
        return {
            sdk: getSdkInfo(),
            os: getOSInfo(),
            device: getDeviceInfo(),
        };
    }
    const userAgent = new uaParserJs.UAParser(navigator.userAgent);
    const { browser, os, device, cpu } = userAgent.getResult();
    return {
        sdk: getSdkInfo(),
        browser: {
            name: browser.name || navigator.userAgent,
            version: browser.version || '',
        },
        os: {
            name: os.name || '',
            version: os.version || '',
            architecture: cpu.architecture || '',
        },
        device: {
            name: [device.vendor, device.model, device.type]
                .filter(Boolean)
                .join(' '),
            version: '',
        },
    };
};

const DEFAULT_BITRATE = 1250000;
const defaultTargetResolution = {
    bitrate: DEFAULT_BITRATE,
    width: 1280,
    height: 720,
};
const defaultBitratePerRid = {
    q: 300000,
    h: 750000,
    f: DEFAULT_BITRATE,
};
/**
 * Determines the most optimal video layers for simulcasting
 * for the given track.
 *
 * @param videoTrack the video track to find optimal layers for.
 * @param targetResolution the expected target resolution.
 */
const findOptimalVideoLayers = (videoTrack, targetResolution = defaultTargetResolution) => {
    const optimalVideoLayers = [];
    const settings = videoTrack.getSettings();
    const { width: w = 0, height: h = 0 } = settings;
    const isRNIos = isReactNative() && getOSInfo()?.name.toLowerCase() === 'ios';
    const maxBitrate = getComputedMaxBitrate(targetResolution, w, h);
    let downscaleFactor = 1;
    ['f', 'h', 'q'].forEach((rid) => {
        // Reversing the order [f, h, q] to [q, h, f] as Chrome uses encoding index
        // when deciding which layer to disable when CPU or bandwidth is constrained.
        // Encodings should be ordered in increasing spatial resolution order.
        optimalVideoLayers.unshift({
            active: true,
            rid,
            width: Math.round(w / downscaleFactor),
            height: Math.round(h / downscaleFactor),
            maxBitrate: Math.round(maxBitrate / downscaleFactor) || defaultBitratePerRid[rid],
            scaleResolutionDownBy: downscaleFactor,
            // Simulcast on iOS React-Native requires all encodings to share the same framerate
            maxFramerate: {
                f: 30,
                h: isRNIos ? 30 : 25,
                q: isRNIos ? 30 : 20,
            }[rid],
        });
        downscaleFactor *= 2;
    });
    // for simplicity, we start with all layers enabled, then this function
    // will clear/reassign the layers that are not needed
    return withSimulcastConstraints(settings, optimalVideoLayers);
};
/**
 * Computes the maximum bitrate for a given resolution.
 * If the current resolution is lower than the target resolution,
 * we want to proportionally reduce the target bitrate.
 * If the current resolution is higher than the target resolution,
 * we want to use the target bitrate.
 *
 * @param targetResolution the target resolution.
 * @param currentWidth the current width of the track.
 * @param currentHeight the current height of the track.
 */
const getComputedMaxBitrate = (targetResolution, currentWidth, currentHeight) => {
    // if the current resolution is lower than the target resolution,
    // we want to proportionally reduce the target bitrate
    const { width: targetWidth, height: targetHeight } = targetResolution;
    if (currentWidth < targetWidth || currentHeight < targetHeight) {
        const currentPixels = currentWidth * currentHeight;
        const targetPixels = targetWidth * targetHeight;
        const reductionFactor = currentPixels / targetPixels;
        return Math.round(targetResolution.bitrate * reductionFactor);
    }
    return targetResolution.bitrate;
};
/**
 * Browsers have different simulcast constraints for different video resolutions.
 *
 * This function modifies the provided list of video layers according to the
 * current implementation of simulcast constraints in the Chromium based browsers.
 *
 * https://chromium.googlesource.com/external/webrtc/+/refs/heads/main/media/engine/simulcast.cc#90
 */
const withSimulcastConstraints = (settings, optimalVideoLayers) => {
    let layers;
    const size = Math.max(settings.width || 0, settings.height || 0);
    if (size <= 320) {
        // provide only one layer 320x240 (q), the one with the highest quality
        layers = optimalVideoLayers.filter((layer) => layer.rid === 'f');
    }
    else if (size <= 640) {
        // provide two layers, 160x120 (q) and 640x480 (h)
        layers = optimalVideoLayers.filter((layer) => layer.rid !== 'h');
    }
    else {
        // provide three layers for sizes > 640x480
        layers = optimalVideoLayers;
    }
    const ridMapping = ['q', 'h', 'f'];
    return layers.map((layer, index) => ({
        ...layer,
        rid: ridMapping[index], // reassign rid
    }));
};
const findOptimalScreenSharingLayers = (videoTrack, preferences, defaultMaxBitrate = 3000000) => {
    const settings = videoTrack.getSettings();
    return [
        {
            active: true,
            rid: 'q', // single track, start from 'q'
            width: settings.width || 0,
            height: settings.height || 0,
            scaleResolutionDownBy: 1,
            maxBitrate: preferences?.maxBitrate ?? defaultMaxBitrate,
            maxFramerate: preferences?.maxFramerate ?? 30,
        },
    ];
};

const trackTypeToParticipantStreamKey = (trackType) => {
    switch (trackType) {
        case TrackType.SCREEN_SHARE:
            return 'screenShareStream';
        case TrackType.SCREEN_SHARE_AUDIO:
            return 'screenShareAudioStream';
        case TrackType.VIDEO:
            return 'videoStream';
        case TrackType.AUDIO:
            return 'audioStream';
        case TrackType.UNSPECIFIED:
            throw new Error('Track type is unspecified');
        default:
            const exhaustiveTrackTypeCheck = trackType;
            throw new Error(`Unknown track type: ${exhaustiveTrackTypeCheck}`);
    }
};
const muteTypeToTrackType = (muteType) => {
    switch (muteType) {
        case 'audio':
            return TrackType.AUDIO;
        case 'video':
            return TrackType.VIDEO;
        case 'screenshare':
            return TrackType.SCREEN_SHARE;
        case 'screenshare_audio':
            return TrackType.SCREEN_SHARE_AUDIO;
        default:
            const exhaustiveMuteTypeCheck = muteType;
            throw new Error(`Unknown mute type: ${exhaustiveMuteTypeCheck}`);
    }
};

/**
 * Checks if the provided update is a function patch.
 *
 * @param update the value to check.
 */
const isFunctionPatch = (update) => typeof update === 'function';
/**
 * Gets the current value of an observable, or undefined if the observable has
 * not emitted a value yet.
 *
 * @param observable$ the observable to get the value from.
 */
const getCurrentValue = (observable$) => {
    let value;
    let err = undefined;
    rxjs.combineLatest([observable$])
        .subscribe({
        next: ([v]) => {
            value = v;
        },
        error: (e) => {
            err = e;
        },
    })
        .unsubscribe();
    if (err)
        throw err;
    return value;
};
/**
 * Updates the value of the provided Subject.
 * An `update` can either be a new value or a function which takes
 * the current value and returns a new value.
 *
 * @param subject the subject to update.
 * @param update the update to apply to the subject.
 * @return the updated value.
 */
const setCurrentValue = (subject, update) => {
    const next = isFunctionPatch(update)
        ? update(getCurrentValue(subject))
        : update;
    subject.next(next);
    return next;
};
/**
 * Creates a subscription and returns a function to unsubscribe.
 *
 * @param observable the observable to subscribe to.
 * @param handler the handler to call when the observable emits a value.
 */
const createSubscription = (observable, handler) => {
    const subscription = observable.subscribe(handler);
    return () => {
        subscription.unsubscribe();
    };
};

var rxUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    createSubscription: createSubscription,
    getCurrentValue: getCurrentValue,
    setCurrentValue: setCurrentValue
});

/**
 * Creates a new combined {@link Comparator<T>} which sorts items by the given comparators.
 * The comparators are applied in the order they are given (left -> right).
 *
 * @param comparators the comparators to use for sorting.
 * @returns a combined {@link Comparator<T>}.
 */
const combineComparators = (...comparators) => {
    return (a, b) => {
        for (const comparator of comparators) {
            const result = comparator(a, b);
            if (result !== 0)
                return result;
        }
        return 0;
    };
};
/**
 * Creates a new comparator which sorts items in descending order.
 *
 * @example
 * const byValue = (a, b) => a < b ? - 1 : a > b ? 1 : 0;
 * const byValueDesc = descending(byValue);
 *
 * @param comparator the comparator to wrap.
 */
const descending = (comparator) => {
    return (a, b) => comparator(b, a);
};
/**
 * Creates a new comparator which conditionally applies the given comparator.
 *
 * @example
 * const shouldSortByValue = (a, b) => a % 2 === 0; // return false to turn it off
 * const byValue = (a, b) => a < b ? - 1 : a > b ? 1 : 0;
 * const comparator = conditional(shouldSortByValue)(byValue);
 *
 * @param predicate the predicate to use for determining whether to apply the comparator.
 */
const conditional = (predicate) => {
    return (comparator) => {
        return (a, b) => {
            if (!predicate(a, b))
                return 0;
            return comparator(a, b);
        };
    };
};
/**
 * A no-op comparator which always returns 0.
 */
const noopComparator = () => {
    return () => 0;
};

/**
 * Check if a participant has a video.
 *
 * @param p the participant to check.
 */
const hasVideo = (p) => p.publishedTracks.includes(TrackType.VIDEO);
/**
 * Check if a participant has audio.
 *
 * @param p the participant to check.
 */
const hasAudio = (p) => p.publishedTracks.includes(TrackType.AUDIO);
/**
 * Check if a participant is screen sharing.
 *
 * @param p the participant to check.
 */
const hasScreenShare = (p) => p.publishedTracks.includes(TrackType.SCREEN_SHARE);
/**
 * Check if a participant is screen sharing audio.
 *
 * @param p the participant to check.
 */
const hasScreenShareAudio = (p) => p.publishedTracks.includes(TrackType.SCREEN_SHARE_AUDIO);
/**
 * Check if the participant is pinned.
 *
 * @param p the participant.
 */
const isPinned = (p) => !!p.pin && (p.pin.isLocalPin || p.pin.pinnedAt > 0);

/**
 * A comparator which sorts participants by the fact that they are the dominant speaker or not.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const dominantSpeaker = (a, b) => {
    if (a.isDominantSpeaker && !b.isDominantSpeaker)
        return -1;
    if (!a.isDominantSpeaker && b.isDominantSpeaker)
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by the fact that they are speaking or not.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const speaking = (a, b) => {
    if (a.isSpeaking && !b.isSpeaking)
        return -1;
    if (!a.isSpeaking && b.isSpeaking)
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by screen sharing status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const screenSharing = (a, b) => {
    if (hasScreenShare(a) && !hasScreenShare(b))
        return -1;
    if (!hasScreenShare(a) && hasScreenShare(b))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by video status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const publishingVideo = (a, b) => {
    if (hasVideo(a) && !hasVideo(b))
        return -1;
    if (!hasVideo(a) && hasVideo(b))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by audio status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const publishingAudio = (a, b) => {
    if (hasAudio(a) && !hasAudio(b))
        return -1;
    if (!hasAudio(a) && hasAudio(b))
        return 1;
    return 0;
};
/**
 * A comparator which prioritizes participants who are pinned.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const pinned = (a, b) => {
    if (a.pin && b.pin) {
        if (!a.pin.isLocalPin && b.pin.isLocalPin)
            return -1;
        if (a.pin.isLocalPin && !b.pin.isLocalPin)
            return 1;
        if (a.pin.pinnedAt > b.pin.pinnedAt)
            return -1;
        if (a.pin.pinnedAt < b.pin.pinnedAt)
            return 1;
    }
    if (a.pin && !b.pin)
        return -1;
    if (!a.pin && b.pin)
        return 1;
    return 0;
};
/**
 * A comparator creator which will set up a comparator which prioritizes
 * participants who have a specific reaction.
 *
 * @param type the reaction type.
 */
const reactionType = (type) => {
    return (a, b) => {
        if (a.reaction?.type === type && b.reaction?.type !== type)
            return -1;
        if (a.reaction?.type !== type && b.reaction?.type === type)
            return 1;
        return 0;
    };
};
/**
 * A comparator creator which will set up a comparator which prioritizes
 * participants who have a specific role.
 *
 * @param roles the roles to prioritize.
 */
const role = (...roles) => (a, b) => {
    if (hasAnyRole(a, roles) && !hasAnyRole(b, roles))
        return -1;
    if (!hasAnyRole(a, roles) && hasAnyRole(b, roles))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by name.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const name = (a, b) => {
    if (a.name < b.name)
        return -1;
    if (a.name > b.name)
        return 1;
    return 0;
};
const hasAnyRole = (p, roles) => (p.roles || []).some((r) => roles.includes(r));

// a comparator decorator which applies the decorated comparator only if the
// participant is invisible.
// This ensures stable sorting when all participants are visible.
const ifInvisibleBy = conditional((a, b) => a.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE);
/**
 * A comparator that applies the decorated comparator when a participant is
 * either invisible or its visibility state isn't known.
 * For visible participants, it ensures stable sorting.
 */
const ifInvisibleOrUnknownBy = conditional((a, b) => a.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    a.viewportVisibilityState?.videoTrack === exports.VisibilityState.UNKNOWN ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.UNKNOWN);
/**
 * The default sorting preset.
 */
const defaultSortPreset = combineComparators(pinned, screenSharing, ifInvisibleBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for speaker layout.
 */
const speakerLayoutSortPreset = combineComparators(pinned, screenSharing, dominantSpeaker, ifInvisibleBy(combineComparators(speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for layouts that don't render all participants but
 * instead, render them in pages.
 */
const paginatedLayoutSortPreset = combineComparators(pinned, ifInvisibleOrUnknownBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for livestreams and audio rooms.
 */
const livestreamOrAudioRoomSortPreset = combineComparators(ifInvisibleBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)), role('admin', 'host', 'speaker'));

/**
 * Represents the state of the current call.
 */
exports.CallingState = void 0;
(function (CallingState) {
    /**
     * The call is in an unknown state.
     */
    CallingState["UNKNOWN"] = "unknown";
    /**
     * The call is in an idle state.
     */
    CallingState["IDLE"] = "idle";
    /**
     * The call is in the process of ringing.
     * (User hasn't accepted nor rejected the call yet.)
     */
    CallingState["RINGING"] = "ringing";
    /**
     * The call is in the process of joining.
     */
    CallingState["JOINING"] = "joining";
    /**
     * The call is currently active.
     */
    CallingState["JOINED"] = "joined";
    /**
     * The call has been left.
     */
    CallingState["LEFT"] = "left";
    /**
     * The call is in the process of reconnecting.
     */
    CallingState["RECONNECTING"] = "reconnecting";
    /**
     * The call is in the process of migrating from one node to another.
     */
    CallingState["MIGRATING"] = "migrating";
    /**
     * The call has failed to reconnect.
     */
    CallingState["RECONNECTING_FAILED"] = "reconnecting-failed";
    /**
     * The call is in offline mode.
     */
    CallingState["OFFLINE"] = "offline";
})(exports.CallingState || (exports.CallingState = {}));
/**
 * Returns the default egress object - when no egress data is available.
 */
const defaultEgress = {
    broadcasting: false,
    hls: { playlist_url: '' },
    rtmps: [],
};
/**
 * Holds the state of the current call.
 * @react You don't have to use this class directly, as we are exposing the state through Hooks.
 */
class CallState {
    /**
     * Creates a new instance of the CallState class.
     *
     */
    constructor() {
        this.backstageSubject = new rxjs.BehaviorSubject(true);
        this.blockedUserIdsSubject = new rxjs.BehaviorSubject([]);
        this.createdAtSubject = new rxjs.BehaviorSubject(new Date());
        this.endedAtSubject = new rxjs.BehaviorSubject(undefined);
        this.startsAtSubject = new rxjs.BehaviorSubject(undefined);
        this.updatedAtSubject = new rxjs.BehaviorSubject(new Date());
        this.createdBySubject = new rxjs.BehaviorSubject(undefined);
        this.customSubject = new rxjs.BehaviorSubject({});
        this.egressSubject = new rxjs.BehaviorSubject(undefined);
        this.ingressSubject = new rxjs.BehaviorSubject(undefined);
        this.recordingSubject = new rxjs.BehaviorSubject(false);
        this.sessionSubject = new rxjs.BehaviorSubject(undefined);
        this.settingsSubject = new rxjs.BehaviorSubject(undefined);
        this.transcribingSubject = new rxjs.BehaviorSubject(false);
        this.endedBySubject = new rxjs.BehaviorSubject(undefined);
        this.thumbnailsSubject = new rxjs.BehaviorSubject(undefined);
        this.membersSubject = new rxjs.BehaviorSubject([]);
        this.ownCapabilitiesSubject = new rxjs.BehaviorSubject([]);
        this.callingStateSubject = new rxjs.BehaviorSubject(exports.CallingState.UNKNOWN);
        this.startedAtSubject = new rxjs.BehaviorSubject(undefined);
        this.participantCountSubject = new rxjs.BehaviorSubject(0);
        this.anonymousParticipantCountSubject = new rxjs.BehaviorSubject(0);
        this.participantsSubject = new rxjs.BehaviorSubject([]);
        this.callStatsReportSubject = new rxjs.BehaviorSubject(undefined);
        this.logger = getLogger(['CallState']);
        /**
         * A list of comparators that are used to sort the participants.
         *
         * @private
         */
        this.sortParticipantsBy = defaultSortPreset;
        /**
         * Sets the list of criteria that are used to sort the participants.
         * To disable sorting, you can pass `noopComparator()`.
         *
         * @param comparator the comparator to use to sort the participants.
         */
        this.setSortParticipantsBy = (comparator) => {
            this.sortParticipantsBy = comparator;
            // trigger re-sorting of participants
            this.setCurrentValue(this.participantsSubject, (ps) => ps);
        };
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        /**
         * Sets the number of participants in the current call.
         *
         * @internal
         * @param count the number of participants.
         */
        this.setParticipantCount = (count) => {
            return this.setCurrentValue(this.participantCountSubject, count);
        };
        /**
         * Sets the time the call session actually started.
         *
         * @internal
         * @param startedAt the time the call session actually started.
         */
        this.setStartedAt = (startedAt) => {
            return this.setCurrentValue(this.startedAtSubject, startedAt);
        };
        /**
         * Sets the number of anonymous participants in the current call.
         *
         * @internal
         * @param count the number of anonymous participants.
         */
        this.setAnonymousParticipantCount = (count) => {
            return this.setCurrentValue(this.anonymousParticipantCountSubject, count);
        };
        /**
         * Sets the list of participants in the current call.
         *
         * @internal
         *
         * @param participants the list of participants.
         */
        this.setParticipants = (participants) => {
            return this.setCurrentValue(this.participantsSubject, participants);
        };
        /**
         * Sets the calling state.
         *
         * @internal
         * @param state the new calling state.
         */
        this.setCallingState = (state) => {
            return this.setCurrentValue(this.callingStateSubject, state);
        };
        /**
         * Sets the call stats report.
         *
         * @internal
         * @param report the report to set.
         */
        this.setCallStatsReport = (report) => {
            return this.setCurrentValue(this.callStatsReportSubject, report);
        };
        /**
         * Sets the members of the current call.
         *
         * @internal
         * @param members the members to set.
         */
        this.setMembers = (members) => {
            this.setCurrentValue(this.membersSubject, members);
        };
        /**
         * Sets the own capabilities.
         *
         * @internal
         * @param capabilities the capabilities to set.
         */
        this.setOwnCapabilities = (capabilities) => {
            return this.setCurrentValue(this.ownCapabilitiesSubject, capabilities);
        };
        /**
         * Will try to find the participant with the given sessionId in the current call.
         *
         * @param sessionId the sessionId of the participant to find.
         * @returns the participant with the given sessionId or undefined if not found.
         */
        this.findParticipantBySessionId = (sessionId) => {
            return this.participants.find((p) => p.sessionId === sessionId);
        };
        /**
         * Returns a new lookup table of participants indexed by their session ID.
         */
        this.getParticipantLookupBySessionId = () => {
            return this.participants.reduce((lookupTable, participant) => {
                lookupTable[participant.sessionId] = participant;
                return lookupTable;
            }, {});
        };
        /**
         * Updates a participant in the current call identified by the given `sessionId`.
         * If the participant can't be found, this operation is no-op.
         *
         * @internal
         *
         * @param sessionId the session ID of the participant to update.
         * @param patch the patch to apply to the participant.
         * @returns the updated participant or `undefined` if the participant couldn't be found.
         */
        this.updateParticipant = (sessionId, patch) => {
            const participant = this.findParticipantBySessionId(sessionId);
            if (!participant) {
                this.logger('warn', `Participant with sessionId ${sessionId} not found`);
                return;
            }
            const thePatch = typeof patch === 'function' ? patch(participant) : patch;
            const updatedParticipant = {
                // FIXME OL: this is not a deep merge, we might want to revisit this
                ...participant,
                ...thePatch,
            };
            return this.setParticipants((participants) => participants.map((p) => p.sessionId === sessionId ? updatedParticipant : p));
        };
        /**
         * Updates a participant in the current call identified by the given `sessionId`.
         * If a participant with matching `sessionId` can't be found, the provided
         * `participant` is added to the list of participants.
         *
         * @param sessionId the session ID of the participant to update.
         * @param participant the participant to update or add.
         */
        this.updateOrAddParticipant = (sessionId, participant) => {
            return this.setParticipants((participants) => {
                let add = true;
                const nextParticipants = participants.map((p) => {
                    if (p.sessionId === sessionId) {
                        add = false;
                        return {
                            ...p,
                            ...participant,
                        };
                    }
                    return p;
                });
                if (add)
                    nextParticipants.push(participant);
                return nextParticipants;
            });
        };
        /**
         * Updates all participants in the current call whose session ID is in the given `sessionIds`.
         * If no patches are provided, this operation is no-op.
         *
         * @internal
         *
         * @param patch the patch to apply to the participants.
         * @returns all participants, with all patch applied.
         */
        this.updateParticipants = (patch) => {
            if (Object.keys(patch).length === 0)
                return;
            return this.setParticipants((participants) => participants.map((p) => {
                const thePatch = patch[p.sessionId];
                if (thePatch) {
                    return {
                        ...p,
                        ...thePatch,
                    };
                }
                return p;
            }));
        };
        /**
         * Updates the call state with the data received from the server.
         *
         * @internal
         *
         * @param event the video event that our backend sent us.
         */
        this.updateFromEvent = (event) => {
            const update = this.eventHandlers[event.type];
            if (update) {
                update(event);
            }
        };
        /**
         * Updates the participant pinned state with server side pinning data.
         *
         * @param pins the latest pins from the server.
         */
        this.setServerSidePins = (pins) => {
            const pinsLookup = pins.reduce((lookup, pin) => {
                lookup[pin.sessionId] = Date.now();
                return lookup;
            }, {});
            return this.setParticipants((participants) => participants.map((participant) => {
                const serverSidePinnedAt = pinsLookup[participant.sessionId];
                // the participant is newly pinned
                if (serverSidePinnedAt) {
                    return {
                        ...participant,
                        pin: {
                            isLocalPin: false,
                            pinnedAt: serverSidePinnedAt,
                        },
                    };
                }
                // the participant is no longer pinned server side
                // we need to reset the pin
                if (participant.pin && !participant.pin.isLocalPin) {
                    return {
                        ...participant,
                        pin: undefined,
                    };
                }
                // no changes to be applied
                return participant;
            }));
        };
        /**
         * Updates the call state with the data received from the server.
         *
         * @internal
         *
         * @param call the call response from the server.
         */
        this.updateFromCallResponse = (call) => {
            this.setCurrentValue(this.backstageSubject, call.backstage);
            this.setCurrentValue(this.blockedUserIdsSubject, call.blocked_user_ids);
            this.setCurrentValue(this.createdAtSubject, new Date(call.created_at));
            this.setCurrentValue(this.updatedAtSubject, new Date(call.updated_at));
            this.setCurrentValue(this.startsAtSubject, call.starts_at ? new Date(call.starts_at) : undefined);
            this.setCurrentValue(this.endedAtSubject, call.ended_at ? new Date(call.ended_at) : undefined);
            this.setCurrentValue(this.createdBySubject, call.created_by);
            this.setCurrentValue(this.customSubject, call.custom);
            this.setCurrentValue(this.egressSubject, call.egress);
            this.setCurrentValue(this.ingressSubject, call.ingress);
            this.setCurrentValue(this.recordingSubject, call.recording);
            this.setCurrentValue(this.sessionSubject, call.session);
            this.setCurrentValue(this.settingsSubject, call.settings);
            this.setCurrentValue(this.transcribingSubject, call.transcribing);
            this.setCurrentValue(this.thumbnailsSubject, call.thumbnails);
        };
        this.updateFromMemberRemoved = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => members.filter((m) => event.members.indexOf(m.user_id) === -1));
        };
        this.updateFromMemberAdded = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => [
                ...members,
                ...event.members,
            ]);
        };
        this.updateFromHLSBroadcastStopped = () => {
            this.setCurrentValue(this.egressSubject, (egress = defaultEgress) => ({
                ...egress,
                broadcasting: false,
            }));
        };
        this.updateFromHLSBroadcastingFailed = () => {
            this.setCurrentValue(this.egressSubject, (egress = defaultEgress) => ({
                ...egress,
                broadcasting: false,
            }));
        };
        this.updateFromHLSBroadcastStarted = (event) => {
            this.setCurrentValue(this.egressSubject, (egress = defaultEgress) => ({
                ...egress,
                broadcasting: true,
                hls: {
                    ...egress.hls,
                    playlist_url: event.hls_playlist_url,
                },
            }));
        };
        this.updateFromSessionParticipantLeft = (event) => {
            this.setCurrentValue(this.sessionSubject, (session) => {
                if (!session) {
                    this.logger('warn', `Received call.session_participant_left event but no session is available.`, event);
                    return session;
                }
                const { participants, participants_count_by_role } = session;
                const { user, user_session_id } = event.participant;
                return {
                    ...session,
                    participants: participants.filter((p) => p.user_session_id !== user_session_id),
                    participants_count_by_role: {
                        ...participants_count_by_role,
                        [user.role]: Math.max(0, (participants_count_by_role[user.role] || 0) - 1),
                    },
                };
            });
        };
        this.updateFromSessionParticipantJoined = (event) => {
            this.setCurrentValue(this.sessionSubject, (session) => {
                if (!session) {
                    this.logger('warn', `Received call.session_participant_joined event but no session is available.`, event);
                    return session;
                }
                const { participants, participants_count_by_role } = session;
                const { user, user_session_id } = event.participant;
                // It could happen that the backend delivers the same participant more than once.
                // Once with the call.session_started event and once again with the
                // call.session_participant_joined event. In this case,
                // we should update the existing participant and prevent duplicating it.
                let shouldInsertParticipant = true;
                const updatedParticipants = participants.map((p) => {
                    if (p.user_session_id === user_session_id) {
                        shouldInsertParticipant = false;
                        return event.participant;
                    }
                    return p;
                });
                if (shouldInsertParticipant) {
                    // this is a new array, we can safely push the new participant
                    updatedParticipants.push(event.participant);
                }
                // If we are updating an existing participant, we don't want to increment
                // the participant_by_role count.
                const increment = shouldInsertParticipant ? 1 : 0;
                return {
                    ...session,
                    participants: updatedParticipants,
                    participants_count_by_role: {
                        ...participants_count_by_role,
                        [user.role]: (participants_count_by_role[user.role] || 0) + increment,
                    },
                };
            });
        };
        this.updateMembers = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => members.map((member) => {
                const memberUpdate = event.members.find((m) => m.user_id === member.user_id);
                return memberUpdate ? memberUpdate : member;
            }));
        };
        this.updateParticipantReaction = (event) => {
            const { user, custom, type, emoji_code } = event.reaction;
            this.setParticipants((participants) => {
                return participants.map((p) => {
                    // skip if the reaction is not for this participant
                    if (p.userId !== user.id)
                        return p;
                    // update the participant with the new reaction
                    return {
                        ...p,
                        reaction: {
                            type,
                            emoji_code,
                            custom,
                        },
                    };
                });
            });
        };
        this.unblockUser = (event) => {
            this.setCurrentValue(this.blockedUserIdsSubject, (current) => {
                if (!current)
                    return current;
                return current.filter((id) => id !== event.user.id);
            });
        };
        this.blockUser = (event) => {
            this.setCurrentValue(this.blockedUserIdsSubject, (current) => [
                ...(current || []),
                event.user.id,
            ]);
        };
        this.updateOwnCapabilities = (event) => {
            if (event.user.id === this.localParticipant?.userId) {
                this.setCurrentValue(this.ownCapabilitiesSubject, event.own_capabilities);
            }
        };
        this.participants$ = this.participantsSubject.asObservable().pipe(
        // maintain stable-sort by mutating the participants stored
        // in the original subject
        rxjs.map((ps) => ps.sort(this.sortParticipantsBy)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.localParticipant$ = this.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.isLocalParticipant)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.remoteParticipants$ = this.participants$.pipe(rxjs.map((participants) => participants.filter((p) => !p.isLocalParticipant)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.pinnedParticipants$ = this.participants$.pipe(rxjs.map((participants) => participants.filter((p) => !!p.pin)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.dominantSpeaker$ = this.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.isDominantSpeaker)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.hasOngoingScreenShare$ = this.participants$.pipe(rxjs.map((participants) => participants.some((p) => hasScreenShare(p))), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        // dates
        this.createdAt$ = this.createdAtSubject.asObservable();
        this.endedAt$ = this.endedAtSubject.asObservable();
        this.startsAt$ = this.startsAtSubject.asObservable();
        this.startedAt$ = this.startedAtSubject.asObservable();
        this.updatedAt$ = this.updatedAtSubject.asObservable();
        this.callStatsReport$ = this.callStatsReportSubject.asObservable();
        this.members$ = this.membersSubject.asObservable();
        // complex objects should work as streams of data
        this.createdBy$ = this.createdBySubject.asObservable();
        this.custom$ = this.customSubject.asObservable();
        this.egress$ = this.egressSubject.asObservable();
        this.ingress$ = this.ingressSubject.asObservable();
        this.session$ = this.sessionSubject.asObservable();
        this.settings$ = this.settingsSubject.asObservable();
        this.endedBy$ = this.endedBySubject.asObservable();
        this.thumbnails$ = this.thumbnailsSubject.asObservable();
        /**
         * Performs shallow comparison of two arrays.
         * Expects primitive values: [1, 2, 3] is equal to [2, 1, 3].
         */
        const isShallowEqual = (a, b) => {
            if (a.length !== b.length)
                return false;
            for (const item of a)
                if (!b.includes(item))
                    return false;
            for (const item of b)
                if (!a.includes(item))
                    return false;
            return true;
        };
        /**
         * Creates an Observable from the given subject by piping to the
         * `distinctUntilChanged()` operator.
         */
        const duc = (subject, comparator) => subject.asObservable().pipe(rxjs.distinctUntilChanged(comparator));
        // primitive values should only emit once the value they hold changes
        this.anonymousParticipantCount$ = duc(this.anonymousParticipantCountSubject);
        this.blockedUserIds$ = duc(this.blockedUserIdsSubject, isShallowEqual);
        this.backstage$ = duc(this.backstageSubject);
        this.callingState$ = duc(this.callingStateSubject);
        this.ownCapabilities$ = duc(this.ownCapabilitiesSubject, isShallowEqual);
        this.participantCount$ = duc(this.participantCountSubject);
        this.recording$ = duc(this.recordingSubject);
        this.transcribing$ = duc(this.transcribingSubject);
        this.eventHandlers = {
            // these events are not updating the call state:
            'call.closed_caption': undefined,
            'call.deleted': undefined,
            'call.permission_request': undefined,
            'call.recording_failed': undefined,
            'call.recording_ready': undefined,
            'call.transcription_ready': undefined,
            'call.user_muted': undefined,
            'connection.error': undefined,
            'connection.ok': undefined,
            'health.check': undefined,
            custom: undefined,
            // events that update call state:
            'call.accepted': (e) => this.updateFromCallResponse(e.call),
            'call.blocked_user': this.blockUser,
            'call.created': (e) => this.updateFromCallResponse(e.call),
            'call.ended': (e) => {
                this.updateFromCallResponse(e.call);
                this.setCurrentValue(this.endedBySubject, e.user);
            },
            'call.hls_broadcasting_failed': this.updateFromHLSBroadcastingFailed,
            'call.hls_broadcasting_started': this.updateFromHLSBroadcastStarted,
            'call.hls_broadcasting_stopped': this.updateFromHLSBroadcastStopped,
            'call.live_started': (e) => this.updateFromCallResponse(e.call),
            'call.member_added': this.updateFromMemberAdded,
            'call.member_removed': this.updateFromMemberRemoved,
            'call.member_updated_permission': this.updateMembers,
            'call.member_updated': this.updateMembers,
            'call.notification': (e) => {
                this.updateFromCallResponse(e.call);
                this.setMembers(e.members);
            },
            'call.permissions_updated': this.updateOwnCapabilities,
            'call.reaction_new': this.updateParticipantReaction,
            'call.recording_started': () => this.setCurrentValue(this.recordingSubject, true),
            'call.recording_stopped': () => this.setCurrentValue(this.recordingSubject, false),
            'call.rejected': (e) => this.updateFromCallResponse(e.call),
            'call.ring': (e) => this.updateFromCallResponse(e.call),
            'call.session_ended': (e) => this.updateFromCallResponse(e.call),
            'call.session_participant_joined': this.updateFromSessionParticipantJoined,
            'call.session_participant_left': this.updateFromSessionParticipantLeft,
            'call.session_started': (e) => this.updateFromCallResponse(e.call),
            'call.transcription_started': () => {
                this.setCurrentValue(this.transcribingSubject, true);
            },
            'call.transcription_stopped': () => {
                this.setCurrentValue(this.transcribingSubject, false);
            },
            'call.transcription_failed': () => {
                this.setCurrentValue(this.transcribingSubject, false);
            },
            'call.unblocked_user': this.unblockUser,
            'call.updated': (e) => this.updateFromCallResponse(e.call),
        };
    }
    /**
     * The server-side counted number of participants connected to the current call.
     * This number includes the anonymous participants as well.
     */
    get participantCount() {
        return this.getCurrentValue(this.participantCount$);
    }
    /**
     * The time the call session actually started.
     * Useful for displaying the call duration.
     */
    get startedAt() {
        return this.getCurrentValue(this.startedAt$);
    }
    /**
     * The server-side counted number of anonymous participants connected to the current call.
     * This number includes the anonymous participants as well.
     */
    get anonymousParticipantCount() {
        return this.getCurrentValue(this.anonymousParticipantCount$);
    }
    /**
     * The list of participants in the current call.
     */
    get participants() {
        return this.getCurrentValue(this.participants$);
    }
    /**
     * The local participant in the current call.
     */
    get localParticipant() {
        return this.getCurrentValue(this.localParticipant$);
    }
    /**
     * The list of remote participants in the current call.
     */
    get remoteParticipants() {
        return this.getCurrentValue(this.remoteParticipants$);
    }
    /**
     * The dominant speaker in the current call.
     */
    get dominantSpeaker() {
        return this.getCurrentValue(this.dominantSpeaker$);
    }
    /**
     * The list of pinned participants in the current call.
     */
    get pinnedParticipants() {
        return this.getCurrentValue(this.pinnedParticipants$);
    }
    /**
     * Tell if there is an ongoing screen share in this call.
     */
    get hasOngoingScreenShare() {
        return this.getCurrentValue(this.hasOngoingScreenShare$);
    }
    /**
     * The calling state.
     */
    get callingState() {
        return this.getCurrentValue(this.callingState$);
    }
    /**
     * The call stats report.
     */
    get callStatsReport() {
        return this.getCurrentValue(this.callStatsReport$);
    }
    /**
     * The members of the current call.
     */
    get members() {
        return this.getCurrentValue(this.members$);
    }
    /**
     * The capabilities of the current user for the current call.
     */
    get ownCapabilities() {
        return this.getCurrentValue(this.ownCapabilities$);
    }
    /**
     * The backstage state.
     */
    get backstage() {
        return this.getCurrentValue(this.backstage$);
    }
    /**
     * Will provide the list of blocked user IDs.
     */
    get blockedUserIds() {
        return this.getCurrentValue(this.blockedUserIds$);
    }
    /**
     * Will provide the time when this call has been created.
     */
    get createdAt() {
        return this.getCurrentValue(this.createdAt$);
    }
    /**
     * Will provide the time when this call has been ended.
     */
    get endedAt() {
        return this.getCurrentValue(this.endedAt$);
    }
    /**
     * Will provide the time when this call has been scheduled to start.
     */
    get startsAt() {
        return this.getCurrentValue(this.startsAt$);
    }
    /**
     * Will provide the time when this call has been updated.
     */
    get updatedAt() {
        return this.getCurrentValue(this.updatedAt$);
    }
    /**
     * Will provide the user who created this call.
     */
    get createdBy() {
        return this.getCurrentValue(this.createdBy$);
    }
    /**
     * Will provide the custom data of this call.
     */
    get custom() {
        return this.getCurrentValue(this.custom$);
    }
    /**
     * Will provide the egress data of this call.
     */
    get egress() {
        return this.getCurrentValue(this.egress$);
    }
    /**
     * Will provide the ingress data of this call.
     */
    get ingress() {
        return this.getCurrentValue(this.ingress$);
    }
    /**
     * Will provide the recording state of this call.
     */
    get recording() {
        return this.getCurrentValue(this.recording$);
    }
    /**
     * Will provide the session data of this call.
     */
    get session() {
        return this.getCurrentValue(this.session$);
    }
    /**
     * Will provide the settings of this call.
     */
    get settings() {
        return this.getCurrentValue(this.settings$);
    }
    /**
     * Will provide the transcribing state of this call.
     */
    get transcribing() {
        return this.getCurrentValue(this.transcribing$);
    }
    /**
     * Will provide the user who ended this call.
     */
    get endedBy() {
        return this.getCurrentValue(this.endedBy$);
    }
    /**
     * Will provide the thumbnails of this call, if enabled in the call settings.
     */
    get thumbnails() {
        return this.getCurrentValue(this.thumbnails$);
    }
}

class StreamVideoWriteableStateStore {
    constructor() {
        /**
         * A store keeping data of a successfully connected user over WS to the coordinator server.
         */
        this.connectedUserSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * A list of {@link Call} objects created/tracked by this client.
         */
        this.callsSubject = new rxjs.BehaviorSubject([]);
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        /**
         * Sets the currently connected user.
         *
         * @internal
         * @param user the user to set as connected.
         */
        this.setConnectedUser = (user) => {
            return this.setCurrentValue(this.connectedUserSubject, user);
        };
        /**
         * Sets the list of {@link Call} objects created/tracked by this client.
         * @param calls
         */
        this.setCalls = (calls) => {
            return this.setCurrentValue(this.callsSubject, calls);
        };
        /**
         * Adds a {@link Call} object to the list of {@link Call} objects created/tracked by this client.
         *
         * @param call the call to add.
         */
        this.registerCall = (call) => {
            if (!this.calls.find((c) => c.cid === call.cid)) {
                this.setCalls((calls) => [...calls, call]);
            }
        };
        /**
         * Removes a {@link Call} object from the list of {@link Call} objects created/tracked by this client.
         *
         * @param call the call to remove
         */
        this.unregisterCall = (call) => {
            return this.setCalls((calls) => calls.filter((c) => c !== call));
        };
        /**
         * Finds a {@link Call} object in the list of {@link Call} objects created/tracked by this client.
         *
         * @param type the type of call to find.
         * @param id the id of the call to find.
         */
        this.findCall = (type, id) => {
            return this.calls.find((c) => c.type === type && c.id === id);
        };
        this.connectedUserSubject.subscribe(async (user) => {
            // leave all calls when the user disconnects.
            if (!user) {
                const logger = getLogger(['client-state']);
                for (const call of this.calls) {
                    if (call.state.callingState === exports.CallingState.LEFT)
                        continue;
                    logger('info', `User disconnected, leaving call: ${call.cid}`);
                    await call
                        .leave({ reason: 'client.disconnectUser() called' })
                        .catch((err) => {
                        logger('error', `Error leaving call: ${call.cid}`, err);
                    });
                }
            }
        });
    }
    /**
     * The currently connected user.
     */
    get connectedUser() {
        return this.getCurrentValue(this.connectedUserSubject);
    }
    /**
     * A list of {@link Call} objects created/tracked by this client.
     */
    get calls() {
        return this.getCurrentValue(this.callsSubject);
    }
}
/**
 * A reactive store that exposes state variables in a reactive manner.
 * You can subscribe to changes of the different state variables.
 * This central store contains all the state variables related to [`StreamVideoClient`](./StreamVideClient.md) and [`Call`](./Call.md).
 */
class StreamVideoReadOnlyStateStore {
    constructor(store) {
        /**
         * This method allows you the get the current value of a state variable.
         *
         * @param observable the observable to get the current value of.
         * @returns the current value of the observable.
         */
        this.getCurrentValue = getCurrentValue;
        // convert and expose subjects as observables
        this.connectedUser$ = store.connectedUserSubject.asObservable();
        this.calls$ = store.callsSubject.asObservable();
    }
    /**
     * The current user connected over WS to the backend.
     */
    get connectedUser() {
        return getCurrentValue(this.connectedUser$);
    }
    /**
     * A list of {@link Call} objects created/tracked by this client.
     */
    get calls() {
        return getCurrentValue(this.calls$);
    }
}

const getRtpMap = (line) => {
    // Example: a=rtpmap:110 opus/48000/2
    const rtpRegex = /^a=rtpmap:(\d*) ([\w\-.]*)(?:\s*\/(\d*)(?:\s*\/(\S*))?)?/;
    // The first captured group is the payload type number, the second captured group is the encoding name, the third captured group is the clock rate, and the fourth captured group is any additional parameters.
    const rtpMatch = rtpRegex.exec(line);
    if (rtpMatch) {
        return {
            original: rtpMatch[0],
            payload: rtpMatch[1],
            codec: rtpMatch[2],
        };
    }
};
const getFmtp = (line) => {
    // Example: a=fmtp:111 minptime=10; useinbandfec=1
    const fmtpRegex = /^a=fmtp:(\d*) (.*)/;
    const fmtpMatch = fmtpRegex.exec(line);
    // The first captured group is the payload type number, the second captured group is any additional parameters.
    if (fmtpMatch) {
        return {
            original: fmtpMatch[0],
            payload: fmtpMatch[1],
            config: fmtpMatch[2],
        };
    }
};
/**
 * gets the media section for the specified media type.
 * The media section contains the media type, port, codec, and payload type.
 * Example: m=video 9 UDP/TLS/RTP/SAVPF 100 101 96 97 35 36 102 125 127
 */
const getMedia = (line, mediaType) => {
    const regex = new RegExp(`(m=${mediaType} \\d+ [\\w/]+) ([\\d\\s]+)`);
    const match = regex.exec(line);
    if (match) {
        return {
            original: match[0],
            mediaWithPorts: match[1],
            codecOrder: match[2],
        };
    }
};
const getMediaSection = (sdp, mediaType) => {
    let media;
    const rtpMap = [];
    const fmtp = [];
    let isTheRequiredMediaSection = false;
    sdp.split(/(\r\n|\r|\n)/).forEach((line) => {
        const isValidLine = /^([a-z])=(.*)/.test(line);
        if (!isValidLine)
            return;
        /*
          NOTE: according to https://www.rfc-editor.org/rfc/rfc8866.pdf
          Each media description starts with an "m=" line and continues to the next media description or the end of the whole session description, whichever comes first
        */
        const type = line[0];
        if (type === 'm') {
            const _media = getMedia(line, mediaType);
            isTheRequiredMediaSection = !!_media;
            if (_media) {
                media = _media;
            }
        }
        else if (isTheRequiredMediaSection && type === 'a') {
            const rtpMapLine = getRtpMap(line);
            const fmtpLine = getFmtp(line);
            if (rtpMapLine) {
                rtpMap.push(rtpMapLine);
            }
            else if (fmtpLine) {
                fmtp.push(fmtpLine);
            }
        }
    });
    if (media) {
        return {
            media,
            rtpMap,
            fmtp,
        };
    }
};
/**
 * Gets the fmtp line corresponding to opus
 */
const getOpusFmtp = (sdp) => {
    const section = getMediaSection(sdp, 'audio');
    const rtpMap = section?.rtpMap.find((r) => r.codec.toLowerCase() === 'opus');
    const codecId = rtpMap?.payload;
    if (codecId) {
        return section?.fmtp.find((f) => f.payload === codecId);
    }
};
/**
 * Returns an SDP with DTX enabled or disabled.
 */
const toggleDtx = (sdp, enable) => {
    const opusFmtp = getOpusFmtp(sdp);
    if (opusFmtp) {
        const matchDtx = /usedtx=(\d)/.exec(opusFmtp.config);
        const requiredDtxConfig = `usedtx=${enable ? '1' : '0'}`;
        if (matchDtx) {
            const newFmtp = opusFmtp.original.replace(/usedtx=(\d)/, requiredDtxConfig);
            return sdp.replace(opusFmtp.original, newFmtp);
        }
        else {
            const newFmtp = `${opusFmtp.original};${requiredDtxConfig}`;
            return sdp.replace(opusFmtp.original, newFmtp);
        }
    }
    return sdp;
};
/**
 * Enables high-quality audio through SDP munging for the given trackMid.
 *
 * @param sdp the SDP to munge.
 * @param trackMid the trackMid.
 * @param maxBitrate the max bitrate to set.
 */
const enableHighQualityAudio = (sdp, trackMid, maxBitrate = 510000) => {
    maxBitrate = Math.max(Math.min(maxBitrate, 510000), 96000);
    const parsedSdp = SDP__namespace.parse(sdp);
    const audioMedia = parsedSdp.media.find((m) => m.type === 'audio' && String(m.mid) === trackMid);
    if (!audioMedia)
        return sdp;
    const opusRtp = audioMedia.rtp.find((r) => r.codec === 'opus');
    if (!opusRtp)
        return sdp;
    const opusFmtp = audioMedia.fmtp.find((f) => f.payload === opusRtp.payload);
    if (!opusFmtp)
        return sdp;
    // enable stereo, if not already enabled
    if (opusFmtp.config.match(/stereo=(\d)/)) {
        opusFmtp.config = opusFmtp.config.replace(/stereo=(\d)/, 'stereo=1');
    }
    else {
        opusFmtp.config = `${opusFmtp.config};stereo=1`;
    }
    // set maxaveragebitrate, to the given value
    if (opusFmtp.config.match(/maxaveragebitrate=(\d*)/)) {
        opusFmtp.config = opusFmtp.config.replace(/maxaveragebitrate=(\d*)/, `maxaveragebitrate=${maxBitrate}`);
    }
    else {
        opusFmtp.config = `${opusFmtp.config};maxaveragebitrate=${maxBitrate}`;
    }
    return SDP__namespace.write(parsedSdp);
};

const logger$3 = getLogger(['Publisher']);
/**
 * The `Publisher` is responsible for publishing/unpublishing media streams to/from the SFU
 * @internal
 */
class Publisher {
    /**
     * Returns the current connection configuration.
     *
     * @internal
     */
    get connectionConfiguration() {
        if (this.pc.getConfiguration)
            return this.pc.getConfiguration();
        return this._connectionConfiguration;
    }
    /**
     * Constructs a new `Publisher` instance.
     *
     * @param connectionConfig the connection configuration to use.
     * @param sfuClient the SFU client to use.
     * @param state the call state to use.
     * @param dispatcher the dispatcher to use.
     * @param isDtxEnabled whether DTX is enabled.
     * @param isRedEnabled whether RED is enabled.
     * @param iceRestartDelay the delay in milliseconds to wait before restarting ICE once connection goes to `disconnected` state.
     */
    constructor({ connectionConfig, sfuClient, dispatcher, state, isDtxEnabled, isRedEnabled, iceRestartDelay = 2500, }) {
        this.transceiverRegistry = {
            [TrackType.AUDIO]: undefined,
            [TrackType.VIDEO]: undefined,
            [TrackType.SCREEN_SHARE]: undefined,
            [TrackType.SCREEN_SHARE_AUDIO]: undefined,
            [TrackType.UNSPECIFIED]: undefined,
        };
        this.publishOptionsPerTrackType = new Map();
        /**
         * An array maintaining the order how transceivers were added to the peer connection.
         * This is needed because some browsers (Firefox) don't reliably report
         * trackId and `mid` parameters.
         *
         * @private
         */
        this.transceiverInitOrder = [];
        this.trackKindMapping = {
            [TrackType.AUDIO]: 'audio',
            [TrackType.VIDEO]: 'video',
            [TrackType.SCREEN_SHARE]: 'video',
            [TrackType.SCREEN_SHARE_AUDIO]: 'audio',
            [TrackType.UNSPECIFIED]: undefined,
        };
        this.trackLayersCache = {
            [TrackType.AUDIO]: undefined,
            [TrackType.VIDEO]: undefined,
            [TrackType.SCREEN_SHARE]: undefined,
            [TrackType.SCREEN_SHARE_AUDIO]: undefined,
            [TrackType.UNSPECIFIED]: undefined,
        };
        this.isIceRestarting = false;
        this.createPeerConnection = (connectionConfig) => {
            const pc = new RTCPeerConnection(connectionConfig);
            this._connectionConfiguration = connectionConfig;
            pc.addEventListener('icecandidate', this.onIceCandidate);
            pc.addEventListener('negotiationneeded', this.onNegotiationNeeded);
            pc.addEventListener('icecandidateerror', this.onIceCandidateError);
            pc.addEventListener('iceconnectionstatechange', this.onIceConnectionStateChange);
            pc.addEventListener('icegatheringstatechange', this.onIceGatheringStateChange);
            pc.addEventListener('signalingstatechange', this.onSignalingStateChange);
            return pc;
        };
        /**
         * Closes the publisher PeerConnection and cleans up the resources.
         */
        this.close = ({ stopTracks = true } = {}) => {
            if (stopTracks) {
                this.stopPublishing();
                Object.keys(this.transceiverRegistry).forEach((trackType) => {
                    // @ts-ignore
                    this.transceiverRegistry[trackType] = undefined;
                });
                Object.keys(this.trackLayersCache).forEach((trackType) => {
                    // @ts-ignore
                    this.trackLayersCache[trackType] = undefined;
                });
            }
            clearTimeout(this.iceRestartTimeout);
            this.unsubscribeOnIceRestart();
            this.pc.removeEventListener('negotiationneeded', this.onNegotiationNeeded);
            this.pc.close();
        };
        /**
         * Starts publishing the given track of the given media stream.
         *
         * Consecutive calls to this method will replace the stream.
         * The previous stream will be stopped.
         *
         * @param mediaStream the media stream to publish.
         * @param track the track to publish.
         * @param trackType the track type to publish.
         * @param opts the optional publish options to use.
         */
        this.publishStream = async (mediaStream, track, trackType, opts = {}) => {
            if (track.readyState === 'ended') {
                throw new Error(`Can't publish a track that has ended already.`);
            }
            let transceiver = this.pc
                .getTransceivers()
                .find((t) => t === this.transceiverRegistry[trackType] &&
                t.sender.track &&
                t.sender.track?.kind === this.trackKindMapping[trackType]);
            /**
             * An event handler which listens for the 'ended' event on the track.
             * Once the track has ended, it will notify the SFU and update the state.
             */
            const handleTrackEnded = async () => {
                logger$3('info', `Track ${TrackType[trackType]} has ended, notifying the SFU`);
                await this.notifyTrackMuteStateChanged(mediaStream, trackType, true);
                // clean-up, this event listener needs to run only once.
                track.removeEventListener('ended', handleTrackEnded);
            };
            if (!transceiver) {
                const { settings } = this.state;
                const targetResolution = settings?.video.target_resolution;
                const screenShareBitrate = settings?.screensharing.target_resolution?.bitrate;
                const videoEncodings = trackType === TrackType.VIDEO
                    ? findOptimalVideoLayers(track, targetResolution)
                    : trackType === TrackType.SCREEN_SHARE
                        ? findOptimalScreenSharingLayers(track, opts.screenShareSettings, screenShareBitrate)
                        : undefined;
                let preferredCodec = opts.preferredCodec;
                if (!preferredCodec && trackType === TrackType.VIDEO) {
                    if (isReactNative()) {
                        const osName = getOSInfo()?.name.toLowerCase();
                        if (osName === 'ipados') {
                            // in ipads it was noticed that if vp8 codec is used
                            // then the bytes sent is 0 in the outbound-rtp
                            // so we are forcing h264 codec for ipads
                            preferredCodec = 'H264';
                        }
                        else if (osName === 'android') {
                            preferredCodec = 'VP8';
                        }
                    }
                }
                const codecPreferences = this.getCodecPreferences(trackType, preferredCodec);
                // listen for 'ended' event on the track as it might be ended abruptly
                // by an external factor as permission revokes, device disconnected, etc.
                // keep in mind that `track.stop()` doesn't trigger this event.
                track.addEventListener('ended', handleTrackEnded);
                if (!track.enabled) {
                    track.enabled = true;
                }
                transceiver = this.pc.addTransceiver(track, {
                    direction: 'sendonly',
                    streams: trackType === TrackType.VIDEO || trackType === TrackType.SCREEN_SHARE
                        ? [mediaStream]
                        : undefined,
                    sendEncodings: videoEncodings,
                });
                logger$3('debug', `Added ${TrackType[trackType]} transceiver`);
                this.transceiverInitOrder.push(trackType);
                this.transceiverRegistry[trackType] = transceiver;
                this.publishOptionsPerTrackType.set(trackType, opts);
                if ('setCodecPreferences' in transceiver && codecPreferences) {
                    logger$3('info', `Setting ${TrackType[trackType]} codec preferences`, codecPreferences);
                    try {
                        transceiver.setCodecPreferences(codecPreferences);
                    }
                    catch (err) {
                        logger$3('warn', `Couldn't set codec preferences`, err);
                    }
                }
            }
            else {
                const previousTrack = transceiver.sender.track;
                // don't stop the track if we are re-publishing the same track
                if (previousTrack && previousTrack !== track) {
                    previousTrack.stop();
                    previousTrack.removeEventListener('ended', handleTrackEnded);
                    track.addEventListener('ended', handleTrackEnded);
                }
                if (!track.enabled) {
                    track.enabled = true;
                }
                await transceiver.sender.replaceTrack(track);
            }
            await this.notifyTrackMuteStateChanged(mediaStream, trackType, false);
        };
        /**
         * Stops publishing the given track type to the SFU, if it is currently being published.
         * Underlying track will be stopped and removed from the publisher.
         * @param trackType the track type to unpublish.
         * @param stopTrack specifies whether track should be stopped or just disabled
         */
        this.unpublishStream = async (trackType, stopTrack) => {
            const transceiver = this.pc
                .getTransceivers()
                .find((t) => t === this.transceiverRegistry[trackType] && t.sender.track);
            if (transceiver &&
                transceiver.sender.track &&
                (stopTrack
                    ? transceiver.sender.track.readyState === 'live'
                    : transceiver.sender.track.enabled)) {
                stopTrack
                    ? transceiver.sender.track.stop()
                    : (transceiver.sender.track.enabled = false);
                // We don't need to notify SFU if unpublishing in response to remote soft mute
                if (this.state.localParticipant?.publishedTracks.includes(trackType)) {
                    await this.notifyTrackMuteStateChanged(undefined, trackType, true);
                }
            }
        };
        /**
         * Returns true if the given track type is currently being published to the SFU.
         *
         * @param trackType the track type to check.
         */
        this.isPublishing = (trackType) => {
            const transceiverForTrackType = this.transceiverRegistry[trackType];
            if (transceiverForTrackType && transceiverForTrackType.sender) {
                const sender = transceiverForTrackType.sender;
                return (!!sender.track &&
                    sender.track.readyState === 'live' &&
                    sender.track.enabled);
            }
            return false;
        };
        /**
         * Returns true if the given track type is currently live
         *
         * @param trackType the track type to check.
         */
        this.isLive = (trackType) => {
            const transceiverForTrackType = this.transceiverRegistry[trackType];
            if (transceiverForTrackType && transceiverForTrackType.sender) {
                const sender = transceiverForTrackType.sender;
                return !!sender.track && sender.track.readyState === 'live';
            }
            return false;
        };
        this.notifyTrackMuteStateChanged = async (mediaStream, trackType, isMuted) => {
            await this.sfuClient.updateMuteState(trackType, isMuted);
            const audioOrVideoOrScreenShareStream = trackTypeToParticipantStreamKey(trackType);
            if (isMuted) {
                this.state.updateParticipant(this.sfuClient.sessionId, (p) => ({
                    publishedTracks: p.publishedTracks.filter((t) => t !== trackType),
                    [audioOrVideoOrScreenShareStream]: undefined,
                }));
            }
            else {
                this.state.updateParticipant(this.sfuClient.sessionId, (p) => {
                    return {
                        publishedTracks: p.publishedTracks.includes(trackType)
                            ? p.publishedTracks
                            : [...p.publishedTracks, trackType],
                        [audioOrVideoOrScreenShareStream]: mediaStream,
                    };
                });
            }
        };
        /**
         * Stops publishing all tracks and stop all tracks.
         */
        this.stopPublishing = () => {
            logger$3('debug', 'Stopping publishing all tracks');
            this.pc.getSenders().forEach((s) => {
                s.track?.stop();
                if (this.pc.signalingState !== 'closed') {
                    this.pc.removeTrack(s);
                }
            });
        };
        this.updateVideoPublishQuality = async (enabledLayers) => {
            logger$3('info', 'Update publish quality, requested layers by SFU:', enabledLayers);
            const videoSender = this.transceiverRegistry[TrackType.VIDEO]?.sender;
            if (!videoSender) {
                logger$3('warn', 'Update publish quality, no video sender found.');
                return;
            }
            const params = videoSender.getParameters();
            if (params.encodings.length === 0) {
                logger$3('warn', 'Update publish quality, No suitable video encoding quality found');
                return;
            }
            let changed = false;
            let enabledRids = enabledLayers
                .filter((ly) => ly.active)
                .map((ly) => ly.name);
            params.encodings.forEach((enc) => {
                // flip 'active' flag only when necessary
                const shouldEnable = enabledRids.includes(enc.rid);
                if (shouldEnable !== enc.active) {
                    enc.active = shouldEnable;
                    changed = true;
                }
                if (shouldEnable) {
                    let layer = enabledLayers.find((vls) => vls.name === enc.rid);
                    if (layer !== undefined) {
                        if (layer.scaleResolutionDownBy >= 1 &&
                            layer.scaleResolutionDownBy !== enc.scaleResolutionDownBy) {
                            logger$3('debug', '[dynascale]: setting scaleResolutionDownBy from server', 'layer', layer.name, 'scale-resolution-down-by', layer.scaleResolutionDownBy);
                            enc.scaleResolutionDownBy = layer.scaleResolutionDownBy;
                            changed = true;
                        }
                        if (layer.maxBitrate > 0 && layer.maxBitrate !== enc.maxBitrate) {
                            logger$3('debug', '[dynascale] setting max-bitrate from the server', 'layer', layer.name, 'max-bitrate', layer.maxBitrate);
                            enc.maxBitrate = layer.maxBitrate;
                            changed = true;
                        }
                        if (layer.maxFramerate > 0 &&
                            layer.maxFramerate !== enc.maxFramerate) {
                            logger$3('debug', '[dynascale]: setting maxFramerate from server', 'layer', layer.name, 'max-framerate', layer.maxFramerate);
                            enc.maxFramerate = layer.maxFramerate;
                            changed = true;
                        }
                    }
                }
            });
            const activeLayers = params.encodings.filter((e) => e.active);
            if (changed) {
                await videoSender.setParameters(params);
                logger$3('info', `Update publish quality, enabled rids: `, activeLayers);
            }
            else {
                logger$3('info', `Update publish quality, no change: `, activeLayers);
            }
        };
        /**
         * Returns the result of the `RTCPeerConnection.getStats()` method
         * @param selector
         * @returns
         */
        this.getStats = (selector) => {
            return this.pc.getStats(selector);
        };
        this.getCodecPreferences = (trackType, preferredCodec) => {
            if (trackType === TrackType.VIDEO) {
                return getPreferredCodecs('video', preferredCodec || 'vp8');
            }
            if (trackType === TrackType.AUDIO) {
                const defaultAudioCodec = this.isRedEnabled ? 'red' : 'opus';
                const codecToRemove = !this.isRedEnabled ? 'red' : undefined;
                return getPreferredCodecs('audio', preferredCodec ?? defaultAudioCodec, codecToRemove);
            }
        };
        this.onIceCandidate = (e) => {
            const { candidate } = e;
            if (!candidate) {
                logger$3('debug', 'null ice candidate');
                return;
            }
            this.sfuClient
                .iceTrickle({
                iceCandidate: getIceCandidate(candidate),
                peerType: PeerType.PUBLISHER_UNSPECIFIED,
            })
                .catch((err) => {
                logger$3('warn', `ICETrickle failed`, err);
            });
        };
        /**
         * Sets the SFU client to use.
         *
         * @param sfuClient the SFU client to use.
         */
        this.setSfuClient = (sfuClient) => {
            this.sfuClient = sfuClient;
        };
        /**
         * Performs a migration of this publisher instance to a new SFU.
         *
         * Initiates a new `iceRestart` offer/answer exchange with the new SFU.
         *
         * @param sfuClient the new SFU client to migrate to.
         * @param connectionConfig the new connection configuration to use.
         */
        this.migrateTo = async (sfuClient, connectionConfig) => {
            this.sfuClient = sfuClient;
            this.pc.setConfiguration(connectionConfig);
            this._connectionConfiguration = connectionConfig;
            const shouldRestartIce = this.pc.iceConnectionState === 'connected';
            if (shouldRestartIce) {
                // negotiate only if there are tracks to publish
                await this.negotiate({ iceRestart: true });
            }
        };
        /**
         * Restarts the ICE connection and renegotiates with the SFU.
         */
        this.restartIce = async () => {
            logger$3('debug', 'Restarting ICE connection');
            const signalingState = this.pc.signalingState;
            if (this.isIceRestarting || signalingState === 'have-local-offer') {
                logger$3('debug', 'ICE restart is already in progress');
                return;
            }
            await this.negotiate({ iceRestart: true });
        };
        this.onNegotiationNeeded = () => {
            this.negotiate().catch((err) => logger$3('warn', `Negotiation failed.`, err));
        };
        /**
         * Initiates a new offer/answer exchange with the currently connected SFU.
         *
         * @param options the optional offer options to use.
         */
        this.negotiate = async (options) => {
            this.isIceRestarting = options?.iceRestart ?? false;
            const offer = await this.pc.createOffer(options);
            let sdp = this.mungeCodecs(offer.sdp);
            if (sdp && this.isPublishing(TrackType.SCREEN_SHARE_AUDIO)) {
                const transceiver = this.transceiverRegistry[TrackType.SCREEN_SHARE_AUDIO];
                if (transceiver && transceiver.sender.track) {
                    const mid = transceiver.mid ??
                        this.extractMid(sdp, transceiver.sender.track, TrackType.SCREEN_SHARE_AUDIO);
                    sdp = enableHighQualityAudio(sdp, mid);
                }
            }
            // set the munged SDP back to the offer
            offer.sdp = sdp;
            const trackInfos = this.getCurrentTrackInfos(offer.sdp);
            if (trackInfos.length === 0) {
                throw new Error(`Can't initiate negotiation without announcing any tracks`);
            }
            await this.pc.setLocalDescription(offer);
            const { response } = await this.sfuClient.setPublisher({
                sdp: offer.sdp || '',
                tracks: trackInfos,
            });
            try {
                await this.pc.setRemoteDescription({
                    type: 'answer',
                    sdp: response.sdp,
                });
            }
            catch (e) {
                logger$3('error', `setRemoteDescription error`, {
                    sdp: response.sdp,
                    error: e,
                });
            }
            this.isIceRestarting = false;
            this.sfuClient.iceTrickleBuffer.publisherCandidates.subscribe(async (candidate) => {
                try {
                    const iceCandidate = JSON.parse(candidate.iceCandidate);
                    await this.pc.addIceCandidate(iceCandidate);
                }
                catch (e) {
                    logger$3('warn', `ICE candidate error`, [e, candidate]);
                }
            });
        };
        this.mungeCodecs = (sdp) => {
            if (sdp) {
                sdp = toggleDtx(sdp, this.isDtxEnabled);
            }
            return sdp;
        };
        this.extractMid = (sdp, track, trackType) => {
            if (!sdp) {
                logger$3('warn', 'No SDP found. Returning empty mid');
                return '';
            }
            logger$3('debug', `No 'mid' found for track. Trying to find it from the Offer SDP`);
            const parsedSdp = SDP__namespace.parse(sdp);
            const media = parsedSdp.media.find((m) => {
                return (m.type === track.kind &&
                    // if `msid` is not present, we assume that the track is the first one
                    (m.msid?.includes(track.id) ?? true));
            });
            if (typeof media?.mid === 'undefined') {
                logger$3('debug', `No mid found in SDP for track type ${track.kind} and id ${track.id}. Attempting to find a heuristic mid`);
                const heuristicMid = this.transceiverInitOrder.indexOf(trackType);
                if (heuristicMid !== -1) {
                    return String(heuristicMid);
                }
                logger$3('debug', 'No heuristic mid found. Returning empty mid');
                return '';
            }
            return String(media.mid);
        };
        this.getCurrentTrackInfos = (sdp) => {
            sdp = sdp || this.pc.localDescription?.sdp;
            const { settings } = this.state;
            const targetResolution = settings?.video.target_resolution;
            return this.pc
                .getTransceivers()
                .filter((t) => t.direction === 'sendonly' && t.sender.track)
                .map((transceiver) => {
                const trackType = Number(Object.keys(this.transceiverRegistry).find((key) => this.transceiverRegistry[key] === transceiver));
                const track = transceiver.sender.track;
                let optimalLayers;
                if (track.readyState === 'live') {
                    const publishOpts = this.publishOptionsPerTrackType.get(trackType);
                    optimalLayers =
                        trackType === TrackType.VIDEO
                            ? findOptimalVideoLayers(track, targetResolution)
                            : trackType === TrackType.SCREEN_SHARE
                                ? findOptimalScreenSharingLayers(track, publishOpts?.screenShareSettings)
                                : [];
                    this.trackLayersCache[trackType] = optimalLayers;
                }
                else {
                    // we report the last known optimal layers for ended tracks
                    optimalLayers = this.trackLayersCache[trackType] || [];
                    logger$3('debug', `Track ${TrackType[trackType]} is ended. Announcing last known optimal layers`, optimalLayers);
                }
                const layers = optimalLayers.map((optimalLayer) => ({
                    rid: optimalLayer.rid || '',
                    bitrate: optimalLayer.maxBitrate || 0,
                    fps: optimalLayer.maxFramerate || 0,
                    quality: this.ridToVideoQuality(optimalLayer.rid || ''),
                    videoDimension: {
                        width: optimalLayer.width,
                        height: optimalLayer.height,
                    },
                }));
                const isAudioTrack = [
                    TrackType.AUDIO,
                    TrackType.SCREEN_SHARE_AUDIO,
                ].includes(trackType);
                const trackSettings = track.getSettings();
                const isStereo = isAudioTrack && trackSettings.channelCount === 2;
                return {
                    trackId: track.id,
                    layers: layers,
                    trackType,
                    mid: transceiver.mid ?? this.extractMid(sdp, track, trackType),
                    stereo: isStereo,
                    dtx: isAudioTrack && this.isDtxEnabled,
                    red: isAudioTrack && this.isRedEnabled,
                };
            });
        };
        this.onIceCandidateError = (e) => {
            const errorMessage = e instanceof RTCPeerConnectionIceErrorEvent &&
                `${e.errorCode}: ${e.errorText}`;
            const iceState = this.pc.iceConnectionState;
            const logLevel = iceState === 'connected' || iceState === 'checking' ? 'debug' : 'warn';
            logger$3(logLevel, `ICE Candidate error`, errorMessage);
        };
        this.onIceConnectionStateChange = () => {
            const state = this.pc.iceConnectionState;
            logger$3('debug', `ICE Connection state changed to`, state);
            const hasNetworkConnection = this.state.callingState !== exports.CallingState.OFFLINE;
            if (state === 'failed') {
                logger$3('warn', `Attempting to restart ICE`);
                this.restartIce().catch((e) => {
                    logger$3('error', `ICE restart error`, e);
                });
            }
            else if (state === 'disconnected' && hasNetworkConnection) {
                // when in `disconnected` state, the browser may recover automatically,
                // hence, we delay the ICE restart
                logger$3('warn', `Scheduling ICE restart in ${this.iceRestartDelay} ms.`);
                this.iceRestartTimeout = setTimeout(() => {
                    // check if the state is still `disconnected` or `failed`
                    // as the connection may have recovered (or failed) in the meantime
                    if (this.pc.iceConnectionState === 'disconnected' ||
                        this.pc.iceConnectionState === 'failed') {
                        this.restartIce().catch((e) => {
                            logger$3('error', `ICE restart error`, e);
                        });
                    }
                    else {
                        logger$3('debug', `Scheduled ICE restart: connection recovered, canceled.`);
                    }
                }, this.iceRestartDelay);
            }
        };
        this.onIceGatheringStateChange = () => {
            logger$3('debug', `ICE Gathering State`, this.pc.iceGatheringState);
        };
        this.onSignalingStateChange = () => {
            logger$3('debug', `Signaling state changed`, this.pc.signalingState);
        };
        this.ridToVideoQuality = (rid) => {
            return rid === 'q'
                ? VideoQuality.LOW_UNSPECIFIED
                : rid === 'h'
                    ? VideoQuality.MID
                    : VideoQuality.HIGH; // default to HIGH
        };
        this.pc = this.createPeerConnection(connectionConfig);
        this.sfuClient = sfuClient;
        this.state = state;
        this.isDtxEnabled = isDtxEnabled;
        this.isRedEnabled = isRedEnabled;
        this.iceRestartDelay = iceRestartDelay;
        this.unsubscribeOnIceRestart = dispatcher.on('iceRestart', (iceRestart) => {
            if (iceRestart.peerType !== PeerType.PUBLISHER_UNSPECIFIED)
                return;
            this.restartIce().catch((err) => {
                logger$3('warn', `ICERestart failed`, err);
            });
        });
    }
}

const logger$2 = getLogger(['Subscriber']);
/**
 * A wrapper around the `RTCPeerConnection` that handles the incoming
 * media streams from the SFU.
 */
class Subscriber {
    /**
     * Returns the current connection configuration.
     *
     * @internal
     */
    get connectionConfiguration() {
        if (this.pc.getConfiguration)
            return this.pc.getConfiguration();
        return this._connectionConfiguration;
    }
    /**
     * Constructs a new `Subscriber` instance.
     *
     * @param sfuClient the SFU client to use.
     * @param dispatcher the dispatcher to use.
     * @param state the state of the call.
     * @param connectionConfig the connection configuration to use.
     * @param iceRestartDelay the delay in milliseconds to wait before restarting ICE when connection goes to `disconnected` state.
     */
    constructor({ sfuClient, dispatcher, state, connectionConfig, iceRestartDelay = 2500, }) {
        this.isIceRestarting = false;
        /**
         * Creates a new `RTCPeerConnection` instance with the given configuration.
         *
         * @param connectionConfig the connection configuration to use.
         */
        this.createPeerConnection = (connectionConfig) => {
            const pc = new RTCPeerConnection(connectionConfig);
            this._connectionConfiguration = connectionConfig;
            pc.addEventListener('icecandidate', this.onIceCandidate);
            pc.addEventListener('track', this.handleOnTrack);
            pc.addEventListener('icecandidateerror', this.onIceCandidateError);
            pc.addEventListener('iceconnectionstatechange', this.onIceConnectionStateChange);
            pc.addEventListener('icegatheringstatechange', this.onIceGatheringStateChange);
            return pc;
        };
        /**
         * Closes the `RTCPeerConnection` and unsubscribes from the dispatcher.
         */
        this.close = () => {
            clearTimeout(this.iceRestartTimeout);
            this.unregisterOnSubscriberOffer();
            this.unregisterOnIceRestart();
            this.pc.close();
        };
        /**
         * Returns the result of the `RTCPeerConnection.getStats()` method
         * @param selector
         * @returns
         */
        this.getStats = (selector) => {
            return this.pc.getStats(selector);
        };
        /**
         * Sets the SFU client to use.
         *
         * @param sfuClient the SFU client to use.
         */
        this.setSfuClient = (sfuClient) => {
            this.sfuClient = sfuClient;
        };
        /**
         * Migrates the subscriber to a new SFU client.
         *
         * @param sfuClient the new SFU client to migrate to.
         * @param connectionConfig the new connection configuration to use.
         */
        this.migrateTo = (sfuClient, connectionConfig) => {
            this.setSfuClient(sfuClient);
            // when migrating, we want to keep the previous subscriber open
            // until the new one is connected
            const previousPC = this.pc;
            // we keep a record of previously available video tracks
            // so that we can monitor when they become available on the new
            // subscriber and close the previous one.
            const trackIdsToMigrate = new Set();
            previousPC.getReceivers().forEach((r) => {
                if (r.track.kind === 'video') {
                    trackIdsToMigrate.add(r.track.id);
                }
            });
            // set up a new subscriber peer connection, configured to connect
            // to the new SFU node
            const pc = this.createPeerConnection(connectionConfig);
            let migrationTimeoutId;
            const cleanupMigration = () => {
                previousPC.close();
                clearTimeout(migrationTimeoutId);
            };
            // When migrating, we want to keep track of the video tracks
            // that are migrating to the new subscriber.
            // Once all of them are available, we can close the previous subscriber.
            const handleTrackMigration = (e) => {
                logger$2('debug', `[Migration]: Migrated track: ${e.track.id}, ${e.track.kind}`);
                trackIdsToMigrate.delete(e.track.id);
                if (trackIdsToMigrate.size === 0) {
                    logger$2('debug', `[Migration]: Migration complete`);
                    pc.removeEventListener('track', handleTrackMigration);
                    cleanupMigration();
                }
            };
            // When migrating, we want to keep track of the connection state
            // of the new subscriber.
            // Once it is connected, we give it a 2-second grace period to receive
            // all the video tracks that are migrating from the previous subscriber.
            // After this threshold, we abruptly close the previous subscriber.
            const handleConnectionStateChange = () => {
                if (pc.connectionState === 'connected') {
                    migrationTimeoutId = setTimeout(() => {
                        pc.removeEventListener('track', handleTrackMigration);
                        cleanupMigration();
                    }, 2000);
                    pc.removeEventListener('connectionstatechange', handleConnectionStateChange);
                }
            };
            pc.addEventListener('track', handleTrackMigration);
            pc.addEventListener('connectionstatechange', handleConnectionStateChange);
            // replace the PeerConnection instance
            this.pc = pc;
        };
        /**
         * Restarts the ICE connection and renegotiates with the SFU.
         */
        this.restartIce = async () => {
            logger$2('debug', 'Restarting ICE connection');
            if (this.pc.signalingState === 'have-remote-offer') {
                logger$2('debug', 'ICE restart is already in progress');
                return;
            }
            const previousIsIceRestarting = this.isIceRestarting;
            try {
                this.isIceRestarting = true;
                await this.sfuClient.iceRestart({
                    peerType: PeerType.SUBSCRIBER,
                });
            }
            catch (e) {
                // restore the previous state, as our intent for restarting ICE failed
                this.isIceRestarting = previousIsIceRestarting;
                throw e;
            }
        };
        this.handleOnTrack = (e) => {
            const [primaryStream] = e.streams;
            // example: `e3f6aaf8-b03d-4911-be36-83f47d37a76a:TRACK_TYPE_VIDEO`
            const [trackId, trackType] = primaryStream.id.split(':');
            const participantToUpdate = this.state.participants.find((p) => p.trackLookupPrefix === trackId);
            logger$2('debug', `[onTrack]: Got remote ${trackType} track for userId: ${participantToUpdate?.userId}`, e.track.id, e.track);
            if (!participantToUpdate) {
                logger$2('error', `[onTrack]: Received track for unknown participant: ${trackId}`, e);
                return;
            }
            e.track.addEventListener('mute', () => {
                logger$2('info', `[onTrack]: Track muted: ${participantToUpdate.userId} ${trackType}:${trackId}`);
            });
            e.track.addEventListener('unmute', () => {
                logger$2('info', `[onTrack]: Track unmuted: ${participantToUpdate.userId} ${trackType}:${trackId}`);
            });
            e.track.addEventListener('ended', () => {
                logger$2('info', `[onTrack]: Track ended: ${participantToUpdate.userId} ${trackType}:${trackId}`);
            });
            const streamKindProp = {
                TRACK_TYPE_AUDIO: 'audioStream',
                TRACK_TYPE_VIDEO: 'videoStream',
                TRACK_TYPE_SCREEN_SHARE: 'screenShareStream',
                TRACK_TYPE_SCREEN_SHARE_AUDIO: 'screenShareAudioStream',
            }[trackType];
            if (!streamKindProp) {
                logger$2('error', `Unknown track type: ${trackType}`);
                return;
            }
            const previousStream = participantToUpdate[streamKindProp];
            if (previousStream) {
                logger$2('info', `[onTrack]: Cleaning up previous remote ${e.track.kind} tracks for userId: ${participantToUpdate.userId}`);
                previousStream.getTracks().forEach((t) => {
                    t.stop();
                    previousStream.removeTrack(t);
                });
            }
            this.state.updateParticipant(participantToUpdate.sessionId, {
                [streamKindProp]: primaryStream,
            });
        };
        this.onIceCandidate = (e) => {
            const { candidate } = e;
            if (!candidate) {
                logger$2('debug', 'null ice candidate');
                return;
            }
            this.sfuClient
                .iceTrickle({
                iceCandidate: getIceCandidate(candidate),
                peerType: PeerType.SUBSCRIBER,
            })
                .catch((err) => {
                logger$2('warn', `ICETrickle failed`, err);
            });
        };
        this.negotiate = async (subscriberOffer) => {
            logger$2('info', `Received subscriberOffer`, subscriberOffer);
            await this.pc.setRemoteDescription({
                type: 'offer',
                sdp: subscriberOffer.sdp,
            });
            this.sfuClient.iceTrickleBuffer.subscriberCandidates.subscribe(async (candidate) => {
                try {
                    const iceCandidate = JSON.parse(candidate.iceCandidate);
                    await this.pc.addIceCandidate(iceCandidate);
                }
                catch (e) {
                    logger$2('warn', `ICE candidate error`, [e, candidate]);
                }
            });
            const answer = await this.pc.createAnswer();
            await this.pc.setLocalDescription(answer);
            await this.sfuClient.sendAnswer({
                peerType: PeerType.SUBSCRIBER,
                sdp: answer.sdp || '',
            });
            this.isIceRestarting = false;
        };
        this.onIceConnectionStateChange = () => {
            const state = this.pc.iceConnectionState;
            logger$2('debug', `ICE connection state changed`, state);
            // do nothing when ICE is restarting
            if (this.isIceRestarting)
                return;
            const hasNetworkConnection = this.state.callingState !== exports.CallingState.OFFLINE;
            if (state === 'failed') {
                logger$2('warn', `Attempting to restart ICE`);
                this.restartIce().catch((e) => {
                    logger$2('error', `ICE restart failed`, e);
                });
            }
            else if (state === 'disconnected' && hasNetworkConnection) {
                // when in `disconnected` state, the browser may recover automatically,
                // hence, we delay the ICE restart
                logger$2('warn', `Scheduling ICE restart in ${this.iceRestartDelay} ms.`);
                this.iceRestartTimeout = setTimeout(() => {
                    // check if the state is still `disconnected` or `failed`
                    // as the connection may have recovered (or failed) in the meantime
                    if (this.pc.iceConnectionState === 'disconnected' ||
                        this.pc.iceConnectionState === 'failed') {
                        this.restartIce().catch((e) => {
                            logger$2('error', `ICE restart failed`, e);
                        });
                    }
                    else {
                        logger$2('debug', `Scheduled ICE restart: connection recovered, canceled.`);
                    }
                }, 5000);
            }
        };
        this.onIceGatheringStateChange = () => {
            logger$2('debug', `ICE gathering state changed`, this.pc.iceGatheringState);
        };
        this.onIceCandidateError = (e) => {
            const errorMessage = e instanceof RTCPeerConnectionIceErrorEvent &&
                `${e.errorCode}: ${e.errorText}`;
            const iceState = this.pc.iceConnectionState;
            const logLevel = iceState === 'connected' || iceState === 'checking' ? 'debug' : 'warn';
            logger$2(logLevel, `ICE Candidate error`, errorMessage);
        };
        this.sfuClient = sfuClient;
        this.state = state;
        this.iceRestartDelay = iceRestartDelay;
        this.pc = this.createPeerConnection(connectionConfig);
        this.unregisterOnSubscriberOffer = dispatcher.on('subscriberOffer', (subscriberOffer) => {
            this.negotiate(subscriberOffer).catch((err) => {
                logger$2('warn', `Negotiation failed.`, err);
            });
        });
        this.unregisterOnIceRestart = dispatcher.on('iceRestart', (iceRestart) => {
            if (iceRestart.peerType !== PeerType.SUBSCRIBER)
                return;
            this.restartIce().catch((err) => {
                logger$2('warn', `ICERestart failed`, err);
            });
        });
    }
}

const createWebSocketSignalChannel = (opts) => {
    const logger = getLogger(['sfu-client']);
    const { endpoint, onMessage } = opts;
    const ws = new WebSocket(endpoint);
    ws.binaryType = 'arraybuffer'; // do we need this?
    ws.addEventListener('error', (e) => {
        logger('error', 'Signaling WS channel error', e);
    });
    ws.addEventListener('close', (e) => {
        logger('info', 'Signaling WS channel is closed', e);
    });
    ws.addEventListener('open', (e) => {
        logger('info', 'Signaling WS channel is open', e);
    });
    ws.addEventListener('message', (e) => {
        try {
            const message = e.data instanceof ArrayBuffer
                ? SfuEvent.fromBinary(new Uint8Array(e.data))
                : SfuEvent.fromJsonString(e.data.toString());
            onMessage(message);
        }
        catch (err) {
            logger('error', 'Failed to decode a message. Check whether the Proto models match.', { event: e, error: err });
        }
    });
    return ws;
};

const sleep = (m) => new Promise((r) => setTimeout(r, m));
function isFunction(value) {
    return (value &&
        (Object.prototype.toString.call(value) === '[object Function]' ||
            'function' === typeof value ||
            value instanceof Function));
}
/**
 * A map of known error codes.
 */
const KnownCodes = {
    TOKEN_EXPIRED: 40,
    WS_CLOSED_SUCCESS: 1000,
    WS_CLOSED_ABRUPTLY: 1006,
    WS_POLICY_VIOLATION: 1008,
};
/**
 * retryInterval - A retry interval which increases acc to number of failures
 *
 * @return {number} Duration to wait in milliseconds
 */
function retryInterval(numberOfFailures) {
    // try to reconnect in 0.25-5 seconds (random to spread out the load from failures)
    const max = Math.min(500 + numberOfFailures * 2000, 5000);
    const min = Math.min(Math.max(250, (numberOfFailures - 1) * 2000), 5000);
    return Math.floor(Math.random() * (max - min) + min);
}
function randomId() {
    return generateUUIDv4();
}
function hex(bytes) {
    let s = '';
    for (let i = 0; i < bytes.length; i++) {
        s += bytes[i].toString(16).padStart(2, '0');
    }
    return s;
}
// https://tools.ietf.org/html/rfc4122
function generateUUIDv4() {
    const bytes = getRandomBytes(16);
    bytes[6] = (bytes[6] & 0x0f) | 0x40; // version
    bytes[8] = (bytes[8] & 0xbf) | 0x80; // variant
    return (hex(bytes.subarray(0, 4)) +
        '-' +
        hex(bytes.subarray(4, 6)) +
        '-' +
        hex(bytes.subarray(6, 8)) +
        '-' +
        hex(bytes.subarray(8, 10)) +
        '-' +
        hex(bytes.subarray(10, 16)));
}
function getRandomValuesWithMathRandom(bytes) {
    const max = Math.pow(2, (8 * bytes.byteLength) / bytes.length);
    for (let i = 0; i < bytes.length; i++) {
        bytes[i] = Math.random() * max;
    }
}
const getRandomValues = (() => {
    if (typeof crypto !== 'undefined' &&
        typeof crypto?.getRandomValues !== 'undefined') {
        return crypto.getRandomValues.bind(crypto);
    }
    else if (typeof msCrypto !== 'undefined') {
        return msCrypto.getRandomValues.bind(msCrypto);
    }
    else {
        return getRandomValuesWithMathRandom;
    }
})();
function getRandomBytes(length) {
    const bytes = new Uint8Array(length);
    getRandomValues(bytes);
    return bytes;
}
function convertErrorToJson(err) {
    const jsonObj = {};
    if (!err)
        return jsonObj;
    try {
        Object.getOwnPropertyNames(err).forEach((key) => {
            jsonObj[key] = Object.getOwnPropertyDescriptor(err, key);
        });
    }
    catch (_) {
        return {
            error: 'failed to serialize the error',
        };
    }
    return jsonObj;
}
/**
 * isOnline safely return the navigator.online value for browser env
 * if navigator is not in global object, it always return true
 */
function isOnline(logger) {
    const nav = typeof navigator !== 'undefined'
        ? navigator
        : typeof window !== 'undefined' && window.navigator
            ? window.navigator
            : undefined;
    if (!nav) {
        logger('warn', 'isOnline failed to access window.navigator and assume browser is online');
        return true;
    }
    // RN navigator has undefined for onLine
    if (typeof nav.onLine !== 'boolean') {
        return true;
    }
    return nav.onLine;
}
/**
 * listenForConnectionChanges - Adds an event listener fired on browser going online or offline
 */
function addConnectionEventListeners(cb) {
    if (typeof window !== 'undefined' && window.addEventListener) {
        window.addEventListener('offline', cb);
        window.addEventListener('online', cb);
    }
}
function removeConnectionEventListeners(cb) {
    if (typeof window !== 'undefined' && window.removeEventListener) {
        window.removeEventListener('offline', cb);
        window.removeEventListener('online', cb);
    }
}

/**
 * The client used for exchanging information with the SFU.
 */
class StreamSfuClient {
    /**
     * Constructs a new SFU client.
     *
     * @param dispatcher the event dispatcher to use.
     * @param sfuServer the SFU server to connect to.
     * @param token the JWT token to use for authentication.
     * @param sessionId the `sessionId` of the currently connected participant.
     */
    constructor({ dispatcher, sfuServer, token, sessionId, }) {
        /**
         * A buffer for ICE Candidates that are received before
         * the PeerConnections are ready to handle them.
         */
        this.iceTrickleBuffer = new IceTrickleBuffer();
        /**
         * A flag indicating whether the client is currently migrating away
         * from this SFU.
         */
        this.isMigratingAway = false;
        /**
         * A flag indicating that the client connection is broken for the current
         * client and that a fast-reconnect with a new client should be attempted.
         */
        this.isFastReconnecting = false;
        this.pingIntervalInMs = 10 * 1000;
        this.unhealthyTimeoutInMs = this.pingIntervalInMs + 5 * 1000;
        this.close = (code, reason) => {
            this.logger('debug', `Closing SFU WS connection: ${code} - ${reason}`);
            if (this.signalWs.readyState !== this.signalWs.CLOSED) {
                this.signalWs.close(code, `js-client: ${reason}`);
            }
            this.unsubscribeIceTrickle();
            clearInterval(this.keepAliveInterval);
            clearTimeout(this.connectionCheckTimeout);
        };
        this.updateSubscriptions = async (subscriptions) => {
            return retryable(() => this.rpc.updateSubscriptions({
                sessionId: this.sessionId,
                tracks: subscriptions,
            }), this.logger, 'debug');
        };
        this.setPublisher = async (data) => {
            return retryable(() => this.rpc.setPublisher({
                ...data,
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.sendAnswer = async (data) => {
            return retryable(() => this.rpc.sendAnswer({
                ...data,
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.iceTrickle = async (data) => {
            return retryable(() => this.rpc.iceTrickle({
                ...data,
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.iceRestart = async (data) => {
            return retryable(() => this.rpc.iceRestart({
                ...data,
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.updateMuteState = async (trackType, muted) => {
            return this.updateMuteStates({
                muteStates: [
                    {
                        trackType,
                        muted,
                    },
                ],
            });
        };
        this.updateMuteStates = async (data) => {
            return retryable(() => this.rpc.updateMuteStates({
                ...data,
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.sendStats = async (stats) => {
            return retryable(() => this.rpc.sendStats({
                ...stats,
                sessionId: this.sessionId,
            }), this.logger, 'debug');
        };
        this.startNoiseCancellation = async () => {
            return retryable(() => this.rpc.startNoiseCancellation({
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.stopNoiseCancellation = async () => {
            return retryable(() => this.rpc.stopNoiseCancellation({
                sessionId: this.sessionId,
            }), this.logger);
        };
        this.join = async (data) => {
            const joinRequest = JoinRequest.create({
                ...data,
                sessionId: this.sessionId,
                token: this.token,
            });
            return this.send(SfuRequest.create({
                requestPayload: {
                    oneofKind: 'joinRequest',
                    joinRequest,
                },
            }));
        };
        this.send = async (message) => {
            return this.signalReady.then((signal) => {
                if (signal.readyState !== signal.OPEN)
                    return;
                this.logger('debug', `Sending message to: ${this.edgeName}`, SfuRequest.toJson(message));
                signal.send(SfuRequest.toBinary(message));
            });
        };
        this.keepAlive = () => {
            clearInterval(this.keepAliveInterval);
            this.keepAliveInterval = setInterval(() => {
                this.logger('trace', 'Sending healthCheckRequest to SFU');
                const message = SfuRequest.create({
                    requestPayload: {
                        oneofKind: 'healthCheckRequest',
                        healthCheckRequest: {},
                    },
                });
                this.send(message).catch((e) => {
                    this.logger('error', 'Error sending healthCheckRequest to SFU', e);
                });
            }, this.pingIntervalInMs);
        };
        this.scheduleConnectionCheck = () => {
            clearTimeout(this.connectionCheckTimeout);
            this.connectionCheckTimeout = setTimeout(() => {
                if (this.lastMessageTimestamp) {
                    const timeSinceLastMessage = new Date().getTime() - this.lastMessageTimestamp.getTime();
                    if (timeSinceLastMessage > this.unhealthyTimeoutInMs) {
                        this.close(StreamSfuClient.ERROR_CONNECTION_UNHEALTHY, `SFU connection unhealthy. Didn't receive any message for ${this.unhealthyTimeoutInMs}ms`);
                    }
                }
            }, this.unhealthyTimeoutInMs);
        };
        this.sessionId = sessionId || generateUUIDv4();
        this.sfuServer = sfuServer;
        this.edgeName = sfuServer.edge_name;
        this.token = token;
        this.logger = getLogger(['sfu-client']);
        const logInterceptor = {
            interceptUnary: (next, method, input, options) => {
                this.logger('trace', `Calling SFU RPC method ${method.name}`, {
                    input,
                    options,
                });
                return next(method, input, options);
            },
        };
        this.rpc = createSignalClient({
            baseUrl: sfuServer.url,
            interceptors: [
                withHeaders({
                    Authorization: `Bearer ${token}`,
                }),
                logInterceptor,
            ],
        });
        // Special handling for the ICETrickle kind of events.
        // These events might be triggered by the SFU before the initial RTC
        // connection is established. In that case, those events (ICE candidates)
        // need to be buffered and later added to the appropriate PeerConnection
        // once the remoteDescription is known and set.
        this.unsubscribeIceTrickle = dispatcher.on('iceTrickle', (iceTrickle) => {
            this.iceTrickleBuffer.push(iceTrickle);
        });
        this.signalWs = createWebSocketSignalChannel({
            endpoint: sfuServer.ws_endpoint,
            onMessage: (message) => {
                this.lastMessageTimestamp = new Date();
                this.scheduleConnectionCheck();
                dispatcher.dispatch(message);
            },
        });
        this.signalReady = new Promise((resolve) => {
            const onOpen = () => {
                this.signalWs.removeEventListener('open', onOpen);
                this.keepAlive();
                resolve(this.signalWs);
            };
            this.signalWs.addEventListener('open', onOpen);
        });
    }
}
/**
 * The normal closure code. Used for controlled shutdowns.
 */
StreamSfuClient.NORMAL_CLOSURE = 1000;
/**
 * The error code used when the SFU connection is unhealthy.
 * Usually, this means that no message has been received from the SFU for
 * a certain amount of time (`connectionCheckTimeout`).
 */
StreamSfuClient.ERROR_CONNECTION_UNHEALTHY = 4001;
/**
 * The error code used when the SFU connection is broken.
 * Usually, this means that the WS connection has been closed unexpectedly.
 * This error code is used to announce a fast-reconnect.
 */
StreamSfuClient.ERROR_CONNECTION_BROKEN = 4002; // used in fast-reconnects
const MAX_RETRIES = 5;
/**
 * Creates a closure which wraps the given RPC call and retries invoking
 * the RPC until it succeeds or the maximum number of retries is reached.
 *
 * Between each retry, there would be a random delay in order to avoid
 * request bursts towards the SFU.
 *
 * @param rpc the closure around the RPC call to execute.
 * @param logger a logger instance to use.
 * @param <I> the type of the request object.
 * @param <O> the type of the response object.
 */
const retryable = async (rpc, logger, level = 'error') => {
    let retryAttempt = 0;
    let rpcCallResult;
    do {
        // don't delay the first invocation
        if (retryAttempt > 0) {
            await sleep(retryInterval(retryAttempt));
        }
        rpcCallResult = await rpc();
        // if the RPC call failed, log the error and retry
        if (rpcCallResult.response.error) {
            logger(level, `SFU RPC Error (${rpcCallResult.method.name}):`, rpcCallResult.response.error);
        }
        retryAttempt++;
    } while (rpcCallResult.response.error?.shouldRetry &&
        retryAttempt < MAX_RETRIES);
    if (rpcCallResult.response.error) {
        throw rpcCallResult.response.error;
    }
    return rpcCallResult;
};

/**
 * Event handler that watched the delivery of `call.accepted`.
 * Once the event is received, the call is joined.
 */
const watchCallAccepted = (call) => {
    return async function onCallAccepted(event) {
        // We want to discard the event if it's from the current user
        if (event.user.id === call.currentUserId)
            return;
        const { state } = call;
        if (event.call.created_by.id === call.currentUserId &&
            state.callingState === exports.CallingState.RINGING) {
            await call.join();
        }
    };
};
/**
 * Event handler that watches delivery of `call.rejected` Websocket event.
 * Once the event is received, the call is left.
 */
const watchCallRejected = (call) => {
    return async function onCallRejected(event) {
        // We want to discard the event if it's from the current user
        if (event.user.id === call.currentUserId)
            return;
        const { call: eventCall } = event;
        const { session: callSession } = eventCall;
        if (!callSession) {
            call.logger('warn', 'No call session provided. Ignoring call.rejected event.', event);
            return;
        }
        const rejectedBy = callSession.rejected_by;
        const { members, callingState } = call.state;
        if (callingState !== exports.CallingState.RINGING) {
            call.logger('info', 'Call is not in ringing mode (it is either accepted or rejected already). Ignoring call.rejected event.', event);
            return;
        }
        if (call.isCreatedByMe) {
            const everyoneElseRejected = members
                .filter((m) => m.user_id !== call.currentUserId)
                .every((m) => rejectedBy[m.user_id]);
            if (everyoneElseRejected) {
                call.logger('info', 'everyone rejected, leaving the call');
                await call.leave({ reason: 'ring: everyone rejected' });
            }
        }
        else {
            if (rejectedBy[eventCall.created_by.id]) {
                call.logger('info', 'call creator rejected, leaving call');
                await call.leave({ reason: 'ring: creator rejected' });
            }
        }
    };
};
/**
 * Event handler that watches the delivery of `call.ended` Websocket event.
 */
const watchCallEnded = (call) => {
    return async function onCallEnded() {
        const { callingState } = call.state;
        if (callingState === exports.CallingState.RINGING ||
            callingState === exports.CallingState.JOINED ||
            callingState === exports.CallingState.JOINING) {
            await call.leave({ reason: 'call.ended event received' });
        }
    };
};

/**
 * Event handler that watches for `callGrantsUpdated` events.
 *
 * @param state the call state to update.
 */
const watchCallGrantsUpdated = (state) => {
    return function onCallGrantsUpdated(event) {
        const { currentGrants } = event;
        if (currentGrants) {
            const { canPublishAudio, canPublishVideo, canScreenshare } = currentGrants;
            const update = {
                [OwnCapability.SEND_AUDIO]: canPublishAudio,
                [OwnCapability.SEND_VIDEO]: canPublishVideo,
                [OwnCapability.SCREENSHARE]: canScreenshare,
            };
            const nextCapabilities = state.ownCapabilities.filter((capability) => update[capability] !== false);
            Object.entries(update).forEach(([capability, value]) => {
                if (value && !nextCapabilities.includes(capability)) {
                    nextCapabilities.push(capability);
                }
            });
            state.setOwnCapabilities(nextCapabilities);
        }
    };
};

const logger$1 = getLogger(['events']);
/**
 * An event responder which handles the `changePublishQuality` event.
 */
const watchChangePublishQuality = (dispatcher, call) => {
    return dispatcher.on('changePublishQuality', (e) => {
        const { videoSenders } = e;
        videoSenders.forEach((videoSender) => {
            const { layers } = videoSender;
            call.updatePublishQuality(layers.filter((l) => l.active));
        });
    });
};
const watchConnectionQualityChanged = (dispatcher, state) => {
    return dispatcher.on('connectionQualityChanged', (e) => {
        const { connectionQualityUpdates } = e;
        if (!connectionQualityUpdates)
            return;
        state.updateParticipants(connectionQualityUpdates.reduce((patches, update) => {
            const { sessionId, connectionQuality } = update;
            patches[sessionId] = {
                connectionQuality,
            };
            return patches;
        }, {}));
    });
};
/**
 * Updates the approximate number of participants in the call by peeking at the
 * health check events that our SFU sends.
 */
const watchParticipantCountChanged = (dispatcher, state) => {
    return dispatcher.on('healthCheckResponse', (e) => {
        const { participantCount } = e;
        if (participantCount) {
            state.setParticipantCount(participantCount.total);
            state.setAnonymousParticipantCount(participantCount.anonymous);
        }
    });
};
const watchLiveEnded = (dispatcher, call) => {
    return dispatcher.on('error', (e) => {
        if (e.error && e.error.code !== ErrorCode.LIVE_ENDED)
            return;
        if (!call.permissionsContext.hasPermission(OwnCapability.JOIN_BACKSTAGE)) {
            call.leave({ reason: 'live ended' }).catch((err) => {
                logger$1('error', 'Failed to leave call after live ended', err);
            });
        }
    });
};
/**
 * Watches and logs the errors reported by the currently connected SFU.
 */
const watchSfuErrorReports = (dispatcher) => {
    return dispatcher.on('error', (e) => {
        if (!e.error)
            return;
        const { error } = e;
        logger$1('error', 'SFU reported error', {
            code: ErrorCode[error.code],
            message: error.message,
            shouldRetry: error.shouldRetry,
        });
    });
};
/**
 * Watches for `pinsUpdated` events and updates the pinned state of participants
 * in the call.
 */
const watchPinsUpdated = (state) => {
    return function onPinsUpdated(e) {
        const { pins } = e;
        state.setServerSidePins(pins);
    };
};

/**
 * An event handler that handles soft mutes.
 *
 * @param call the call.
 */
const handleRemoteSoftMute = (call) => {
    return call.on('trackUnpublished', async (event) => {
        const { cause, type, sessionId } = event;
        const { localParticipant } = call.state;
        if (cause === TrackUnpublishReason.MODERATION &&
            sessionId === localParticipant?.sessionId) {
            const logger = call.logger;
            logger('info', `Local participant's ${TrackType[type]} track is muted remotely`);
            try {
                if (type === TrackType.VIDEO) {
                    await call.camera.disable();
                }
                else if (type === TrackType.AUDIO) {
                    await call.microphone.disable();
                }
                else {
                    logger('warn', 'Unsupported track type to soft mute', TrackType[type]);
                }
                if (call.publisher?.isPublishing(type)) {
                    await call.stopPublish(type);
                }
            }
            catch (error) {
                logger('error', 'Failed to stop publishing', error);
            }
        }
    });
};

/**
 * An event responder which handles the `participantJoined` event.
 */
const watchParticipantJoined = (state) => {
    return function onParticipantJoined(e) {
        const { participant } = e;
        if (!participant)
            return;
        // `state.updateOrAddParticipant` acts as a safeguard against
        // potential duplicate events from the SFU.
        //
        // Although the SFU should not send duplicate events, we have seen
        // some race conditions in the past during the `join-flow` where
        // the SFU would send participant info as part of the `join`
        // response and then follow up with a `participantJoined` event for
        // already announced participants.
        state.updateOrAddParticipant(participant.sessionId, Object.assign(participant, {
            viewportVisibilityState: {
                videoTrack: exports.VisibilityState.UNKNOWN,
                screenShareTrack: exports.VisibilityState.UNKNOWN,
            },
        }));
    };
};
/**
 * An event responder which handles the `participantLeft` event.
 */
const watchParticipantLeft = (state) => {
    return function onParticipantLeft(e) {
        const { participant } = e;
        if (!participant)
            return;
        state.setParticipants((participants) => participants.filter((p) => p.sessionId !== participant.sessionId));
    };
};
/**
 * An event responder which handles the `participantUpdated` event.
 */
const watchParticipantUpdated = (state) => {
    return function onParticipantUpdated(e) {
        const { participant } = e;
        if (!participant)
            return;
        state.updateParticipant(participant.sessionId, participant);
    };
};
/**
 * An event responder which handles the `trackPublished` event.
 * The SFU will send this event when a participant publishes a track.
 */
const watchTrackPublished = (state) => {
    return function onTrackPublished(e) {
        const { type, sessionId, participant } = e;
        // An optimization for large calls.
        // After a certain threshold, the SFU would stop emitting `participantJoined`
        // events, and instead, it would only provide the participant's information
        // once they start publishing a track.
        if (participant) {
            state.updateOrAddParticipant(sessionId, participant);
        }
        else {
            state.updateParticipant(sessionId, (p) => ({
                publishedTracks: [...p.publishedTracks, type].filter(unique),
            }));
        }
    };
};
/**
 * An event responder which handles the `trackUnpublished` event.
 * The SFU will send this event when a participant unpublishes a track.
 */
const watchTrackUnpublished = (state) => {
    return function onTrackUnpublished(e) {
        const { type, sessionId, participant } = e;
        // An optimization for large calls. See `watchTrackPublished`.
        if (participant) {
            state.updateOrAddParticipant(sessionId, participant);
        }
        else {
            state.updateParticipant(sessionId, (p) => ({
                publishedTracks: p.publishedTracks.filter((t) => t !== type),
            }));
        }
    };
};
const unique = (v, i, arr) => arr.indexOf(v) === i;

/**
 * Watches for `dominantSpeakerChanged` events.
 */
const watchDominantSpeakerChanged = (dispatcher, state) => {
    return dispatcher.on('dominantSpeakerChanged', (e) => {
        const { sessionId } = e;
        if (sessionId === state.dominantSpeaker?.sessionId)
            return;
        state.setParticipants((participants) => participants.map((participant) => {
            // mark the new dominant speaker
            if (participant.sessionId === sessionId) {
                return {
                    ...participant,
                    isDominantSpeaker: true,
                };
            }
            // unmark the old dominant speaker
            if (participant.isDominantSpeaker) {
                return {
                    ...participant,
                    isDominantSpeaker: false,
                };
            }
            return participant; // no change
        }));
    });
};
/**
 * Watches for `audioLevelChanged` events.
 */
const watchAudioLevelChanged = (dispatcher, state) => {
    return dispatcher.on('audioLevelChanged', (e) => {
        const { audioLevels } = e;
        state.updateParticipants(audioLevels.reduce((patches, current) => {
            patches[current.sessionId] = {
                audioLevel: current.level,
                isSpeaking: current.isSpeaking,
            };
            return patches;
        }, {}));
    });
};

/**
 * Registers the default event handlers for a call during its lifecycle.
 *
 * @param call the call to register event handlers for.
 * @param state the call state.
 * @param dispatcher the dispatcher.
 */
const registerEventHandlers = (call, state, dispatcher) => {
    const eventHandlers = [
        call.on('call.ended', watchCallEnded(call)),
        watchLiveEnded(dispatcher, call),
        watchSfuErrorReports(dispatcher),
        watchChangePublishQuality(dispatcher, call),
        watchConnectionQualityChanged(dispatcher, state),
        watchParticipantCountChanged(dispatcher, state),
        call.on('participantJoined', watchParticipantJoined(state)),
        call.on('participantLeft', watchParticipantLeft(state)),
        call.on('participantUpdated', watchParticipantUpdated(state)),
        call.on('trackPublished', watchTrackPublished(state)),
        call.on('trackUnpublished', watchTrackUnpublished(state)),
        watchAudioLevelChanged(dispatcher, state),
        watchDominantSpeakerChanged(dispatcher, state),
        call.on('callGrantsUpdated', watchCallGrantsUpdated(state)),
        call.on('pinsUpdated', watchPinsUpdated(state)),
        handleRemoteSoftMute(call),
    ];
    if (call.ringing) {
        // these events are only relevant when the call is ringing
        eventHandlers.push(registerRingingCallEventHandlers(call));
    }
    return () => {
        eventHandlers.forEach((unsubscribe) => unsubscribe());
    };
};
/**
 * Registers event handlers for a call that is of ringing type.
 *
 * @param call the call to register event handlers for.
 */
const registerRingingCallEventHandlers = (call) => {
    const coordinatorRingEvents = {
        'call.accepted': watchCallAccepted(call),
        'call.rejected': watchCallRejected(call),
    };
    const eventHandlers = Object.keys(coordinatorRingEvents).map((event) => {
        const eventName = event;
        return call.on(eventName, coordinatorRingEvents[eventName]);
    });
    return () => {
        eventHandlers.forEach((unsubscribe) => unsubscribe());
    };
};

/**
 * Collects all necessary information to join a call, talks to the coordinator
 * and returns the necessary information to join the call.
 *
 * @param httpClient the http client to use.
 * @param type the type of the call.
 * @param id the id of the call.
 * @param data the data for the call.
 */
const join = async (httpClient, type, id, data) => {
    const { call, credentials, members, own_capabilities, stats_options } = await doJoin(httpClient, type, id, data);
    return {
        connectionConfig: toRtcConfiguration(credentials.ice_servers),
        sfuServer: credentials.server,
        token: credentials.token,
        metadata: call,
        members,
        ownCapabilities: own_capabilities,
        statsOptions: stats_options,
    };
};
const doJoin = async (httpClient, type, id, data) => {
    const location = await httpClient.getLocationHint();
    const request = {
        ...data,
        location,
    };
    return httpClient.post(`/call/${type}/${id}/join`, request);
};
const toRtcConfiguration = (config) => {
    if (!config || config.length === 0)
        return undefined;
    const rtcConfig = {
        iceServers: config.map((ice) => ({
            urls: ice.urls,
            username: ice.username,
            credential: ice.password,
        })),
    };
    return rtcConfig;
};

/**
 * Flatten the stats report into an array of stats objects.
 *
 * @param report the report to flatten.
 */
const flatten = (report) => {
    const stats = [];
    report.forEach((s) => {
        stats.push(s);
    });
    return stats;
};
const getSdkSignature = (clientDetails) => {
    const { sdk, ...platform } = clientDetails;
    const sdkName = getSdkName(sdk);
    const sdkVersion = getSdkVersion(sdk);
    return {
        sdkName,
        sdkVersion,
        ...platform,
    };
};
const getSdkName = (sdk) => {
    return sdk && sdk.type === SdkType.REACT
        ? 'stream-react'
        : sdk && sdk.type === SdkType.REACT_NATIVE
            ? 'stream-react-native'
            : 'stream-js';
};
const getSdkVersion = (sdk) => {
    return sdk ? `${sdk.major}.${sdk.minor}.${sdk.patch}` : '0.0.0-development';
};

/**
 * Creates a new StatsReporter instance that collects metrics about the ongoing call and reports them to the state store
 */
const createStatsReporter = ({ subscriber, publisher, state, datacenter, pollingIntervalInMs = 2000, }) => {
    const logger = getLogger(['stats']);
    const getRawStatsForTrack = async (kind, selector) => {
        if (kind === 'subscriber' && subscriber) {
            return subscriber.getStats(selector);
        }
        else if (kind === 'publisher' && publisher) {
            return publisher.getStats(selector);
        }
        else {
            return undefined;
        }
    };
    const getStatsForStream = async (kind, mediaStream) => {
        const pc = kind === 'subscriber' ? subscriber : publisher;
        if (!pc)
            return [];
        const statsForStream = [];
        for (let track of mediaStream.getTracks()) {
            const report = await pc.getStats(track);
            const stats = transform(report, {
                // @ts-ignore
                trackKind: track.kind,
                kind,
            });
            statsForStream.push(stats);
        }
        return statsForStream;
    };
    const startReportingStatsFor = (sessionId) => {
        sessionIdsToTrack.add(sessionId);
        void run();
    };
    const stopReportingStatsFor = (sessionId) => {
        sessionIdsToTrack.delete(sessionId);
        void run();
    };
    const sessionIdsToTrack = new Set();
    /**
     * The main stats reporting loop.
     */
    const run = async () => {
        const participantStats = {};
        const sessionIds = new Set(sessionIdsToTrack);
        if (sessionIds.size > 0) {
            for (let participant of state.participants) {
                if (!sessionIds.has(participant.sessionId))
                    continue;
                const kind = participant.isLocalParticipant
                    ? 'publisher'
                    : 'subscriber';
                try {
                    const mergedStream = new MediaStream([
                        ...(participant.videoStream?.getVideoTracks() || []),
                        ...(participant.audioStream?.getAudioTracks() || []),
                    ]);
                    participantStats[participant.sessionId] = await getStatsForStream(kind, mergedStream);
                    mergedStream.getTracks().forEach((t) => {
                        mergedStream.removeTrack(t);
                    });
                }
                catch (e) {
                    logger('error', `Failed to collect stats for ${kind} of ${participant.userId}`, e);
                }
            }
        }
        const [subscriberStats, publisherStats] = await Promise.all([
            subscriber
                .getStats()
                .then((report) => transform(report, {
                kind: 'subscriber',
                trackKind: 'video',
            }))
                .then(aggregate),
            publisher
                ? publisher
                    .getStats()
                    .then((report) => transform(report, {
                    kind: 'publisher',
                    trackKind: 'video',
                }))
                    .then(aggregate)
                : getEmptyStats(),
        ]);
        const [subscriberRawStats, publisherRawStats] = await Promise.all([
            getRawStatsForTrack('subscriber'),
            publisher ? getRawStatsForTrack('publisher') : undefined,
        ]);
        state.setCallStatsReport({
            datacenter,
            publisherStats,
            subscriberStats,
            subscriberRawStats,
            publisherRawStats,
            participants: participantStats,
            timestamp: Date.now(),
        });
    };
    let timeoutId;
    if (pollingIntervalInMs > 0) {
        const loop = async () => {
            await run().catch((e) => {
                logger('debug', 'Failed to collect stats', e);
            });
            timeoutId = setTimeout(loop, pollingIntervalInMs);
        };
        void loop();
    }
    const stop = () => {
        if (timeoutId) {
            clearTimeout(timeoutId);
        }
    };
    return {
        getRawStatsForTrack,
        getStatsForStream,
        startReportingStatsFor,
        stopReportingStatsFor,
        stop,
    };
};
/**
 * Transforms raw RTC stats into a slimmer and uniform across browsers format.
 *
 * @param report the report to transform.
 * @param opts the transform options.
 */
const transform = (report, opts) => {
    const { trackKind, kind } = opts;
    const direction = kind === 'subscriber' ? 'inbound-rtp' : 'outbound-rtp';
    const stats = flatten(report);
    const streams = stats
        .filter((stat) => stat.type === direction &&
        stat.kind === trackKind)
        .map((stat) => {
        const rtcStreamStats = stat;
        const codec = stats.find((s) => s.type === 'codec' && s.id === rtcStreamStats.codecId); // FIXME OL: incorrect type!
        const transport = stats.find((s) => s.type === 'transport' && s.id === rtcStreamStats.transportId);
        let roundTripTime;
        if (transport && transport.dtlsState === 'connected') {
            const candidatePair = stats.find((s) => s.type === 'candidate-pair' &&
                s.id === transport.selectedCandidatePairId);
            roundTripTime = candidatePair?.currentRoundTripTime;
        }
        return {
            bytesSent: rtcStreamStats.bytesSent,
            bytesReceived: rtcStreamStats.bytesReceived,
            codec: codec?.mimeType,
            currentRoundTripTime: roundTripTime,
            frameHeight: rtcStreamStats.frameHeight,
            frameWidth: rtcStreamStats.frameWidth,
            framesPerSecond: rtcStreamStats.framesPerSecond,
            jitter: rtcStreamStats.jitter,
            kind: rtcStreamStats.kind,
            // @ts-ignore: available in Chrome only, TS doesn't recognize this
            qualityLimitationReason: rtcStreamStats.qualityLimitationReason,
            rid: rtcStreamStats.rid,
            ssrc: rtcStreamStats.ssrc,
        };
    });
    return {
        rawStats: report,
        streams,
        timestamp: Date.now(),
    };
};
const getEmptyStats = (stats) => {
    return {
        rawReport: stats ?? { streams: [], timestamp: Date.now() },
        totalBytesSent: 0,
        totalBytesReceived: 0,
        averageJitterInMs: 0,
        averageRoundTripTimeInMs: 0,
        qualityLimitationReasons: 'none',
        highestFrameWidth: 0,
        highestFrameHeight: 0,
        highestFramesPerSecond: 0,
        timestamp: Date.now(),
    };
};
/**
 * Aggregates generic stats.
 *
 * @param stats the stats to aggregate.
 */
const aggregate = (stats) => {
    const aggregatedStats = getEmptyStats(stats);
    let maxArea = -1;
    const area = (w, h) => w * h;
    const qualityLimitationReasons = new Set();
    const streams = stats.streams;
    const report = streams.reduce((acc, stream) => {
        acc.totalBytesSent += stream.bytesSent || 0;
        acc.totalBytesReceived += stream.bytesReceived || 0;
        acc.averageJitterInMs += stream.jitter || 0;
        acc.averageRoundTripTimeInMs += stream.currentRoundTripTime || 0;
        // naive calculation of the highest resolution
        const streamArea = area(stream.frameWidth || 0, stream.frameHeight || 0);
        if (streamArea > maxArea) {
            acc.highestFrameWidth = stream.frameWidth || 0;
            acc.highestFrameHeight = stream.frameHeight || 0;
            acc.highestFramesPerSecond = stream.framesPerSecond || 0;
            maxArea = streamArea;
        }
        qualityLimitationReasons.add(stream.qualityLimitationReason || '');
        return acc;
    }, aggregatedStats);
    if (streams.length > 0) {
        report.averageJitterInMs = Math.round((report.averageJitterInMs / streams.length) * 1000);
        report.averageRoundTripTimeInMs = Math.round((report.averageRoundTripTimeInMs / streams.length) * 1000);
    }
    const qualityLimitationReason = [
        qualityLimitationReasons.has('cpu') && 'cpu',
        qualityLimitationReasons.has('bandwidth') && 'bandwidth',
        qualityLimitationReasons.has('other') && 'other',
    ]
        .filter(Boolean)
        .join(', ');
    if (qualityLimitationReason) {
        report.qualityLimitationReasons = qualityLimitationReason;
    }
    return report;
};

class SfuStatsReporter {
    constructor(sfuClient, { options, clientDetails, subscriber, publisher }) {
        this.logger = getLogger(['SfuStatsReporter']);
        this.run = async () => {
            const [subscriberStats, publisherStats] = await Promise.all([
                this.subscriber.getStats().then(flatten).then(JSON.stringify),
                this.publisher?.getStats().then(flatten).then(JSON.stringify) ?? '[]',
            ]);
            await this.sfuClient.sendStats({
                sdk: this.sdkName,
                sdkVersion: this.sdkVersion,
                webrtcVersion: this.webRTCVersion,
                subscriberStats,
                publisherStats,
            });
        };
        this.start = () => {
            if (this.options.reporting_interval_ms <= 0)
                return;
            this.intervalId = setInterval(() => {
                this.run().catch((err) => {
                    this.logger('warn', 'Failed to report stats', err);
                });
            }, this.options.reporting_interval_ms);
        };
        this.stop = () => {
            clearInterval(this.intervalId);
            this.intervalId = undefined;
        };
        this.sfuClient = sfuClient;
        this.options = options;
        this.subscriber = subscriber;
        this.publisher = publisher;
        const webRTCInfo = getWebRTCInfo();
        const { sdk, browser } = clientDetails;
        this.sdkName = getSdkName(sdk);
        this.sdkVersion = getSdkVersion(sdk);
        // The WebRTC version if passed from the SDK, it is taken else the browser info is sent.
        this.webRTCVersion =
            webRTCInfo?.version ||
                `${browser?.name || ''}-${browser?.version || ''}` ||
                'N/A';
    }
}

const DEFAULT_THRESHOLD = 0.35;
class ViewportTracker {
    constructor() {
        /**
         * @private
         */
        this.elementHandlerMap = new Map();
        /**
         * @private
         */
        this.observer = null;
        // in React children render before viewport is set, add
        // them to the queue and observe them once the observer is ready
        /**
         * @private
         */
        this.queueSet = new Set();
        /**
         * Method to set scrollable viewport as root for the IntersectionObserver, returns
         * cleanup function to be invoked upon disposing of the DOM element to prevent memory leaks
         *
         * @param viewportElement
         * @param options
         * @returns Unobserve
         */
        this.setViewport = (viewportElement, options) => {
            const cleanup = () => {
                this.observer?.disconnect();
                this.observer = null;
                this.elementHandlerMap.clear();
            };
            this.observer = new IntersectionObserver((entries) => {
                entries.forEach((entry) => {
                    const handler = this.elementHandlerMap.get(entry.target);
                    handler?.(entry);
                });
            }, {
                root: viewportElement,
                ...options,
                threshold: options?.threshold ?? DEFAULT_THRESHOLD,
            });
            if (this.queueSet.size) {
                this.queueSet.forEach(([queueElement, queueHandler]) => {
                    // check if element which requested observation is
                    // a child of a viewport element, skip if isn't
                    if (!viewportElement.contains(queueElement))
                        return;
                    this.observer.observe(queueElement);
                    this.elementHandlerMap.set(queueElement, queueHandler);
                });
                this.queueSet.clear();
            }
            return cleanup;
        };
        /**
         * Method to set element to observe and handler to be triggered whenever IntersectionObserver
         * detects a possible change in element's visibility within specified viewport, returns
         * cleanup function to be invoked upon disposing of the DOM element to prevent memory leaks
         *
         * @param element
         * @param handler
         * @returns Unobserve
         */
        this.observe = (element, handler) => {
            const queueItem = [element, handler];
            const cleanup = () => {
                this.elementHandlerMap.delete(element);
                this.observer?.unobserve(element);
                this.queueSet.delete(queueItem);
            };
            if (this.elementHandlerMap.has(element))
                return cleanup;
            if (!this.observer) {
                this.queueSet.add(queueItem);
                return cleanup;
            }
            if (this.observer.root.contains(element)) {
                this.elementHandlerMap.set(element, handler);
                this.observer.observe(element);
            }
            return cleanup;
        };
    }
}

/**
 * Checks whether the current browser is Safari.
 */
const isSafari = () => {
    if (typeof navigator === 'undefined')
        return false;
    return /^((?!chrome|android).)*safari/i.test(navigator.userAgent || '');
};
/**
 * Checks whether the current browser is Firefox.
 */
const isFirefox = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.userAgent?.includes('Firefox');
};
/**
 * Checks whether the current browser is Google Chrome.
 */
const isChrome = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.userAgent?.includes('Chrome');
};

var browsers = /*#__PURE__*/Object.freeze({
    __proto__: null,
    isChrome: isChrome,
    isFirefox: isFirefox,
    isSafari: isSafari
});

const DEFAULT_VIEWPORT_VISIBILITY_STATE = {
    videoTrack: exports.VisibilityState.UNKNOWN,
    screenShareTrack: exports.VisibilityState.UNKNOWN,
};
/**
 * A manager class that handles dynascale related tasks like:
 *
 * - binding video elements to session ids
 * - binding audio elements to session ids
 * - tracking element visibility
 * - updating subscriptions based on viewport visibility
 * - updating subscriptions based on video element dimensions
 * - updating subscriptions based on published tracks
 */
class DynascaleManager {
    /**
     * Creates a new DynascaleManager instance.
     *
     * @param call the call to manage.
     */
    constructor(call) {
        /**
         * The viewport tracker instance.
         */
        this.viewportTracker = new ViewportTracker();
        this.logger = getLogger(['DynascaleManager']);
        /**
         * Will begin tracking the given element for visibility changes within the
         * configured viewport element (`call.setViewport`).
         *
         * @param element the element to track.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         * @returns Untrack.
         */
        this.trackElementVisibility = (element, sessionId, trackType) => {
            const cleanup = this.viewportTracker.observe(element, (entry) => {
                this.call.state.updateParticipant(sessionId, (participant) => {
                    const previousVisibilityState = participant.viewportVisibilityState ??
                        DEFAULT_VIEWPORT_VISIBILITY_STATE;
                    // observer triggers when the element is "moved" to be a fullscreen element
                    // keep it VISIBLE if that happens to prevent fullscreen with placeholder
                    const isVisible = entry.isIntersecting || document.fullscreenElement === element
                        ? exports.VisibilityState.VISIBLE
                        : exports.VisibilityState.INVISIBLE;
                    return {
                        ...participant,
                        viewportVisibilityState: {
                            ...previousVisibilityState,
                            [trackType]: isVisible,
                        },
                    };
                });
            });
            return () => {
                cleanup();
                // reset visibility state to UNKNOWN upon cleanup
                // so that the layouts that are not actively observed
                // can still function normally (runtime layout switching)
                this.call.state.updateParticipant(sessionId, (participant) => {
                    const previousVisibilityState = participant.viewportVisibilityState ??
                        DEFAULT_VIEWPORT_VISIBILITY_STATE;
                    return {
                        ...participant,
                        viewportVisibilityState: {
                            ...previousVisibilityState,
                            [trackType]: exports.VisibilityState.UNKNOWN,
                        },
                    };
                });
            };
        };
        /**
         * Sets the viewport element to track bound video elements for visibility.
         *
         * @param element the viewport element.
         */
        this.setViewport = (element) => {
            return this.viewportTracker.setViewport(element);
        };
        /**
         * Binds a DOM <video> element to the given session id.
         * This method will make sure that the video element will play
         * the correct video stream for the given session id.
         *
         * Under the hood, it would also keep track of the video element dimensions
         * and update the subscription accordingly in order to optimize the bandwidth.
         *
         * If a "viewport" is configured, the video element will be automatically
         * tracked for visibility and the subscription will be updated accordingly.
         *
         * @param videoElement the video element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         */
        this.bindVideoElement = (videoElement, sessionId, trackType) => {
            const boundParticipant = this.call.state.findParticipantBySessionId(sessionId);
            if (!boundParticipant)
                return;
            const requestTrackWithDimensions = (debounceType, dimension) => {
                if (dimension && (dimension.width === 0 || dimension.height === 0)) {
                    // ignore 0x0 dimensions. this can happen when the video element
                    // is not visible (e.g., has display: none).
                    // we treat this as "unsubscription" as we don't want to keep
                    // consuming bandwidth for a video that is not visible on the screen.
                    this.logger('debug', `Ignoring 0x0 dimension`, boundParticipant);
                    dimension = undefined;
                }
                this.call.updateSubscriptionsPartial(trackType, { [sessionId]: { dimension } }, debounceType);
            };
            const participant$ = this.call.state.participants$.pipe(rxjs.map((participants) => participants.find((participant) => participant.sessionId === sessionId)), rxjs.takeWhile((participant) => !!participant), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
            /**
             * Since the video elements are now being removed from the DOM (React SDK) upon
             * visibility change, this subscription is not in use an stays here only for the
             * plain JS integrations where integrators might choose not to remove the video
             * elements from the DOM.
             */
            // keep copy for resize observer handler
            let viewportVisibilityState;
            const viewportVisibilityStateSubscription = boundParticipant.isLocalParticipant
                ? null
                : participant$
                    .pipe(rxjs.map((p) => p.viewportVisibilityState?.[trackType]), rxjs.distinctUntilChanged())
                    .subscribe((nextViewportVisibilityState) => {
                    // skip initial trigger
                    if (!viewportVisibilityState) {
                        viewportVisibilityState =
                            nextViewportVisibilityState ?? exports.VisibilityState.UNKNOWN;
                        return;
                    }
                    viewportVisibilityState =
                        nextViewportVisibilityState ?? exports.VisibilityState.UNKNOWN;
                    if (nextViewportVisibilityState === exports.VisibilityState.INVISIBLE) {
                        return requestTrackWithDimensions(exports.DebounceType.MEDIUM, undefined);
                    }
                    requestTrackWithDimensions(exports.DebounceType.MEDIUM, {
                        width: videoElement.clientWidth,
                        height: videoElement.clientHeight,
                    });
                });
            let lastDimensions;
            const resizeObserver = boundParticipant.isLocalParticipant
                ? null
                : new ResizeObserver(() => {
                    const currentDimensions = `${videoElement.clientWidth},${videoElement.clientHeight}`;
                    // skip initial trigger
                    if (!lastDimensions) {
                        lastDimensions = currentDimensions;
                        return;
                    }
                    if (lastDimensions === currentDimensions ||
                        viewportVisibilityState === exports.VisibilityState.INVISIBLE) {
                        return;
                    }
                    requestTrackWithDimensions(exports.DebounceType.SLOW, {
                        width: videoElement.clientWidth,
                        height: videoElement.clientHeight,
                    });
                    lastDimensions = currentDimensions;
                });
            resizeObserver?.observe(videoElement);
            // element renders and gets bound - track subscription gets
            // triggered first other ones get skipped on initial subscriptions
            const publishedTracksSubscription = boundParticipant.isLocalParticipant
                ? null
                : participant$
                    .pipe(rxjs.distinctUntilKeyChanged('publishedTracks'), rxjs.map((p) => trackType === 'videoTrack' ? hasVideo(p) : hasScreenShare(p)), rxjs.distinctUntilChanged())
                    .subscribe((isPublishing) => {
                    if (isPublishing) {
                        // the participant just started to publish a track
                        requestTrackWithDimensions(exports.DebounceType.FAST, {
                            width: videoElement.clientWidth,
                            height: videoElement.clientHeight,
                        });
                    }
                    else {
                        // the participant just stopped publishing a track
                        requestTrackWithDimensions(exports.DebounceType.FAST, undefined);
                    }
                });
            videoElement.autoplay = true;
            videoElement.playsInline = true;
            // explicitly marking the element as muted will allow autoplay to work
            // without prior user interaction:
            // https://developer.mozilla.org/en-US/docs/Web/Media/Autoplay_guide
            videoElement.muted = true;
            const streamSubscription = participant$
                .pipe(rxjs.distinctUntilKeyChanged(trackType === 'videoTrack' ? 'videoStream' : 'screenShareStream'))
                .subscribe((p) => {
                const source = trackType === 'videoTrack' ? p.videoStream : p.screenShareStream;
                if (videoElement.srcObject === source)
                    return;
                videoElement.srcObject = source ?? null;
                if (isSafari() || isFirefox()) {
                    setTimeout(() => {
                        videoElement.srcObject = source ?? null;
                        videoElement.play().catch((e) => {
                            this.logger('warn', `Failed to play stream`, e);
                        });
                        // we add extra delay until we attempt to force-play
                        // the participant's media stream in Firefox and Safari,
                        // as they seem to have some timing issues
                    }, 25);
                }
            });
            return () => {
                requestTrackWithDimensions(exports.DebounceType.FAST, undefined);
                viewportVisibilityStateSubscription?.unsubscribe();
                publishedTracksSubscription?.unsubscribe();
                streamSubscription.unsubscribe();
                resizeObserver?.disconnect();
            };
        };
        /**
         * Binds a DOM <audio> element to the given session id.
         *
         * This method will make sure that the audio element will
         * play the correct audio stream for the given session id.
         *
         * @param audioElement the audio element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of audio.
         * @returns a cleanup function that will unbind the audio element.
         */
        this.bindAudioElement = (audioElement, sessionId, trackType) => {
            const participant = this.call.state.findParticipantBySessionId(sessionId);
            if (!participant || participant.isLocalParticipant)
                return;
            const participant$ = this.call.state.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.sessionId === sessionId)), rxjs.takeWhile((p) => !!p), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
            const updateMediaStreamSubscription = participant$
                .pipe(rxjs.distinctUntilKeyChanged(trackType === 'screenShareAudioTrack'
                ? 'screenShareAudioStream'
                : 'audioStream'))
                .subscribe((p) => {
                const source = trackType === 'screenShareAudioTrack'
                    ? p.screenShareAudioStream
                    : p.audioStream;
                if (audioElement.srcObject === source)
                    return;
                setTimeout(() => {
                    audioElement.srcObject = source ?? null;
                    if (audioElement.srcObject) {
                        audioElement.play().catch((e) => {
                            this.logger('warn', `Failed to play stream`, e);
                        });
                        // audio output device shall be set after the audio element is played
                        // otherwise, the browser will not pick it up, and will always
                        // play audio through the system's default device
                        const { selectedDevice } = this.call.speaker.state;
                        if (selectedDevice && 'setSinkId' in audioElement) {
                            audioElement.setSinkId(selectedDevice);
                        }
                    }
                });
            });
            const sinkIdSubscription = !('setSinkId' in audioElement)
                ? null
                : this.call.speaker.state.selectedDevice$.subscribe((deviceId) => {
                    if (deviceId) {
                        audioElement.setSinkId(deviceId);
                    }
                });
            const volumeSubscription = rxjs.combineLatest([
                this.call.speaker.state.volume$,
                participant$.pipe(rxjs.distinctUntilKeyChanged('audioVolume')),
            ]).subscribe(([volume, p]) => {
                audioElement.volume = p.audioVolume ?? volume;
            });
            audioElement.autoplay = true;
            return () => {
                sinkIdSubscription?.unsubscribe();
                volumeSubscription.unsubscribe();
                updateMediaStreamSubscription.unsubscribe();
            };
        };
        this.call = call;
    }
}

/**
 * Stores the permissions for the current user and exposes
 * a few helper methods which make it easier to work with permissions.
 *
 * This is an internal class meant to be used in combination with
 * a {@link Call} instance.
 *
 * @internal
 */
class PermissionsContext {
    constructor() {
        this.permissions = [];
        /**
         * Sets the permissions for the current user.
         *
         * @param permissions the permissions to set.
         */
        this.setPermissions = (permissions) => {
            this.permissions = permissions || [];
        };
        /**
         * Sets the settings for the bound call.
         * @param settings
         */
        this.setCallSettings = (settings) => {
            this.settings = settings;
        };
        /**
         * Checks if the current user has a specific permission.
         *
         * @param permission the permission to check for.
         */
        this.hasPermission = (permission) => {
            return this.permissions.includes(permission);
        };
        /**
         * Checks if the current user can request a specific permission
         * within the call.
         *
         * @param permission the permission to check for.
         * @param settings the call settings to check against (optional).
         */
        this.canRequest = (permission, settings = this.settings) => {
            if (!settings)
                return false;
            const { audio, video, screensharing } = settings;
            switch (permission) {
                case OwnCapability.SEND_AUDIO:
                    return audio.access_request_enabled;
                case OwnCapability.SEND_VIDEO:
                    return video.access_request_enabled;
                case OwnCapability.SCREENSHARE:
                    return screensharing.access_request_enabled;
                default:
                    return false;
            }
        };
    }
}

/**
 * Represents a call type.
 */
class CallType {
    /**
     * Constructs a new CallType.
     *
     * @param name the name of the call type.
     * @param options the options for the call type.
     */
    constructor(name, options = {
        sortParticipantsBy: defaultSortPreset,
    }) {
        this.name = name;
        this.options = options;
    }
}
/**
 * A registry of {@link CallType}s.
 * You can register and unregister call types.
 */
class CallTypesRegistry {
    /**
     * Constructs a new CallTypesRegistry.
     *
     * @param callTypes the initial call types to register.
     */
    constructor(callTypes) {
        /**
         * Registers a new call type.
         *
         * @param callType the call type to register.
         */
        this.register = (callType) => {
            this.callTypes[callType.name] = callType;
        };
        /**
         * Unregisters a call type.
         *
         * @param name the name of the call type to unregister.
         */
        this.unregister = (name) => {
            delete this.callTypes[name];
        };
        /**
         * Gets a call type by name.
         *
         * @param name the name of the call type to get.
         */
        this.get = (name) => {
            if (!this.callTypes[name]) {
                this.register(new CallType(name));
            }
            return this.callTypes[name];
        };
        this.callTypes = callTypes.reduce((acc, callType) => {
            acc[callType.name] = callType;
            return acc;
        }, {});
    }
}
/**
 * The default call types registry.
 * You can use this instance to dynamically register and unregister call types.
 */
const CallTypes = new CallTypesRegistry([
    new CallType('default', {
        sortParticipantsBy: defaultSortPreset,
    }),
    new CallType('development', {
        sortParticipantsBy: defaultSortPreset,
    }),
    new CallType('livestream', {
        sortParticipantsBy: livestreamOrAudioRoomSortPreset,
    }),
    new CallType('audio_room', {
        sortParticipantsBy: livestreamOrAudioRoomSortPreset,
    }),
]);

/**
 * Returns an Observable that emits the list of available devices
 * that meet the given constraints.
 *
 * @param constraints the constraints to use when requesting the devices.
 * @param kind the kind of devices to enumerate.
 */
const getDevices = (constraints, kind) => {
    return new rxjs.Observable((subscriber) => {
        const enumerate = async () => {
            let devices = await navigator.mediaDevices.enumerateDevices();
            // some browsers report empty device labels (Firefox).
            // in that case, we need to request permissions (via getUserMedia)
            // to be able to get the device labels
            const needsGetUserMedia = devices.some((device) => device.kind === kind && device.label === '');
            if (needsGetUserMedia) {
                let mediaStream;
                try {
                    mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                    devices = await navigator.mediaDevices.enumerateDevices();
                }
                finally {
                    if (mediaStream)
                        disposeOfMediaStream(mediaStream);
                }
            }
            return devices;
        };
        enumerate()
            .then((devices) => {
            // notify subscribers and complete
            subscriber.next(devices);
            subscriber.complete();
        })
            .catch((error) => {
            const logger = getLogger(['devices']);
            logger('error', 'Failed to enumerate devices', error);
            subscriber.error(error);
        });
    });
};
/**
 * [Tells if the browser supports audio output change on 'audio' elements](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/setSinkId).
 *
 *  */
const checkIfAudioOutputChangeSupported = () => {
    if (typeof document === 'undefined')
        return false;
    const element = document.createElement('audio');
    return 'setSinkId' in element;
};
/**
 * The default constraints used to request audio devices.
 */
const audioDeviceConstraints = {
    audio: {
        autoGainControl: true,
        noiseSuppression: true,
        echoCancellation: true,
    },
};
/**
 * The default constraints used to request video devices.
 */
const videoDeviceConstraints = {
    video: {
        width: 1280,
        height: 720,
    },
};
/**
 * Creates a memoized observable instance
 * that will be created only once and shared between all callers.
 *
 * @param create a function that creates an Observable.
 */
const memoizedObservable = (create) => {
    let memoized;
    return () => {
        if (!memoized)
            memoized = create();
        return memoized;
    };
};
const getDeviceChangeObserver = memoizedObservable(() => {
    // Audio and video devices are requested in two separate requests.
    // That way, users will be presented with two separate prompts
    // -> they can give access to just camera, or just microphone
    return new rxjs.Observable((subscriber) => {
        // 'addEventListener' is not available in React Native
        if (!navigator.mediaDevices.addEventListener)
            return;
        const notify = () => subscriber.next();
        navigator.mediaDevices.addEventListener('devicechange', notify);
        return () => {
            navigator.mediaDevices.removeEventListener('devicechange', notify);
        };
    }).pipe(rxjs.debounceTime(500), rxjs.concatMap(() => rxjs.from(navigator.mediaDevices.enumerateDevices())), rxjs.shareReplay(1));
});
const getAudioDevicesObserver = memoizedObservable(() => {
    return rxjs.merge(getDevices(audioDeviceConstraints, 'audioinput'), getDeviceChangeObserver()).pipe(rxjs.shareReplay(1));
});
const getAudioOutputDevicesObserver = memoizedObservable(() => {
    return rxjs.merge(getDevices(audioDeviceConstraints, 'audiooutput'), getDeviceChangeObserver()).pipe(rxjs.shareReplay(1));
});
const getVideoDevicesObserver = memoizedObservable(() => {
    return rxjs.merge(getDevices(videoDeviceConstraints, 'videoinput'), getDeviceChangeObserver()).pipe(rxjs.shareReplay(1));
});
/**
 * Prompts the user for a permission to use audio devices (if not already granted) and lists the available 'audioinput' devices, if devices are added/removed the list is updated.
 */
const getAudioDevices = () => {
    return getAudioDevicesObserver().pipe(rxjs.map((values) => values.filter((d) => d.kind === 'audioinput')));
};
/**
 * Prompts the user for a permission to use video devices (if not already granted) and lists the available 'videoinput' devices, if devices are added/removed the list is updated.
 */
const getVideoDevices = () => {
    return getVideoDevicesObserver().pipe(rxjs.map((values) => values.filter((d) => d.kind === 'videoinput')));
};
/**
 * Prompts the user for a permission to use audio devices (if not already granted) and lists the available 'audiooutput' devices, if devices are added/removed the list is updated. Selecting 'audiooutput' device only makes sense if [the browser has support for changing audio output on 'audio' elements](#checkifaudiooutputchangesupported)
 */
const getAudioOutputDevices = () => {
    return getAudioOutputDevicesObserver().pipe(rxjs.map((values) => values.filter((d) => d.kind === 'audiooutput')));
};
const getStream = async (constraints) => {
    try {
        return await navigator.mediaDevices.getUserMedia(constraints);
    }
    catch (e) {
        getLogger(['devices'])('error', `Failed get user media`, {
            error: e,
            constraints: constraints,
        });
        throw e;
    }
};
/**
 * Returns an audio media stream that fulfills the given constraints.
 * If no constraints are provided, it uses the browser's default ones.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 * @param trackConstraints the constraints to use when requesting the stream.
 * @returns the new `MediaStream` fulfilling the given constraints.
 */
const getAudioStream = async (trackConstraints) => {
    const constraints = {
        audio: {
            ...audioDeviceConstraints.audio,
            ...trackConstraints,
        },
    };
    return getStream(constraints);
};
/**
 * Returns a video media stream that fulfills the given constraints.
 * If no constraints are provided, it uses the browser's default ones.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 * @param trackConstraints the constraints to use when requesting the stream.
 * @returns a new `MediaStream` fulfilling the given constraints.
 */
const getVideoStream = async (trackConstraints) => {
    const constraints = {
        video: {
            ...videoDeviceConstraints.video,
            ...trackConstraints,
        },
    };
    return getStream(constraints);
};
/**
 * Prompts the user for a permission to share a screen.
 * If the user grants the permission, a screen sharing stream is returned. Throws otherwise.
 *
 * The callers of this API are responsible to handle the possible errors.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 *
 * @param options any additional options to pass to the [`getDisplayMedia`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia) API.
 */
const getScreenShareStream = async (options) => {
    try {
        return await navigator.mediaDevices.getDisplayMedia({
            video: true,
            audio: {
                channelCount: {
                    ideal: 2,
                },
                echoCancellation: false,
                autoGainControl: false,
                noiseSuppression: false,
            },
            // @ts-expect-error - not present in types yet
            systemAudio: 'include',
            ...options,
        });
    }
    catch (e) {
        getLogger(['devices'])('error', 'Failed to get screen share stream', e);
        throw e;
    }
};
const deviceIds$ = typeof navigator !== 'undefined' &&
    typeof navigator.mediaDevices !== 'undefined'
    ? memoizedObservable(() => rxjs.merge(rxjs.from(navigator.mediaDevices.enumerateDevices()), getDeviceChangeObserver()).pipe(rxjs.shareReplay(1)))()
    : undefined;
/**
 * Deactivates MediaStream (stops and removes tracks) to be later garbage collected
 *
 * @param stream MediaStream
 * @returns void
 */
const disposeOfMediaStream = (stream) => {
    if (!stream.active)
        return;
    stream.getTracks().forEach((track) => {
        track.stop();
        stream.removeTrack(track);
    });
    // @ts-expect-error release() is present in react-native-webrtc and must be called to dispose the stream
    if (typeof stream.release === 'function') {
        // @ts-expect-error
        stream.release();
    }
};

class InputMediaDeviceManager {
    constructor(call, state, trackType) {
        this.call = call;
        this.state = state;
        this.trackType = trackType;
        /**
         * if true, stops the media stream when call is left
         */
        this.stopOnLeave = true;
        this.subscriptions = [];
        this.isTrackStoppedDueToTrackEnd = false;
        this.filters = [];
        /**
         * Disposes the manager.
         *
         * @internal
         */
        this.dispose = () => {
            this.subscriptions.forEach((s) => s());
        };
        this.logger = getLogger([`${TrackType[trackType].toLowerCase()} manager`]);
        if (deviceIds$ &&
            !isReactNative() &&
            (this.trackType === TrackType.AUDIO || this.trackType === TrackType.VIDEO)) {
            this.handleDisconnectedOrReplacedDevices();
        }
    }
    /**
     * Lists the available audio/video devices
     *
     * Note: It prompts the user for a permission to use devices (if not already granted)
     *
     * @returns an Observable that will be updated if a device is connected or disconnected
     */
    listDevices() {
        return this.getDevices();
    }
    /**
     * Starts stream.
     */
    async enable() {
        if (this.state.optimisticStatus === 'enabled') {
            await this.statusChangePromise;
            return;
        }
        const signal = this.nextAbortableStatusChangeRequest('enabled');
        const doEnable = async () => {
            if (signal.aborted)
                return;
            try {
                await this.unmuteStream();
                this.state.setStatus('enabled');
            }
            finally {
                if (!signal.aborted)
                    this.resetStatusChangeRequest();
            }
        };
        this.statusChangePromise = this.statusChangePromise
            ? this.statusChangePromise.then(doEnable)
            : doEnable();
        await this.statusChangePromise;
    }
    /**
     * Stops or pauses the stream based on state.disableMode
     * @param {boolean} [forceStop=false] when true, stops the tracks regardless of the state.disableMode
     */
    async disable(forceStop = false) {
        this.state.prevStatus = this.state.status;
        if (!forceStop && this.state.optimisticStatus === 'disabled') {
            await this.statusChangePromise;
            return;
        }
        const stopTracks = forceStop || this.state.disableMode === 'stop-tracks';
        const signal = this.nextAbortableStatusChangeRequest('disabled');
        const doDisable = async () => {
            if (signal.aborted)
                return;
            try {
                await this.muteStream(stopTracks);
                this.state.setStatus('disabled');
            }
            finally {
                if (!signal.aborted)
                    this.resetStatusChangeRequest();
            }
        };
        this.statusChangePromise = this.statusChangePromise
            ? this.statusChangePromise.then(doDisable)
            : doDisable();
        await this.statusChangePromise;
    }
    /**
     * If status was previously enabled, it will re-enable the device.
     */
    async resume() {
        if (this.state.prevStatus === 'enabled' &&
            this.state.status === 'disabled') {
            await this.enable();
        }
    }
    /**
     * If the current device status is disabled, it will enable the device,
     * else it will disable it.
     */
    async toggle() {
        if (this.state.optimisticStatus === 'enabled') {
            return this.disable();
        }
        else {
            return this.enable();
        }
    }
    /**
     * Registers a filter that will be applied to the stream.
     *
     * The registered filter will get the existing stream, and it should return
     * a new stream with the applied filter.
     *
     * @param filter the filter to register.
     * @returns a function that will unregister the filter.
     */
    async registerFilter(filter) {
        this.filters.push(filter);
        await this.applySettingsToStream();
        return async () => {
            this.filters = this.filters.filter((f) => f !== filter);
            await this.applySettingsToStream();
        };
    }
    /**
     * Will set the default constraints for the device.
     *
     * @param constraints the constraints to set.
     */
    setDefaultConstraints(constraints) {
        this.state.setDefaultConstraints(constraints);
    }
    /**
     * Selects a device.
     *
     * Note: This method is not supported in React Native
     * @param deviceId the device id to select.
     */
    async select(deviceId) {
        if (isReactNative()) {
            throw new Error('This method is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for reference.');
        }
        if (deviceId === this.state.selectedDevice) {
            return;
        }
        this.state.setDevice(deviceId);
        await this.applySettingsToStream();
    }
    async applySettingsToStream() {
        if (this.state.status === 'enabled') {
            await this.muteStream();
            await this.unmuteStream();
        }
    }
    getTracks() {
        return this.state.mediaStream?.getTracks() ?? [];
    }
    async muteStream(stopTracks = true) {
        if (!this.state.mediaStream)
            return;
        this.logger('debug', `${stopTracks ? 'Stopping' : 'Disabling'} stream`);
        if (this.call.state.callingState === exports.CallingState.JOINED) {
            await this.stopPublishStream(stopTracks);
        }
        this.muteLocalStream(stopTracks);
        const allEnded = this.getTracks().every((t) => t.readyState === 'ended');
        if (allEnded) {
            if (this.state.mediaStream &&
                // @ts-expect-error release() is present in react-native-webrtc
                typeof this.state.mediaStream.release === 'function') {
                // @ts-expect-error called to dispose the stream in RN
                this.state.mediaStream.release();
            }
            this.state.setMediaStream(undefined, undefined);
        }
    }
    muteTracks() {
        this.getTracks().forEach((track) => {
            if (track.enabled)
                track.enabled = false;
        });
    }
    unmuteTracks() {
        this.getTracks().forEach((track) => {
            if (!track.enabled)
                track.enabled = true;
        });
    }
    stopTracks() {
        this.getTracks().forEach((track) => {
            if (track.readyState === 'live')
                track.stop();
        });
    }
    muteLocalStream(stopTracks) {
        if (!this.state.mediaStream) {
            return;
        }
        if (stopTracks) {
            this.stopTracks();
        }
        else {
            this.muteTracks();
        }
    }
    async unmuteStream() {
        this.logger('debug', 'Starting stream');
        let stream;
        let rootStream;
        if (this.state.mediaStream &&
            this.getTracks().every((t) => t.readyState === 'live')) {
            stream = this.state.mediaStream;
            this.unmuteTracks();
        }
        else {
            const defaultConstraints = this.state.defaultConstraints;
            const constraints = {
                ...defaultConstraints,
                deviceId: this.state.selectedDevice,
            };
            /**
             * Chains two media streams together.
             *
             * In our case, filters MediaStreams are derived from their parent MediaStream.
             * However, once a child filter's track is stopped,
             * the tracks of the parent MediaStream aren't automatically stopped.
             * This leads to a situation where the camera indicator light is still on
             * even though the user stopped publishing video.
             *
             * This function works around this issue by stopping the parent MediaStream's tracks
             * as well once the child filter's tracks are stopped.
             *
             * It works by patching the stop() method of the child filter's tracks to also stop
             * the parent MediaStream's tracks of the same type. Here we assume that
             * the parent MediaStream has only one track of each type.
             *
             * @param parentStream the parent MediaStream. Omit for the root stream.
             */
            const chainWith = (parentStream) => async (filterStream) => {
                if (!parentStream)
                    return filterStream;
                // TODO OL: take care of track.enabled property as well
                const parent = await parentStream;
                filterStream.getTracks().forEach((track) => {
                    const originalStop = track.stop;
                    track.stop = function stop() {
                        originalStop.call(track);
                        parent.getTracks().forEach((parentTrack) => {
                            if (parentTrack.kind === track.kind) {
                                parentTrack.stop();
                            }
                        });
                    };
                });
                parent.getTracks().forEach((parentTrack) => {
                    // When the parent stream abruptly ends, we propagate the event
                    // to the filter stream.
                    // This usually happens when the camera/microphone permissions
                    // are revoked or when the device is disconnected.
                    const handleParentTrackEnded = () => {
                        filterStream.getTracks().forEach((track) => {
                            if (parentTrack.kind !== track.kind)
                                return;
                            track.stop();
                            track.dispatchEvent(new Event('ended')); // propagate the event
                        });
                    };
                    parentTrack.addEventListener('ended', handleParentTrackEnded);
                    this.subscriptions.push(() => {
                        parentTrack.removeEventListener('ended', handleParentTrackEnded);
                    });
                });
                return filterStream;
            };
            // the rootStream represents the stream coming from the actual device
            // e.g. camera or microphone stream
            rootStream = this.getStream(constraints);
            // we publish the last MediaStream of the chain
            stream = await this.filters.reduce((parent, filter) => parent.then(filter).then(chainWith(parent)), rootStream);
        }
        if (this.call.state.callingState === exports.CallingState.JOINED) {
            await this.publishStream(stream);
        }
        if (this.state.mediaStream !== stream) {
            this.state.setMediaStream(stream, await rootStream);
            this.getTracks().forEach((track) => {
                track.addEventListener('ended', async () => {
                    if (this.statusChangePromise) {
                        await this.statusChangePromise;
                    }
                    if (this.state.status === 'enabled') {
                        this.isTrackStoppedDueToTrackEnd = true;
                        setTimeout(() => {
                            this.isTrackStoppedDueToTrackEnd = false;
                        }, 2000);
                        await this.disable();
                    }
                });
            });
        }
    }
    get mediaDeviceKind() {
        if (this.trackType === TrackType.AUDIO) {
            return 'audioinput';
        }
        if (this.trackType === TrackType.VIDEO) {
            return 'videoinput';
        }
        return '';
    }
    handleDisconnectedOrReplacedDevices() {
        this.subscriptions.push(createSubscription(rxjs.combineLatest([
            deviceIds$.pipe(rxjs.pairwise()),
            this.state.selectedDevice$,
        ]), async ([[prevDevices, currentDevices], deviceId]) => {
            if (!deviceId) {
                return;
            }
            if (this.statusChangePromise) {
                await this.statusChangePromise;
            }
            let isDeviceDisconnected = false;
            let isDeviceReplaced = false;
            const currentDevice = this.findDeviceInList(currentDevices, deviceId);
            const prevDevice = this.findDeviceInList(prevDevices, deviceId);
            if (!currentDevice && prevDevice) {
                isDeviceDisconnected = true;
            }
            else if (currentDevice &&
                prevDevice &&
                currentDevice.deviceId === prevDevice.deviceId &&
                currentDevice.groupId !== prevDevice.groupId) {
                isDeviceReplaced = true;
            }
            if (isDeviceDisconnected) {
                await this.disable();
                this.select(undefined);
            }
            if (isDeviceReplaced) {
                if (this.isTrackStoppedDueToTrackEnd &&
                    this.state.status === 'disabled') {
                    await this.enable();
                    this.isTrackStoppedDueToTrackEnd = false;
                }
                else {
                    await this.applySettingsToStream();
                }
            }
        }));
    }
    findDeviceInList(devices, deviceId) {
        return devices.find((d) => d.deviceId === deviceId && d.kind === this.mediaDeviceKind);
    }
    nextAbortableStatusChangeRequest(status) {
        this.statusChangeAbortController?.abort();
        this.statusChangeAbortController = new AbortController();
        this.state.setPendingStatus(status);
        return this.statusChangeAbortController.signal;
    }
    resetStatusChangeRequest() {
        this.statusChangePromise = undefined;
        this.statusChangeAbortController = undefined;
        this.state.setPendingStatus(this.state.status);
    }
}

class InputMediaDeviceManagerState {
    /**
     * Constructs new InputMediaDeviceManagerState instance.
     *
     * @param disableMode the disable mode to use.
     * @param permissionName the permission name to use for querying.
     * `undefined` means no permission is required.
     */
    constructor(disableMode = 'stop-tracks', permissionName = undefined) {
        this.disableMode = disableMode;
        this.permissionName = permissionName;
        this.statusSubject = new rxjs.BehaviorSubject(undefined);
        this.optimisticStatusSubject = new rxjs.BehaviorSubject(undefined);
        this.mediaStreamSubject = new rxjs.BehaviorSubject(undefined);
        this.selectedDeviceSubject = new rxjs.BehaviorSubject(undefined);
        this.defaultConstraintsSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * An Observable that emits the current media stream, or `undefined` if the device is currently disabled.
         *
         */
        this.mediaStream$ = this.mediaStreamSubject.asObservable();
        /**
         * An Observable that emits the currently selected device
         */
        this.selectedDevice$ = this.selectedDeviceSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable that emits the device status
         */
        this.status$ = this.statusSubject.asObservable().pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable the reflects the requested device status. Useful for optimistic UIs
         */
        this.optimisticStatus$ = this.optimisticStatusSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * The default constraints for the device.
         */
        this.defaultConstraints$ = this.defaultConstraintsSubject.asObservable();
        /**
         * An observable that will emit `true` if browser/system permission
         * is granted, `false` otherwise.
         */
        this.hasBrowserPermission$ = new rxjs.Observable((subscriber) => {
            const notifyGranted = () => subscriber.next(true);
            const permissionsAPIAvailable = !!navigator?.permissions?.query;
            if (isReactNative() || !this.permissionName || !permissionsAPIAvailable) {
                getLogger(['devices'])('warn', `Permissions can't be queried. Assuming granted.`);
                return notifyGranted();
            }
            let permissionState;
            const notify = () => {
                subscriber.next(
                // In some browsers, the 'change' event doesn't reliably emit and hence,
                // permissionState stays in 'prompt' state forever.
                // Typically, this happens when a user grants one-time permission.
                // Instead of checking if a permission is granted, we check if it isn't denied
                permissionState.state !== 'denied');
            };
            navigator.permissions
                .query({ name: this.permissionName })
                .then((permissionStatus) => {
                permissionState = permissionStatus;
                permissionState.addEventListener('change', notify);
                notify();
            })
                .catch(() => {
                // permission doesn't exist or can't be queried -> assume it's granted
                // an example would be Firefox,
                // where neither camera microphone permission can be queried
                notifyGranted();
            });
            return () => {
                permissionState?.removeEventListener('change', notify);
            };
        }).pipe(rxjs.shareReplay(1));
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
    }
    /**
     * The device status
     */
    get status() {
        return this.getCurrentValue(this.status$);
    }
    /**
     * The requested device status. Useful for optimistic UIs
     */
    get optimisticStatus() {
        return this.getCurrentValue(this.optimisticStatus$);
    }
    /**
     * The currently selected device
     */
    get selectedDevice() {
        return this.getCurrentValue(this.selectedDevice$);
    }
    /**
     * The current media stream, or `undefined` if the device is currently disabled.
     */
    get mediaStream() {
        return this.getCurrentValue(this.mediaStream$);
    }
    /**
     * @internal
     * @param status
     */
    setStatus(status) {
        this.setCurrentValue(this.statusSubject, status);
    }
    /**
     * @internal
     * @param pendingStatus
     */
    setPendingStatus(pendingStatus) {
        this.setCurrentValue(this.optimisticStatusSubject, pendingStatus);
    }
    /**
     * Updates the `mediaStream` state variable.
     *
     * @internal
     * @param stream the stream to set.
     * @param rootStream the root stream, applicable when filters are used
     * as this is the stream that holds the actual deviceId information.
     */
    setMediaStream(stream, rootStream) {
        this.setCurrentValue(this.mediaStreamSubject, stream);
        if (rootStream) {
            this.setDevice(this.getDeviceIdFromStream(rootStream));
        }
    }
    /**
     * @internal
     * @param deviceId the device id to set.
     */
    setDevice(deviceId) {
        this.setCurrentValue(this.selectedDeviceSubject, deviceId);
    }
    /**
     * Gets the default constraints for the device.
     */
    get defaultConstraints() {
        return this.getCurrentValue(this.defaultConstraints$);
    }
    /**
     * Sets the default constraints for the device.
     *
     * @internal
     * @param constraints the constraints to set.
     */
    setDefaultConstraints(constraints) {
        this.setCurrentValue(this.defaultConstraintsSubject, constraints);
    }
}

class CameraManagerState extends InputMediaDeviceManagerState {
    constructor() {
        super('stop-tracks', 
        // `camera` is not in the W3C standard yet,
        // but it's supported by Chrome and Safari.
        'camera');
        this.directionSubject = new rxjs.BehaviorSubject(undefined);
        this.direction$ = this.directionSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * The preferred camera direction
     * front - means the camera facing the user
     * back - means the camera facing the environment
     */
    get direction() {
        return this.getCurrentValue(this.direction$);
    }
    /**
     * @internal
     */
    setDirection(direction) {
        this.setCurrentValue(this.directionSubject, direction);
    }
    /**
     * @internal
     */
    setMediaStream(stream, rootStream) {
        super.setMediaStream(stream, rootStream);
        if (stream) {
            // RN getSettings() doesn't return facingMode, so we don't verify camera direction
            const direction = isReactNative()
                ? this.direction
                : stream.getVideoTracks()[0]?.getSettings().facingMode === 'environment'
                    ? 'back'
                    : 'front';
            this.setDirection(direction);
        }
    }
    getDeviceIdFromStream(stream) {
        const [track] = stream.getVideoTracks();
        return track?.getSettings().deviceId;
    }
}

class CameraManager extends InputMediaDeviceManager {
    constructor(call) {
        super(call, new CameraManagerState(), TrackType.VIDEO);
        this.targetResolution = {
            width: 1280,
            height: 720,
        };
    }
    /**
     * Select the camera direction.
     *
     * @param direction the direction of the camera to select.
     */
    async selectDirection(direction) {
        this.state.setDirection(direction);
        // Providing both device id and direction doesn't work, so we deselect the device
        this.state.setDevice(undefined);
        await this.applySettingsToStream();
    }
    /**
     * Flips the camera direction: if it's front it will change to back, if it's back, it will change to front.
     *
     * Note: if there is no available camera with the desired direction, this method will do nothing.
     * @returns
     */
    async flip() {
        const newDirection = this.state.direction === 'front' ? 'back' : 'front';
        await this.selectDirection(newDirection);
    }
    /**
     * @internal
     */
    async selectTargetResolution(resolution) {
        this.targetResolution.height = resolution.height;
        this.targetResolution.width = resolution.width;
        if (this.statusChangePromise && this.state.optimisticStatus === 'enabled') {
            try {
                await this.statusChangePromise;
            }
            catch (error) {
                // couldn't enable device, target resolution will be applied the next time user attempts to start the device
                this.logger('warn', 'could not apply target resolution', error);
            }
        }
        if (this.state.status === 'enabled') {
            const { width, height } = this.state
                .mediaStream.getVideoTracks()[0]
                ?.getSettings();
            if (width !== this.targetResolution.width ||
                height !== this.targetResolution.height) {
                await this.applySettingsToStream();
                this.logger('debug', `${width}x${height} target resolution applied to media stream`);
            }
        }
    }
    /**
     * Sets the preferred codec for encoding the video.
     *
     * @internal internal use only, not part of the public API.
     * @param codec the codec to use for encoding the video.
     */
    setPreferredCodec(codec) {
        this.preferredCodec = codec;
    }
    getDevices() {
        return getVideoDevices();
    }
    getStream(constraints) {
        constraints.width = this.targetResolution.width;
        constraints.height = this.targetResolution.height;
        // We can't set both device id and facing mode
        // Device id has higher priority
        if (!constraints.deviceId && this.state.direction) {
            constraints.facingMode =
                this.state.direction === 'front' ? 'user' : 'environment';
        }
        return getVideoStream(constraints);
    }
    publishStream(stream) {
        return this.call.publishVideoStream(stream, {
            preferredCodec: this.preferredCodec,
        });
    }
    stopPublishStream(stopTracks) {
        return this.call.stopPublish(TrackType.VIDEO, stopTracks);
    }
}

class MicrophoneManagerState extends InputMediaDeviceManagerState {
    constructor(disableMode) {
        super(disableMode, 
        // `microphone` is not in the W3C standard yet,
        // but it's supported by Chrome and Safari.
        'microphone');
        this.speakingWhileMutedSubject = new rxjs.BehaviorSubject(false);
        this.speakingWhileMuted$ = this.speakingWhileMutedSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * `true` if the user's microphone is muted but they'are speaking.
     *
     * This feature is not available in the React Native SDK.
     */
    get speakingWhileMuted() {
        return this.getCurrentValue(this.speakingWhileMuted$);
    }
    /**
     * @internal
     */
    setSpeakingWhileMuted(isSpeaking) {
        this.setCurrentValue(this.speakingWhileMutedSubject, isSpeaking);
    }
    getDeviceIdFromStream(stream) {
        const [track] = stream.getAudioTracks();
        return track?.getSettings().deviceId;
    }
}

const DETECTION_FREQUENCY_IN_MS = 500;
const AUDIO_LEVEL_THRESHOLD$1 = 150;
const FFT_SIZE = 128;
/**
 * Creates a new sound detector.
 *
 * @param audioStream the audio stream to observe. Depending on the provided configuration, this stream might be destroyed when the sound detector is stopped.
 * @param onSoundDetectedStateChanged a callback which is called when the sound state changes.
 * @param options custom options for the sound detector.
 * @returns a clean-up function which once invoked stops the sound detector.
 */
const createSoundDetector = (audioStream, onSoundDetectedStateChanged, options = {}) => {
    const { detectionFrequencyInMs = DETECTION_FREQUENCY_IN_MS, audioLevelThreshold = AUDIO_LEVEL_THRESHOLD$1, fftSize = FFT_SIZE, destroyStreamOnStop = true, } = options;
    const audioContext = new AudioContext();
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = fftSize;
    const microphone = audioContext.createMediaStreamSource(audioStream);
    microphone.connect(analyser);
    const intervalId = setInterval(() => {
        const data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        const isSoundDetected = data.some((value) => value >= audioLevelThreshold);
        const averagedDataValue = data.reduce((pv, cv) => pv + cv, 0) / data.length;
        const percentage = averagedDataValue > audioLevelThreshold
            ? 100
            : Math.round((averagedDataValue / audioLevelThreshold) * 100);
        // When the track is disabled, it takes time for the buffer to empty
        // This check will ensure that we don't send anything if the track is disabled
        if (audioStream.getAudioTracks()[0]?.enabled) {
            onSoundDetectedStateChanged({ isSoundDetected, audioLevel: percentage });
        }
        else {
            onSoundDetectedStateChanged({ isSoundDetected: false, audioLevel: 0 });
        }
    }, detectionFrequencyInMs);
    return async function stop() {
        clearInterval(intervalId);
        // clean-up the AudioContext elements
        microphone.disconnect();
        analyser.disconnect();
        if (audioContext.state !== 'closed') {
            await audioContext.close();
        }
        // stop the stream
        if (destroyStreamOnStop) {
            audioStream.getTracks().forEach((track) => {
                track.stop();
                audioStream.removeTrack(track);
            });
        }
    };
};

const AUDIO_LEVEL_THRESHOLD = 0.2;
class RNSpeechDetector {
    constructor() {
        this.pc1 = new RTCPeerConnection({});
        this.pc2 = new RTCPeerConnection({});
    }
    /**
     * Starts the speech detection.
     */
    async start() {
        try {
            const audioStream = await navigator.mediaDevices.getUserMedia({
                audio: true,
            });
            this.pc1.addEventListener('icecandidate', async (e) => {
                await this.pc2.addIceCandidate(e.candidate);
            });
            this.pc2.addEventListener('icecandidate', async (e) => {
                await this.pc1.addIceCandidate(e.candidate);
            });
            audioStream
                .getTracks()
                .forEach((track) => this.pc1.addTrack(track, audioStream));
            const offer = await this.pc1.createOffer({});
            await this.pc2.setRemoteDescription(offer);
            await this.pc1.setLocalDescription(offer);
            const answer = await this.pc2.createAnswer();
            await this.pc1.setRemoteDescription(answer);
            await this.pc2.setLocalDescription(answer);
            const audioTracks = audioStream.getAudioTracks();
            // We need to mute the audio track for this temporary stream, or else you will hear yourself twice while in the call.
            audioTracks.forEach((track) => (track.enabled = false));
        }
        catch (error) {
            console.error('Error connecting and negotiating between PeerConnections:', error);
        }
    }
    /**
     * Stops the speech detection and releases all allocated resources.
     */
    stop() {
        this.pc1.close();
        this.pc2.close();
        if (this.intervalId) {
            clearInterval(this.intervalId);
        }
    }
    /**
     * Public method that detects the audio levels and returns the status.
     */
    onSpeakingDetectedStateChange(onSoundDetectedStateChanged) {
        this.intervalId = setInterval(async () => {
            const stats = (await this.pc1.getStats());
            const report = flatten(stats);
            // Audio levels are present inside stats of type `media-source` and of kind `audio`
            const audioMediaSourceStats = report.find((stat) => stat.type === 'media-source' &&
                stat.kind === 'audio');
            if (audioMediaSourceStats) {
                const { audioLevel } = audioMediaSourceStats;
                if (audioLevel) {
                    if (audioLevel >= AUDIO_LEVEL_THRESHOLD) {
                        onSoundDetectedStateChanged({
                            isSoundDetected: true,
                            audioLevel,
                        });
                    }
                    else {
                        onSoundDetectedStateChanged({
                            isSoundDetected: false,
                            audioLevel: 0,
                        });
                    }
                }
            }
        }, 1000);
        return () => {
            clearInterval(this.intervalId);
        };
    }
}

class MicrophoneManager extends InputMediaDeviceManager {
    constructor(call, disableMode = isReactNative()
        ? 'disable-tracks'
        : 'stop-tracks') {
        super(call, new MicrophoneManagerState(disableMode), TrackType.AUDIO);
        this.speakingWhileMutedNotificationEnabled = true;
        this.subscriptions.push(createSubscription(rxjs.combineLatest([
            this.call.state.callingState$,
            this.call.state.ownCapabilities$,
            this.state.selectedDevice$,
            this.state.status$,
        ]), async ([callingState, ownCapabilities, deviceId, status]) => {
            if (callingState === exports.CallingState.LEFT) {
                await this.stopSpeakingWhileMutedDetection();
            }
            if (callingState !== exports.CallingState.JOINED)
                return;
            if (!this.speakingWhileMutedNotificationEnabled)
                return;
            if (ownCapabilities.includes(OwnCapability.SEND_AUDIO)) {
                if (status === 'disabled') {
                    await this.startSpeakingWhileMutedDetection(deviceId);
                }
                else {
                    await this.stopSpeakingWhileMutedDetection();
                }
            }
            else {
                await this.stopSpeakingWhileMutedDetection();
            }
        }));
        this.subscriptions.push(createSubscription(this.call.state.callingState$, (callingState) => {
            // do nothing when noise filtering isn't turned on
            if (!this.noiseCancellationRegistration || !this.noiseCancellation)
                return;
            const autoOn = this.call.state.settings?.audio.noise_cancellation?.mode ===
                NoiseCancellationSettingsModeEnum.AUTO_ON;
            if (autoOn && callingState === exports.CallingState.JOINED) {
                this.noiseCancellationRegistration
                    .then(() => this.noiseCancellation?.enable())
                    .catch((err) => {
                    this.logger('warn', `Failed to enable noise cancellation`, err);
                    return this.call.notifyNoiseCancellationStopped();
                });
            }
            else if (callingState === exports.CallingState.LEFT) {
                this.noiseCancellationRegistration
                    .then(() => this.noiseCancellation?.disable())
                    .catch((err) => {
                    this.logger('warn', `Failed to disable noise cancellation`, err);
                });
            }
        }));
    }
    /**
     * Enables noise cancellation for the microphone.
     *
     * Note: not supported in React Native.
     * @param noiseCancellation - a noise cancellation instance to use.
     */
    async enableNoiseCancellation(noiseCancellation) {
        if (isReactNative()) {
            throw new Error('Noise cancellation is not supported in React Native');
        }
        const { ownCapabilities, settings } = this.call.state;
        const hasNoiseCancellationCapability = ownCapabilities.includes(OwnCapability.ENABLE_NOISE_CANCELLATION);
        if (!hasNoiseCancellationCapability) {
            throw new Error('Noise cancellation is not available.');
        }
        const noiseCancellationSettings = settings?.audio.noise_cancellation;
        if (!noiseCancellationSettings ||
            noiseCancellationSettings.mode ===
                NoiseCancellationSettingsModeEnum.DISABLED) {
            throw new Error('Noise cancellation is disabled for this call type.');
        }
        try {
            this.noiseCancellation = noiseCancellation;
            // listen for change events and notify the SFU
            this.noiseCancellationChangeUnsubscribe = this.noiseCancellation.on('change', (enabled) => {
                if (enabled) {
                    this.call.notifyNoiseCancellationStarting().catch((err) => {
                        this.logger('warn', `notifyNoiseCancellationStart failed`, err);
                    });
                }
                else {
                    this.call.notifyNoiseCancellationStopped().catch((err) => {
                        this.logger('warn', `notifyNoiseCancellationStop failed`, err);
                    });
                }
            });
            this.noiseCancellationRegistration = this.registerFilter(noiseCancellation.toFilter());
            await this.noiseCancellationRegistration;
            // handles an edge case where a noise cancellation is enabled after
            // the participant as joined the call -> we immediately enable NC
            if (noiseCancellationSettings.mode ===
                NoiseCancellationSettingsModeEnum.AUTO_ON &&
                this.call.state.callingState === exports.CallingState.JOINED) {
                noiseCancellation.enable();
            }
        }
        catch (e) {
            this.logger('warn', 'Failed to enable noise cancellation', e);
            await this.disableNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to disable noise cancellation', err);
            });
        }
    }
    /**
     * Disables noise cancellation for the microphone.
     *
     * Note: not supported in React Native.
     */
    async disableNoiseCancellation() {
        if (isReactNative()) {
            throw new Error('Noise cancellation is not supported in React Native');
        }
        await this.noiseCancellationRegistration
            ?.then((unregister) => unregister())
            .then(() => this.noiseCancellation?.disable())
            .then(() => this.noiseCancellationChangeUnsubscribe?.())
            .catch((err) => {
            this.logger('warn', 'Failed to unregister noise cancellation', err);
        });
        await this.call.notifyNoiseCancellationStopped();
    }
    /**
     * Enables speaking while muted notification.
     */
    async enableSpeakingWhileMutedNotification() {
        this.speakingWhileMutedNotificationEnabled = true;
        if (this.state.status === 'disabled') {
            await this.startSpeakingWhileMutedDetection(this.state.selectedDevice);
        }
    }
    /**
     * Disables speaking while muted notification.
     */
    async disableSpeakingWhileMutedNotification() {
        this.speakingWhileMutedNotificationEnabled = false;
        await this.stopSpeakingWhileMutedDetection();
    }
    getDevices() {
        return getAudioDevices();
    }
    getStream(constraints) {
        return getAudioStream(constraints);
    }
    publishStream(stream) {
        return this.call.publishAudioStream(stream);
    }
    stopPublishStream(stopTracks) {
        return this.call.stopPublish(TrackType.AUDIO, stopTracks);
    }
    async startSpeakingWhileMutedDetection(deviceId) {
        await this.stopSpeakingWhileMutedDetection();
        if (isReactNative()) {
            this.rnSpeechDetector = new RNSpeechDetector();
            await this.rnSpeechDetector.start();
            const unsubscribe = this.rnSpeechDetector?.onSpeakingDetectedStateChange((event) => {
                this.state.setSpeakingWhileMuted(event.isSoundDetected);
            });
            this.soundDetectorCleanup = () => {
                unsubscribe();
                this.rnSpeechDetector?.stop();
                this.rnSpeechDetector = undefined;
            };
        }
        else {
            // Need to start a new stream that's not connected to publisher
            const stream = await this.getStream({
                deviceId,
            });
            this.soundDetectorCleanup = createSoundDetector(stream, (event) => {
                this.state.setSpeakingWhileMuted(event.isSoundDetected);
            });
        }
    }
    async stopSpeakingWhileMutedDetection() {
        if (!this.soundDetectorCleanup)
            return;
        this.state.setSpeakingWhileMuted(false);
        try {
            await this.soundDetectorCleanup();
        }
        finally {
            this.soundDetectorCleanup = undefined;
        }
    }
}

class ScreenShareState extends InputMediaDeviceManagerState {
    constructor() {
        super(...arguments);
        this.audioEnabledSubject = new rxjs.BehaviorSubject(true);
        this.settingsSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * An Observable that emits the current screen share audio status.
         */
        this.audioEnabled$ = this.audioEnabledSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable that emits the current screen share settings.
         */
        this.settings$ = this.settingsSubject.asObservable();
        /**
         * @internal
         */
        this.getDeviceIdFromStream = (stream) => {
            const [track] = stream.getTracks();
            return track?.getSettings().deviceId;
        };
    }
    /**
     * The current screen share audio status.
     */
    get audioEnabled() {
        return this.getCurrentValue(this.audioEnabled$);
    }
    /**
     * Set the current screen share audio status.
     */
    setAudioEnabled(isEnabled) {
        this.setCurrentValue(this.audioEnabledSubject, isEnabled);
    }
    /**
     * The current screen share settings.
     */
    get settings() {
        return this.getCurrentValue(this.settings$);
    }
    /**
     * Set the current screen share settings.
     *
     * @param settings the screen share settings to set.
     */
    setSettings(settings) {
        this.setCurrentValue(this.settingsSubject, settings);
    }
}

class ScreenShareManager extends InputMediaDeviceManager {
    constructor(call) {
        super(call, new ScreenShareState(), TrackType.SCREEN_SHARE);
        this.subscriptions.push(createSubscription(call.state.settings$, (settings) => {
            const maybeTargetResolution = settings?.screensharing.target_resolution;
            if (maybeTargetResolution) {
                this.setDefaultConstraints({
                    video: {
                        width: maybeTargetResolution.width,
                        height: maybeTargetResolution.height,
                    },
                });
            }
        }));
    }
    /**
     * Will enable screen share audio options on supported platforms.
     *
     * Note: for ongoing screen share, audio won't be enabled until you
     * re-publish the screen share stream.
     */
    enableScreenShareAudio() {
        this.state.setAudioEnabled(true);
    }
    /**
     * Will disable screen share audio options on supported platforms.
     */
    async disableScreenShareAudio() {
        this.state.setAudioEnabled(false);
        if (this.call.publisher?.isPublishing(TrackType.SCREEN_SHARE_AUDIO)) {
            await this.call.stopPublish(TrackType.SCREEN_SHARE_AUDIO, true);
        }
    }
    /**
     * Returns the current screen share settings.
     */
    getSettings() {
        return this.state.settings;
    }
    /**
     * Sets the current screen share settings.
     *
     * @param settings the settings to set.
     */
    setSettings(settings) {
        this.state.setSettings(settings);
    }
    getDevices() {
        return rxjs.of([]); // there are no devices to be listed for Screen Share
    }
    getStream(constraints) {
        if (!this.state.audioEnabled) {
            constraints.audio = false;
        }
        return getScreenShareStream(constraints);
    }
    publishStream(stream) {
        return this.call.publishScreenShareStream(stream, {
            screenShareSettings: this.state.settings,
        });
    }
    async stopPublishStream(stopTracks) {
        await this.call.stopPublish(TrackType.SCREEN_SHARE, stopTracks);
        await this.call.stopPublish(TrackType.SCREEN_SHARE_AUDIO, stopTracks);
    }
    /**
     * Overrides the default `select` method to throw an error.
     *
     * @param deviceId ignored.
     */
    async select(deviceId) {
        throw new Error('This method is not supported in for Screen Share');
    }
}

class SpeakerState {
    constructor() {
        this.selectedDeviceSubject = new rxjs.BehaviorSubject('');
        this.volumeSubject = new rxjs.BehaviorSubject(1);
        /**
         * [Tells if the browser supports audio output change on 'audio' elements](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/setSinkId).
         */
        this.isDeviceSelectionSupported = checkIfAudioOutputChangeSupported();
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        this.selectedDevice$ = this.selectedDeviceSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        this.volume$ = this.volumeSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * The currently selected device
     *
     * Note: this feature is not supported in React Native
     */
    get selectedDevice() {
        return this.getCurrentValue(this.selectedDevice$);
    }
    /**
     * The currently selected volume
     *
     * Note: this feature is not supported in React Native
     */
    get volume() {
        return this.getCurrentValue(this.volume$);
    }
    /**
     * @internal
     * @param deviceId
     */
    setDevice(deviceId) {
        this.setCurrentValue(this.selectedDeviceSubject, deviceId);
    }
    /**
     * @internal
     * @param volume
     */
    setVolume(volume) {
        this.setCurrentValue(this.volumeSubject, volume);
    }
}

class SpeakerManager {
    constructor(call) {
        this.state = new SpeakerState();
        this.subscriptions = [];
        /**
         * Disposes the manager.
         *
         * @internal
         */
        this.dispose = () => {
            this.subscriptions.forEach((s) => s.unsubscribe());
        };
        this.call = call;
        if (deviceIds$ && !isReactNative()) {
            this.subscriptions.push(rxjs.combineLatest([deviceIds$, this.state.selectedDevice$]).subscribe(([devices, deviceId]) => {
                if (!deviceId) {
                    return;
                }
                const device = devices.find((d) => d.deviceId === deviceId && d.kind === 'audiooutput');
                if (!device) {
                    this.select('');
                }
            }));
        }
    }
    /**
     * Lists the available audio output devices
     *
     * Note: It prompts the user for a permission to use devices (if not already granted)
     * Note: This method is not supported in React Native
     *
     * @returns an Observable that will be updated if a device is connected or disconnected
     */
    listDevices() {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        return getAudioOutputDevices();
    }
    /**
     * Select a device.
     *
     * Note: This method is not supported in React Native
     *
     * @param deviceId empty string means the system default
     */
    select(deviceId) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        this.state.setDevice(deviceId);
    }
    /**
     * Set the volume of the audio elements
     * @param volume a number between 0 and 1.
     *
     * Note: This method is not supported in React Native
     */
    setVolume(volume) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        if (volume && (volume < 0 || volume > 1)) {
            throw new Error('Volume must be between 0 and 1');
        }
        this.state.setVolume(volume);
    }
    /**
     * Set the volume of a participant.
     *
     * Note: This method is not supported in React Native.
     *
     * @param sessionId the participant's session id.
     * @param volume a number between 0 and 1. Set it to `undefined` to use the default volume.
     */
    setParticipantVolume(sessionId, volume) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        if (volume && (volume < 0 || volume > 1)) {
            throw new Error('Volume must be between 0 and 1, or undefined');
        }
        this.call.state.updateParticipant(sessionId, { audioVolume: volume });
    }
}

/**
 * An object representation of a `Call`.
 */
class Call {
    /**
     * Constructs a new `Call` instance.
     *
     * NOTE: Don't call the constructor directly, instead
     * Use the [`StreamVideoClient.call`](./StreamVideoClient.md/#call)
     * method to construct a `Call` instance.
     */
    constructor({ type, id, streamClient, members, ownCapabilities, sortParticipantsBy, clientStore, ringing = false, watching = false, }) {
        /**
         * The state of this call.
         */
        this.state = new CallState();
        /**
         * The DynascaleManager instance.
         */
        this.dynascaleManager = new DynascaleManager(this);
        /**
         * The permissions context of this call.
         */
        this.permissionsContext = new PermissionsContext();
        /**
         * The event dispatcher instance dedicated to this Call instance.
         * @private
         */
        this.dispatcher = new Dispatcher();
        this.trackSubscriptionsSubject = new rxjs.BehaviorSubject({ type: exports.DebounceType.MEDIUM, data: [] });
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 10;
        this.isLeaving = false;
        /**
         * A list hooks/functions to invoke when the call is left.
         * A typical use case is to clean up some global event handlers.
         * @private
         */
        this.leaveCallHooks = new Set();
        this.streamClientEventHandlers = new Map();
        /**
         * You can subscribe to WebSocket events provided by the API. To remove a subscription, call the `off` method.
         * Please note that subscribing to WebSocket events is an advanced use-case.
         * For most use-cases, it should be enough to watch for state changes.
         *
         * @param eventName the event name.
         * @param fn the event handler.
         */
        this.on = (eventName, fn) => {
            if (isSfuEvent(eventName)) {
                return this.dispatcher.on(eventName, fn);
            }
            const offHandler = this.streamClient.on(eventName, (e) => {
                const event = e;
                if (event.call_cid && event.call_cid === this.cid) {
                    fn(event);
                }
            });
            // keep the 'off' reference returned by the stream client
            this.streamClientEventHandlers.set(fn, offHandler);
            return () => {
                this.off(eventName, fn);
            };
        };
        /**
         * Remove subscription for WebSocket events that were created by the `on` method.
         *
         * @param eventName the event name.
         * @param fn the event handler.
         */
        this.off = (eventName, fn) => {
            if (isSfuEvent(eventName)) {
                return this.dispatcher.off(eventName, fn);
            }
            // unsubscribe from the stream client event by using the 'off' reference
            const registeredOffHandler = this.streamClientEventHandlers.get(fn);
            if (registeredOffHandler) {
                registeredOffHandler();
            }
        };
        /**
         * Leave the call and stop the media streams that were published by the call.
         */
        this.leave = async ({ reject = false, reason = 'user is leaving the call', } = {}) => {
            const callingState = this.state.callingState;
            if (callingState === exports.CallingState.LEFT) {
                throw new Error('Cannot leave call that has already been left.');
            }
            if (callingState === exports.CallingState.JOINING) {
                await this.assertCallJoined();
            }
            this.isLeaving = true;
            if (this.ringing) {
                // I'm the one who started the call, so I should cancel it.
                const hasOtherParticipants = this.state.remoteParticipants.length > 0;
                if (this.isCreatedByMe && !hasOtherParticipants) {
                    // Signals other users that I have cancelled my call to them
                    // before they accepted it.
                    await this.reject();
                }
                else if (reject && callingState === exports.CallingState.RINGING) {
                    // Signals other users that I have rejected the incoming call.
                    await this.reject();
                }
            }
            this.statsReporter?.stop();
            this.statsReporter = undefined;
            this.sfuStatsReporter?.stop();
            this.sfuStatsReporter = undefined;
            this.subscriber?.close();
            this.subscriber = undefined;
            this.publisher?.close();
            this.publisher = undefined;
            this.sfuClient?.close(StreamSfuClient.NORMAL_CLOSURE, reason);
            this.sfuClient = undefined;
            this.dispatcher.offAll();
            this.state.setCallingState(exports.CallingState.LEFT);
            // Call all leave call hooks, e.g. to clean up global event handlers
            this.leaveCallHooks.forEach((hook) => hook());
            this.clientStore.unregisterCall(this);
            this.camera.dispose();
            this.microphone.dispose();
            this.screenShare.dispose();
            this.speaker.dispose();
            const stopOnLeavePromises = [];
            if (this.camera.stopOnLeave) {
                stopOnLeavePromises.push(this.camera.disable(true));
            }
            if (this.microphone.stopOnLeave) {
                stopOnLeavePromises.push(this.microphone.disable(true));
            }
            if (this.screenShare.stopOnLeave) {
                stopOnLeavePromises.push(this.screenShare.disable(true));
            }
            await Promise.all(stopOnLeavePromises);
        };
        /**
         * Loads the information about the call.
         *
         * @param params.ring if set to true, a `call.ring` event will be sent to the call members.
         * @param params.notify if set to true, a `call.notification` event will be sent to the call members.
         * @param params.members_limit the total number of members to return as part of the response.
         */
        this.get = async (params) => {
            const response = await this.streamClient.get(this.streamClientBasePath, params);
            if (params?.ring && !this.ringing) {
                this.ringingSubject.next(true);
            }
            this.state.updateFromCallResponse(response.call);
            this.state.setMembers(response.members);
            this.state.setOwnCapabilities(response.own_capabilities);
            if (this.streamClient._hasConnectionID()) {
                this.watching = true;
                this.clientStore.registerCall(this);
            }
            this.applyDeviceConfig();
            return response;
        };
        /**
         * Loads the information about the call and creates it if it doesn't exist.
         *
         * @param data the data to create the call with.
         */
        this.getOrCreate = async (data) => {
            const response = await this.streamClient.post(this.streamClientBasePath, data);
            if (data?.ring && !this.ringing) {
                this.ringingSubject.next(true);
            }
            this.state.updateFromCallResponse(response.call);
            this.state.setMembers(response.members);
            this.state.setOwnCapabilities(response.own_capabilities);
            if (this.streamClient._hasConnectionID()) {
                this.watching = true;
                this.clientStore.registerCall(this);
            }
            this.applyDeviceConfig();
            return response;
        };
        /**
         * Creates a call
         *
         * @param data the data to create the call with.
         */
        this.create = async (data) => {
            return this.getOrCreate(data);
        };
        /**
         * A shortcut for {@link Call.get} with `ring` parameter set to `true`.
         * Will send a `call.ring` event to the call members.
         */
        this.ring = async () => {
            return await this.get({ ring: true });
        };
        /**
         * A shortcut for {@link Call.get} with `notify` parameter set to `true`.
         * Will send a `call.notification` event to the call members.
         */
        this.notify = async () => {
            return await this.get({ notify: true });
        };
        /**
         * Marks the incoming call as accepted.
         *
         * This method should be used only for "ringing" call flows.
         * {@link Call.join} invokes this method automatically for you when joining a call.
         * Unless you are implementing a custom "ringing" flow, you should not use this method.
         */
        this.accept = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/accept`);
        };
        /**
         * Marks the incoming call as rejected.
         *
         * This method should be used only for "ringing" call flows.
         * {@link Call.leave} invokes this method automatically for you when you leave or reject this call.
         * Unless you are implementing a custom "ringing" flow, you should not use this method.
         */
        this.reject = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/reject`);
        };
        /**
         * Will start to watch for call related WebSocket events and initiate a call session with the server.
         *
         * @returns a promise which resolves once the call join-flow has finished.
         */
        this.join = async (data) => {
            const callingState = this.state.callingState;
            if ([exports.CallingState.JOINED, exports.CallingState.JOINING].includes(callingState)) {
                this.logger('warn', 'Join method called twice, you should only call this once');
                throw new Error(`Illegal State: Already joined.`);
            }
            if (callingState === exports.CallingState.LEFT) {
                throw new Error('Illegal State: Cannot join already left call. Create a new Call instance to join a call.');
            }
            const isMigrating = callingState === exports.CallingState.MIGRATING;
            const isReconnecting = callingState === exports.CallingState.RECONNECTING;
            this.state.setCallingState(exports.CallingState.JOINING);
            this.logger('debug', 'Starting join flow');
            if (data?.ring && !this.ringing) {
                this.ringingSubject.next(true);
            }
            if (this.ringing && !this.isCreatedByMe) {
                // signals other users that I have accepted the incoming call.
                await this.accept();
            }
            let sfuServer;
            let sfuToken;
            let connectionConfig;
            let statsOptions;
            try {
                if (this.sfuClient?.isFastReconnecting) {
                    // use previous SFU configuration and values
                    connectionConfig = this.publisher?.connectionConfiguration;
                    sfuServer = this.sfuClient.sfuServer;
                    sfuToken = this.sfuClient.token;
                    statsOptions = this.sfuStatsReporter?.options;
                }
                else {
                    // full join flow - let the Coordinator pick a new SFU for us
                    const call = await join(this.streamClient, this.type, this.id, data);
                    this.state.updateFromCallResponse(call.metadata);
                    this.state.setMembers(call.members);
                    this.state.setOwnCapabilities(call.ownCapabilities);
                    connectionConfig = call.connectionConfig;
                    sfuServer = call.sfuServer;
                    sfuToken = call.token;
                    statsOptions = call.statsOptions;
                }
                if (this.streamClient._hasConnectionID()) {
                    this.watching = true;
                    this.clientStore.registerCall(this);
                }
            }
            catch (error) {
                // restore the previous call state if the join-flow fails
                this.state.setCallingState(callingState);
                throw error;
            }
            const previousSfuClient = this.sfuClient;
            const sfuClient = (this.sfuClient = new StreamSfuClient({
                dispatcher: this.dispatcher,
                sfuServer,
                token: sfuToken,
                sessionId: previousSfuClient?.sessionId,
            }));
            /**
             * A closure which hides away the re-connection logic.
             */
            const reconnect = async (strategy, reason) => {
                const currentState = this.state.callingState;
                if (currentState === exports.CallingState.MIGRATING ||
                    currentState === exports.CallingState.RECONNECTING) {
                    // prevent parallel reconnection attempts
                    return;
                }
                this.reconnectAttempts++;
                this.state.setCallingState(strategy === 'migrate'
                    ? exports.CallingState.MIGRATING
                    : exports.CallingState.RECONNECTING);
                if (strategy === 'migrate') {
                    this.logger('debug', `[Migration]: migrating call ${this.cid} away from ${sfuServer.edge_name}`);
                    sfuClient.isMigratingAway = true;
                }
                else {
                    this.logger('debug', `[Rejoin]: ${strategy} rejoin call ${this.cid} (${this.reconnectAttempts})...`);
                }
                // take a snapshot of the current "local participant" state
                // we'll need it for restoring the previous publishing state later
                const localParticipant = this.state.localParticipant;
                if (strategy === 'fast') {
                    sfuClient.close(StreamSfuClient.ERROR_CONNECTION_BROKEN, `attempting fast reconnect: ${reason}`);
                }
                else if (strategy === 'full') {
                    // in migration or recovery scenarios, we don't want to
                    // wait before attempting to reconnect to an SFU server
                    await sleep(retryInterval(this.reconnectAttempts));
                    // in full-reconnect, we need to dispose all Peer Connections
                    this.subscriber?.close();
                    this.subscriber = undefined;
                    this.publisher?.close({ stopTracks: false });
                    this.publisher = undefined;
                    this.statsReporter?.stop();
                    this.statsReporter = undefined;
                    this.sfuStatsReporter?.stop();
                    this.sfuStatsReporter = undefined;
                    // clean up current connection
                    sfuClient.close(StreamSfuClient.NORMAL_CLOSURE, `attempting full reconnect: ${reason}`);
                }
                await this.join({
                    ...data,
                    ...(strategy === 'migrate' && { migrating_from: sfuServer.edge_name }),
                });
                // clean up previous connection
                if (strategy === 'migrate') {
                    sfuClient.close(StreamSfuClient.NORMAL_CLOSURE, 'attempting migration');
                }
                this.logger('info', `[Rejoin]: Attempt ${this.reconnectAttempts} successful!`);
                // we shouldn't be republishing the streams if we're migrating
                // as the underlying peer connection will take care of it as part
                // of the ice-restart process
                if (localParticipant && strategy === 'full') {
                    const { audioStream, videoStream, screenShareStream, screenShareAudioStream, } = localParticipant;
                    let screenShare;
                    if (screenShareStream || screenShareAudioStream) {
                        screenShare = new MediaStream();
                        screenShareStream?.getVideoTracks().forEach((track) => {
                            screenShare?.addTrack(track);
                        });
                        screenShareAudioStream?.getAudioTracks().forEach((track) => {
                            screenShare?.addTrack(track);
                        });
                    }
                    // restore previous publishing state
                    if (audioStream)
                        await this.publishAudioStream(audioStream);
                    if (videoStream) {
                        await this.publishVideoStream(videoStream, {
                            preferredCodec: this.camera.preferredCodec,
                        });
                    }
                    if (screenShare)
                        await this.publishScreenShareStream(screenShare);
                    this.logger('info', `[Rejoin]: State restored. Attempt: ${this.reconnectAttempts}`);
                }
            };
            // reconnect if the connection was closed unexpectedly. example:
            // - SFU crash or restart
            // - network change
            sfuClient.signalReady.then(() => {
                // register a handler for the "goAway" event
                const unregisterGoAway = this.dispatcher.on('goAway', (event) => {
                    const { reason } = event;
                    this.logger('info', `[Migration]: Going away from SFU... Reason: ${GoAwayReason[reason]}`);
                    reconnect('migrate', GoAwayReason[reason]).catch((err) => {
                        this.logger('warn', `[Migration]: Failed to migrate to another SFU.`, err);
                    });
                });
                sfuClient.signalWs.addEventListener('close', (e) => {
                    // unregister the "goAway" handler, as we won't need it anymore for this connection.
                    // the upcoming re-join will register a new handler anyway
                    unregisterGoAway();
                    // when the user has initiated "call.leave()" operation, we shouldn't
                    // care for the WS close code and we shouldn't ever attempt to reconnect
                    if (this.isLeaving)
                        return;
                    // do nothing if the connection was closed on purpose
                    if (e.code === StreamSfuClient.NORMAL_CLOSURE)
                        return;
                    // do nothing if the connection was closed because of a policy violation
                    // e.g., the user has been blocked by an admin or moderator
                    if (e.code === KnownCodes.WS_POLICY_VIOLATION)
                        return;
                    // When the SFU is being shut down, it sends a goAway message.
                    // While we migrate to another SFU, we might have the WS connection
                    // to the old SFU closed abruptly. In this case, we don't want
                    // to reconnect to the old SFU, but rather to the new one.
                    const isMigratingAway = e.code === KnownCodes.WS_CLOSED_ABRUPTLY && sfuClient.isMigratingAway;
                    const isFastReconnecting = e.code === KnownCodes.WS_CLOSED_ABRUPTLY &&
                        sfuClient.isFastReconnecting;
                    if (isMigratingAway || isFastReconnecting)
                        return;
                    // do nothing if the connection was closed because of a fast reconnect
                    if (e.code === StreamSfuClient.ERROR_CONNECTION_BROKEN)
                        return;
                    if (this.reconnectAttempts < this.maxReconnectAttempts) {
                        sfuClient.isFastReconnecting = this.reconnectAttempts === 0;
                        const strategy = sfuClient.isFastReconnecting ? 'fast' : 'full';
                        reconnect(strategy, `SFU closed the WS with code: ${e.code}`).catch((err) => {
                            this.logger('error', `[Rejoin]: ${strategy} rejoin failed for ${this.reconnectAttempts} times. Giving up.`, err);
                            this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
                        });
                    }
                    else {
                        this.logger('error', '[Rejoin]: Reconnect attempts exceeded. Giving up...');
                        this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
                    }
                });
            });
            // handlers for connection online/offline events
            const unsubscribeOnlineEvent = this.streamClient.on('connection.changed', async (e) => {
                if (e.type !== 'connection.changed')
                    return;
                if (!e.online)
                    return;
                unsubscribeOnlineEvent();
                const currentCallingState = this.state.callingState;
                const shouldReconnect = currentCallingState === exports.CallingState.OFFLINE ||
                    currentCallingState === exports.CallingState.RECONNECTING_FAILED;
                if (!shouldReconnect)
                    return;
                this.logger('info', '[Rejoin]: Going online...');
                let isFirstReconnectAttempt = true;
                do {
                    try {
                        sfuClient.isFastReconnecting = isFirstReconnectAttempt;
                        await reconnect(isFirstReconnectAttempt ? 'fast' : 'full', 'Network: online');
                        return; // break the loop if rejoin is successful
                    }
                    catch (err) {
                        this.logger('error', `[Rejoin][Network]: Rejoin failed for attempt ${this.reconnectAttempts}`, err);
                    }
                    // wait for a bit before trying to reconnect again
                    await sleep(retryInterval(this.reconnectAttempts));
                    isFirstReconnectAttempt = false;
                } while (this.reconnectAttempts < this.maxReconnectAttempts);
                // if we're here, it means that we've exhausted all the reconnect attempts
                this.logger('error', `[Rejoin][Network]: Rejoin failed. Giving up.`);
                this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
            });
            const unsubscribeOfflineEvent = this.streamClient.on('connection.changed', (e) => {
                if (e.type !== 'connection.changed')
                    return;
                if (e.online)
                    return;
                unsubscribeOfflineEvent();
                this.state.setCallingState(exports.CallingState.OFFLINE);
            });
            this.leaveCallHooks.add(() => {
                unsubscribeOnlineEvent();
                unsubscribeOfflineEvent();
            });
            if (!this.subscriber) {
                this.subscriber = new Subscriber({
                    sfuClient,
                    dispatcher: this.dispatcher,
                    state: this.state,
                    connectionConfig,
                });
            }
            // anonymous users can't publish anything hence, there is no need
            // to create Publisher Peer Connection for them
            const isAnonymous = this.streamClient.user?.type === 'anonymous';
            if (!this.publisher && !isAnonymous) {
                const audioSettings = this.state.settings?.audio;
                const isDtxEnabled = !!audioSettings?.opus_dtx_enabled;
                const isRedEnabled = !!audioSettings?.redundant_coding_enabled;
                this.publisher = new Publisher({
                    sfuClient,
                    dispatcher: this.dispatcher,
                    state: this.state,
                    connectionConfig,
                    isDtxEnabled,
                    isRedEnabled,
                });
            }
            if (!this.statsReporter) {
                this.statsReporter = createStatsReporter({
                    subscriber: this.subscriber,
                    publisher: this.publisher,
                    state: this.state,
                    datacenter: this.sfuClient.edgeName,
                });
            }
            const clientDetails = getClientDetails();
            if (!this.sfuStatsReporter && statsOptions) {
                this.sfuStatsReporter = new SfuStatsReporter(sfuClient, {
                    clientDetails,
                    options: statsOptions,
                    subscriber: this.subscriber,
                    publisher: this.publisher,
                });
                this.sfuStatsReporter.start();
            }
            try {
                // 1. wait for the signal server to be ready before sending "joinRequest"
                sfuClient.signalReady
                    .catch((err) => this.logger('error', 'Signal ready failed', err))
                    // prepare a generic SDP and send it to the SFU.
                    // this is a throw-away SDP that the SFU will use to determine
                    // the capabilities of the client (codec support, etc.)
                    .then(() => getGenericSdp('recvonly'))
                    .then((sdp) => {
                    const subscriptions = getCurrentValue(this.trackSubscriptionsSubject);
                    const migration = isMigrating
                        ? {
                            fromSfuId: data?.migrating_from || '',
                            subscriptions: subscriptions.data || [],
                            announcedTracks: this.publisher?.getCurrentTrackInfos() || [],
                        }
                        : undefined;
                    return sfuClient.join({
                        subscriberSdp: sdp || '',
                        clientDetails,
                        migration,
                        fastReconnect: previousSfuClient?.isFastReconnecting ?? false,
                    });
                });
                // 2. in parallel, wait for the SFU to send us the "joinResponse"
                // this will throw an error if the SFU rejects the join request or
                // fails to respond in time
                const { callState, reconnected } = await this.waitForJoinResponse();
                if (isReconnecting) {
                    this.logger('debug', '[Rejoin] fast reconnected:', reconnected);
                }
                if (isMigrating) {
                    await this.subscriber.migrateTo(sfuClient, connectionConfig);
                    await this.publisher?.migrateTo(sfuClient, connectionConfig);
                }
                else if (isReconnecting) {
                    if (reconnected) {
                        // update the SFU client instance on the subscriber and publisher
                        this.subscriber.setSfuClient(sfuClient);
                        // publisher might not be there (anonymous users)
                        if (this.publisher) {
                            this.publisher.setSfuClient(sfuClient);
                            // and perform a full ICE restart on the publisher
                            await this.publisher.restartIce();
                        }
                    }
                    else if (previousSfuClient?.isFastReconnecting) {
                        // reconnection wasn't possible, so we need to do a full rejoin
                        return await reconnect('full', 're-attempting').catch((err) => {
                            this.logger('error', `[Rejoin]: Rejoin failed forced full rejoin.`, err);
                        });
                    }
                }
                const currentParticipants = callState?.participants || [];
                const participantCount = callState?.participantCount;
                const startedAt = callState?.startedAt
                    ? Timestamp.toDate(callState.startedAt)
                    : new Date();
                const pins = callState?.pins ?? [];
                this.state.setParticipants(() => {
                    const participantLookup = this.state.getParticipantLookupBySessionId();
                    return currentParticipants.map((p) => {
                        // We need to preserve the local state of the participant
                        // (e.g. videoDimension, visibilityState, pinnedAt, etc.)
                        // as it doesn't exist on the server.
                        const existingParticipant = participantLookup[p.sessionId];
                        return Object.assign(p, existingParticipant, {
                            isLocalParticipant: p.sessionId === sfuClient.sessionId,
                            viewportVisibilityState: existingParticipant?.viewportVisibilityState ?? {
                                videoTrack: exports.VisibilityState.UNKNOWN,
                                screenShareTrack: exports.VisibilityState.UNKNOWN,
                            },
                        });
                    });
                });
                this.state.setParticipantCount(participantCount?.total || 0);
                this.state.setAnonymousParticipantCount(participantCount?.anonymous || 0);
                this.state.setStartedAt(startedAt);
                this.state.setServerSidePins(pins);
                this.reconnectAttempts = 0; // reset the reconnect attempts counter
                this.state.setCallingState(exports.CallingState.JOINED);
                try {
                    await this.initCamera({ setStatus: true });
                    await this.initMic({ setStatus: true });
                }
                catch (error) {
                    this.logger('warn', 'Camera and/or mic init failed during join call', error);
                }
                // 3. once we have the "joinResponse", and possibly reconciled the local state
                // we schedule a fast subscription update for all remote participants
                // that were visible before we reconnected or migrated to a new SFU.
                const { remoteParticipants } = this.state;
                if (remoteParticipants.length > 0) {
                    this.updateSubscriptions(remoteParticipants, exports.DebounceType.FAST);
                }
                this.logger('info', `Joined call ${this.cid}`);
            }
            catch (err) {
                // join failed, try to rejoin
                if (this.reconnectAttempts < this.maxReconnectAttempts) {
                    this.logger('error', `[Rejoin]: Rejoin ${this.reconnectAttempts} failed.`, err);
                    await reconnect('full', 'previous attempt failed');
                    this.logger('info', `[Rejoin]: Rejoin ${this.reconnectAttempts} successful!`);
                }
                else {
                    this.logger('error', `[Rejoin]: Rejoin failed for ${this.reconnectAttempts} times. Giving up.`);
                    this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
                    throw new Error('Join failed');
                }
            }
        };
        this.waitForJoinResponse = (timeout = 5000) => {
            return new Promise((resolve, reject) => {
                const unsubscribe = this.on('joinResponse', (event) => {
                    clearTimeout(timeoutId);
                    unsubscribe();
                    resolve(event);
                });
                const timeoutId = setTimeout(() => {
                    unsubscribe();
                    reject(new Error('Waiting for "joinResponse" has timed out'));
                }, timeout);
            });
        };
        /**
         * Starts publishing the given video stream to the call.
         * The stream will be stopped if the user changes an input device, or if the user leaves the call.
         *
         * Consecutive calls to this method will replace the previously published stream.
         * The previous video stream will be stopped.
         *
         * @param videoStream the video stream to publish.
         * @param opts the options to use when publishing the stream.
         */
        this.publishVideoStream = async (videoStream, opts = {}) => {
            // we should wait until we get a JoinResponse from the SFU,
            // otherwise we risk breaking the ICETrickle flow.
            await this.assertCallJoined();
            if (!this.publisher) {
                this.logger('error', 'Trying to publish video before join is completed');
                throw new Error(`Call not joined yet.`);
            }
            const [videoTrack] = videoStream.getVideoTracks();
            if (!videoTrack) {
                this.logger('error', `There is no video track to publish in the stream.`);
                return;
            }
            await this.publisher.publishStream(videoStream, videoTrack, TrackType.VIDEO, opts);
        };
        /**
         * Starts publishing the given audio stream to the call.
         * The stream will be stopped if the user changes an input device, or if the user leaves the call.
         *
         * Consecutive calls to this method will replace the audio stream that is currently being published.
         * The previous audio stream will be stopped.
         *
         * @param audioStream the audio stream to publish.
         */
        this.publishAudioStream = async (audioStream) => {
            // we should wait until we get a JoinResponse from the SFU,
            // otherwise we risk breaking the ICETrickle flow.
            await this.assertCallJoined();
            if (!this.publisher) {
                this.logger('error', 'Trying to publish audio before join is completed');
                throw new Error(`Call not joined yet.`);
            }
            const [audioTrack] = audioStream.getAudioTracks();
            if (!audioTrack) {
                this.logger('error', `There is no audio track in the stream to publish`);
                return;
            }
            await this.publisher.publishStream(audioStream, audioTrack, TrackType.AUDIO);
        };
        /**
         * Starts publishing the given screen-share stream to the call.
         *
         * Consecutive calls to this method will replace the previous screen-share stream.
         * The previous screen-share stream will be stopped.
         *
         * @param screenShareStream the screen-share stream to publish.
         * @param opts the options to use when publishing the stream.
         */
        this.publishScreenShareStream = async (screenShareStream, opts = {}) => {
            // we should wait until we get a JoinResponse from the SFU,
            // otherwise we risk breaking the ICETrickle flow.
            await this.assertCallJoined();
            if (!this.publisher) {
                this.logger('error', 'Trying to publish screen share before join is completed');
                throw new Error(`Call not joined yet.`);
            }
            const [screenShareTrack] = screenShareStream.getVideoTracks();
            if (!screenShareTrack) {
                this.logger('error', `There is no video track in the screen share stream to publish`);
                return;
            }
            await this.publisher.publishStream(screenShareStream, screenShareTrack, TrackType.SCREEN_SHARE, opts);
            const [screenShareAudioTrack] = screenShareStream.getAudioTracks();
            if (screenShareAudioTrack) {
                await this.publisher.publishStream(screenShareStream, screenShareAudioTrack, TrackType.SCREEN_SHARE_AUDIO, opts);
            }
        };
        /**
         * Stops publishing the given track type to the call, if it is currently being published.
         * Underlying track will be stopped and removed from the publisher.
         *
         * @param trackType the track type to stop publishing.
         * @param stopTrack if `true` the track will be stopped, else it will be just disabled
         */
        this.stopPublish = async (trackType, stopTrack = true) => {
            this.logger('info', `stopPublish ${TrackType[trackType]}, stop tracks: ${stopTrack}`);
            await this.publisher?.unpublishStream(trackType, stopTrack);
        };
        /**
         * Notifies the SFU that a noise cancellation process has started.
         *
         * @internal
         */
        this.notifyNoiseCancellationStarting = async () => {
            return this.sfuClient?.startNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to notify start of noise cancellation', err);
            });
        };
        /**
         * Notifies the SFU that a noise cancellation process has stopped.
         *
         * @internal
         */
        this.notifyNoiseCancellationStopped = async () => {
            return this.sfuClient?.stopNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to notify stop of noise cancellation', err);
            });
        };
        /**
         * Update track subscription configuration for one or more participants.
         * You have to create a subscription for each participant for all the different kinds of tracks you want to receive.
         * You can only subscribe for tracks after the participant started publishing the given kind of track.
         *
         * @param trackType the kind of subscription to update.
         * @param changes the list of subscription changes to do.
         * @param type the debounce type to use for the update.
         */
        this.updateSubscriptionsPartial = (trackType, changes, type = exports.DebounceType.SLOW) => {
            if (trackType === 'video') {
                this.logger('warn', `updateSubscriptionsPartial: ${trackType} is deprecated. Please switch to 'videoTrack'`);
                trackType = 'videoTrack';
            }
            else if (trackType === 'screen') {
                this.logger('warn', `updateSubscriptionsPartial: ${trackType} is deprecated. Please switch to 'screenShareTrack'`);
                trackType = 'screenShareTrack';
            }
            const participants = this.state.updateParticipants(Object.entries(changes).reduce((acc, [sessionId, change]) => {
                if (change.dimension?.height) {
                    change.dimension.height = Math.ceil(change.dimension.height);
                }
                if (change.dimension?.width) {
                    change.dimension.width = Math.ceil(change.dimension.width);
                }
                const prop = trackType === 'videoTrack'
                    ? 'videoDimension'
                    : trackType === 'screenShareTrack'
                        ? 'screenShareDimension'
                        : undefined;
                if (prop) {
                    acc[sessionId] = {
                        [prop]: change.dimension,
                    };
                }
                return acc;
            }, {}));
            if (participants) {
                this.updateSubscriptions(participants, type);
            }
        };
        this.updateSubscriptions = (participants, type = exports.DebounceType.SLOW) => {
            const subscriptions = [];
            for (const p of participants) {
                // we don't want to subscribe to our own tracks
                if (p.isLocalParticipant)
                    continue;
                // NOTE: audio tracks don't have to be requested explicitly
                // as the SFU will implicitly subscribe us to all of them,
                // once they become available.
                if (p.videoDimension && hasVideo(p)) {
                    subscriptions.push({
                        userId: p.userId,
                        sessionId: p.sessionId,
                        trackType: TrackType.VIDEO,
                        dimension: p.videoDimension,
                    });
                }
                if (p.screenShareDimension && hasScreenShare(p)) {
                    subscriptions.push({
                        userId: p.userId,
                        sessionId: p.sessionId,
                        trackType: TrackType.SCREEN_SHARE,
                        dimension: p.screenShareDimension,
                    });
                }
                if (hasScreenShareAudio(p)) {
                    subscriptions.push({
                        userId: p.userId,
                        sessionId: p.sessionId,
                        trackType: TrackType.SCREEN_SHARE_AUDIO,
                    });
                }
            }
            // schedule update
            this.trackSubscriptionsSubject.next({ type, data: subscriptions });
        };
        /**
         * Will enhance the reported stats with additional participant-specific information (`callStatsReport$` state [store variable](./StreamVideoClient.md/#readonlystatestore)).
         * This is usually helpful when detailed stats for a specific participant are needed.
         *
         * @param sessionId the sessionId to start reporting for.
         */
        this.startReportingStatsFor = (sessionId) => {
            return this.statsReporter?.startReportingStatsFor(sessionId);
        };
        /**
         * Opposite of `startReportingStatsFor`.
         * Will turn off stats reporting for a specific participant.
         *
         * @param sessionId the sessionId to stop reporting for.
         */
        this.stopReportingStatsFor = (sessionId) => {
            return this.statsReporter?.stopReportingStatsFor(sessionId);
        };
        /**
         * Resets the last sent reaction for the user holding the given `sessionId`. This is a local action, it won't reset the reaction on the backend.
         *
         * @param sessionId the session id.
         */
        this.resetReaction = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                reaction: undefined,
            });
        };
        /**
         * Sets the list of criteria to sort the participants by.
         *
         * @param criteria the list of criteria to sort the participants by.
         */
        this.setSortParticipantsBy = (criteria) => {
            return this.state.setSortParticipantsBy(criteria);
        };
        /**
         * Updates the list of video layers to publish.
         *
         * @internal
         * @param enabledLayers the list of layers to enable.
         */
        this.updatePublishQuality = async (enabledLayers) => {
            return this.publisher?.updateVideoPublishQuality(enabledLayers);
        };
        this.assertCallJoined = () => {
            return new Promise((resolve) => {
                this.state.callingState$
                    .pipe(rxjs.takeWhile((state) => state !== exports.CallingState.JOINED, true), rxjs.filter((s) => s === exports.CallingState.JOINED))
                    .subscribe(() => resolve());
            });
        };
        /**
         * Sends a reaction to the other call participants.
         *
         * @param reaction the reaction to send.
         */
        this.sendReaction = async (reaction) => {
            return this.streamClient.post(`${this.streamClientBasePath}/reaction`, reaction);
        };
        /**
         * Blocks the user with the given `userId`.
         *
         * @param userId the id of the user to block.
         */
        this.blockUser = async (userId) => {
            return this.streamClient.post(`${this.streamClientBasePath}/block`, {
                user_id: userId,
            });
        };
        /**
         * Unblocks the user with the given `userId`.
         *
         * @param userId the id of the user to unblock.
         */
        this.unblockUser = async (userId) => {
            return this.streamClient.post(`${this.streamClientBasePath}/unblock`, {
                user_id: userId,
            });
        };
        /**
         * Mutes the current user.
         *
         * @param type the type of the mute operation.
         */
        this.muteSelf = (type) => {
            const myUserId = this.currentUserId;
            if (myUserId) {
                return this.muteUser(myUserId, type);
            }
        };
        /**
         * Mutes all the other participants.
         *
         * @param type the type of the mute operation.
         */
        this.muteOthers = (type) => {
            const trackType = muteTypeToTrackType(type);
            if (!trackType)
                return;
            const userIdsToMute = [];
            for (const participant of this.state.remoteParticipants) {
                if (participant.publishedTracks.includes(trackType)) {
                    userIdsToMute.push(participant.userId);
                }
            }
            return this.muteUser(userIdsToMute, type);
        };
        /**
         * Mutes the user with the given `userId`.
         *
         * @param userId the id of the user to mute.
         * @param type the type of the mute operation.
         */
        this.muteUser = (userId, type) => {
            return this.streamClient.post(`${this.streamClientBasePath}/mute_users`, {
                user_ids: Array.isArray(userId) ? userId : [userId],
                [type]: true,
            });
        };
        /**
         * Will mute all users in the call.
         *
         * @param type the type of the mute operation.
         */
        this.muteAllUsers = (type) => {
            return this.streamClient.post(`${this.streamClientBasePath}/mute_users`, {
                mute_all_users: true,
                [type]: true,
            });
        };
        /**
         * Starts recording the call
         */
        this.startRecording = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_recording`, request ? request : {});
        };
        /**
         * Stops recording the call
         */
        this.stopRecording = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_recording`, {});
        };
        /**
         * Starts the transcription of the call.
         *
         * @param request the request data.
         */
        this.startTranscription = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_transcription`, request);
        };
        /**
         * Stops the transcription of the call.
         */
        this.stopTranscription = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_transcription`);
        };
        /**
         * Sends a `call.permission_request` event to all users connected to the call. The call settings object contains infomration about which permissions can be requested during a call (for example a user might be allowed to request permission to publish audio, but not video).
         */
        this.requestPermissions = async (data) => {
            const { permissions } = data;
            const canRequestPermissions = permissions.every((permission) => this.permissionsContext.canRequest(permission));
            if (!canRequestPermissions) {
                throw new Error(`You are not allowed to request permissions: ${permissions.join(', ')}`);
            }
            return this.streamClient.post(`${this.streamClientBasePath}/request_permission`, data);
        };
        /**
         * Allows you to grant certain permissions to a user in a call.
         * The permissions are specific to the call experience and do not survive the call itself.
         *
         * Supported permissions that can be granted are:
         * - `send-audio`
         * - `send-video`
         * - `screenshare`
         *
         * @param userId the id of the user to grant permissions to.
         * @param permissions the permissions to grant.
         */
        this.grantPermissions = async (userId, permissions) => {
            return this.updateUserPermissions({
                user_id: userId,
                grant_permissions: permissions,
            });
        };
        /**
         * Allows you to revoke certain permissions from a user in a call.
         * The permissions are specific to the call experience and do not survive the call itself.
         *
         * Supported permissions that can be revoked are:
         * - `send-audio`
         * - `send-video`
         * - `screenshare`
         *
         * @param userId the id of the user to revoke permissions from.
         * @param permissions the permissions to revoke.
         */
        this.revokePermissions = async (userId, permissions) => {
            return this.updateUserPermissions({
                user_id: userId,
                revoke_permissions: permissions,
            });
        };
        /**
         * Allows you to grant or revoke a specific permission to a user in a call. The permissions are specific to the call experience and do not survive the call itself.
         *
         * When revoking a permission, this endpoint will also mute the relevant track from the user. This is similar to muting a user with the difference that the user will not be able to unmute afterwards.
         *
         * Supported permissions that can be granted or revoked: `send-audio`, `send-video` and `screenshare`.
         *
         * `call.permissions_updated` event is sent to all members of the call.
         *
         */
        this.updateUserPermissions = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/user_permissions`, data);
        };
        /**
         * Starts the livestreaming of the call.
         *
         * @param data the request data.
         * @param params the request params.
         */
        this.goLive = async (data = {}, params) => {
            return this.streamClient.post(`${this.streamClientBasePath}/go_live`, data, params);
        };
        /**
         * Stops the livestreaming of the call.
         */
        this.stopLive = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_live`, {});
        };
        /**
         * Starts the broadcasting of the call.
         */
        this.startHLS = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_broadcasting`, {});
        };
        /**
         * Stops the broadcasting of the call.
         */
        this.stopHLS = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_broadcasting`, {});
        };
        /**
         * Updates the call settings or custom data.
         *
         * @param updates the updates to apply to the call.
         */
        this.update = async (updates) => {
            const response = await this.streamClient.patch(`${this.streamClientBasePath}`, updates);
            const { call, members, own_capabilities } = response;
            this.state.updateFromCallResponse(call);
            this.state.setMembers(members);
            this.state.setOwnCapabilities(own_capabilities);
            return response;
        };
        /**
         * Ends the call. Once the call is ended, it cannot be re-joined.
         */
        this.endCall = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/mark_ended`);
        };
        /**
         * Pins the given session to the top of the participants list.
         *
         * @param sessionId the sessionId to pin.
         */
        this.pin = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                pin: {
                    isLocalPin: true,
                    pinnedAt: Date.now(),
                },
            });
        };
        /**
         * Unpins the given session from the top of the participants list.
         *
         * @param sessionId the sessionId to unpin.
         */
        this.unpin = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                pin: undefined,
            });
        };
        /**
         * Pins the given session to the top of the participants list for everyone
         * in the call.
         * You can execute this method only if you have the `pin-for-everyone` capability.
         *
         * @param request the request object.
         */
        this.pinForEveryone = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/pin`, request);
        };
        /**
         * Unpins the given session from the top of the participants list for everyone
         * in the call.
         * You can execute this method only if you have the `pin-for-everyone` capability.
         *
         * @param request the request object.
         */
        this.unpinForEveryone = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/unpin`, request);
        };
        /**
         * Query call members with filter query. The result won't be stored in call state.
         * @param request
         * @returns
         */
        this.queryMembers = (request) => {
            return this.streamClient.post('/call/members', {
                ...(request || {}),
                id: this.id,
                type: this.type,
            });
        };
        /**
         * Will update the call members.
         *
         * @param data the request data.
         */
        this.updateCallMembers = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/members`, data);
        };
        /**
         * Schedules an auto-drop timeout based on the call settings.
         * Applicable only for ringing calls.
         */
        this.scheduleAutoDrop = () => {
            clearTimeout(this.dropTimeout);
            this.leaveCallHooks.add(createSubscription(this.state.settings$, (settings) => {
                if (!settings)
                    return;
                // ignore if the call is not ringing
                if (this.state.callingState !== exports.CallingState.RINGING)
                    return;
                const timeoutInMs = settings.ring.auto_cancel_timeout_ms;
                // 0 means no auto-drop
                if (timeoutInMs <= 0)
                    return;
                clearTimeout(this.dropTimeout);
                this.dropTimeout = setTimeout(() => {
                    this.leave({ reason: 'ring: timeout' }).catch((err) => {
                        this.logger('error', 'Failed to drop call', err);
                    });
                }, timeoutInMs);
            }));
        };
        /**
         * Retrieves the list of recordings for the current call or call session.
         *
         * If `callSessionId` is provided, it will return the recordings for that call session.
         * Otherwise, all recordings for the current call will be returned.
         *
         * @param callSessionId the call session id to retrieve recordings for.
         */
        this.queryRecordings = async (callSessionId) => {
            let endpoint = this.streamClientBasePath;
            if (callSessionId) {
                endpoint = `${endpoint}/${callSessionId}`;
            }
            return this.streamClient.get(`${endpoint}/recordings`);
        };
        /**
         * Retrieves the list of transcriptions for the current call.
         *
         * @returns the list of transcriptions.
         */
        this.queryTranscriptions = async () => {
            return this.streamClient.get(`${this.streamClientBasePath}/transcriptions`);
        };
        /**
         * Retrieve call statistics for a particular call session (historical).
         * Here `callSessionID` is mandatory.
         *
         * @param callSessionID the call session ID to retrieve statistics for.
         * @returns The call stats.
         */
        this.getCallStats = async (callSessionID) => {
            const endpoint = `${this.streamClientBasePath}/stats/${callSessionID}`;
            return this.streamClient.get(endpoint);
        };
        /**
         * Submit user feedback for the call
         *
         * @param rating Rating between 1 and 5 denoting the experience of the user in the call
         * @param reason The reason/description for the rating
         * @param custom Custom data
         * @returns
         */
        this.submitFeedback = async (rating, { reason, custom, } = {}) => {
            if (rating < 1 || rating > 5) {
                throw new Error('Rating must be between 1 and 5');
            }
            const callSessionId = this.state.session?.id;
            if (!callSessionId) {
                throw new Error('Feedback can be submitted only in the context of a call session');
            }
            const { sdkName, sdkVersion, ...platform } = getSdkSignature(getClientDetails());
            // user sessionId is not available once the call has been left
            // until we relax the backend validation, we'll send N/A
            const userSessionId = this.sfuClient?.sessionId ?? 'N/A';
            const endpoint = `${this.streamClientBasePath}/feedback/${callSessionId}`;
            return this.streamClient.post(endpoint, {
                rating,
                reason,
                user_session_id: userSessionId,
                sdk: sdkName,
                sdk_version: sdkVersion,
                custom: {
                    ...custom,
                    'x-stream-platform-data': platform,
                },
            });
        };
        /**
         * Sends a custom event to all call participants.
         *
         * @param payload the payload to send.
         */
        this.sendCustomEvent = async (payload) => {
            return this.streamClient.post(`${this.streamClientBasePath}/event`, { custom: payload });
        };
        this.applyDeviceConfig = () => {
            this.initCamera({ setStatus: false });
            this.initMic({ setStatus: false });
        };
        /**
         * Will begin tracking the given element for visibility changes within the
         * configured viewport element (`call.setViewport`).
         *
         * @param element the element to track.
         * @param sessionId the session id.
         * @param trackType the video mode.
         */
        this.trackElementVisibility = (element, sessionId, trackType) => {
            return this.dynascaleManager.trackElementVisibility(element, sessionId, trackType);
        };
        /**
         * Sets the viewport element to track bound video elements for visibility.
         *
         * @param element the viewport element.
         */
        this.setViewport = (element) => {
            return this.dynascaleManager.setViewport(element);
        };
        /**
         * Binds a DOM <video> element to the given session id.
         * This method will make sure that the video element will play
         * the correct video stream for the given session id.
         *
         * Under the hood, it would also keep track of the video element dimensions
         * and update the subscription accordingly in order to optimize the bandwidth.
         *
         * If a "viewport" is configured, the video element will be automatically
         * tracked for visibility and the subscription will be updated accordingly.
         *
         * @param videoElement the video element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         */
        this.bindVideoElement = (videoElement, sessionId, trackType) => {
            const unbind = this.dynascaleManager.bindVideoElement(videoElement, sessionId, trackType);
            if (!unbind)
                return;
            this.leaveCallHooks.add(unbind);
            return () => {
                this.leaveCallHooks.delete(unbind);
                unbind();
            };
        };
        /**
         * Binds a DOM <audio> element to the given session id.
         *
         * This method will make sure that the audio element will
         * play the correct audio stream for the given session id.
         *
         * @param audioElement the audio element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of audio.
         */
        this.bindAudioElement = (audioElement, sessionId, trackType = 'audioTrack') => {
            const unbind = this.dynascaleManager.bindAudioElement(audioElement, sessionId, trackType);
            if (!unbind)
                return;
            this.leaveCallHooks.add(unbind);
            return () => {
                this.leaveCallHooks.delete(unbind);
                unbind();
            };
        };
        /**
         * Binds a DOM <img> element to this call's thumbnail (if enabled in settings).
         *
         * @param imageElement the image element to bind to.
         * @param opts options for the binding.
         */
        this.bindCallThumbnailElement = (imageElement, opts = {}) => {
            const handleError = () => {
                imageElement.src =
                    opts.fallbackImageSource ||
                        'https://getstream.io/random_svg/?name=x&id=x';
            };
            const unsubscribe = createSubscription(this.state.thumbnails$, (thumbnails) => {
                if (!thumbnails)
                    return;
                imageElement.addEventListener('error', handleError);
                const thumbnailUrl = new URL(thumbnails.image_url);
                thumbnailUrl.searchParams.set('w', String(imageElement.clientWidth));
                thumbnailUrl.searchParams.set('h', String(imageElement.clientHeight));
                imageElement.src = thumbnailUrl.toString();
            });
            return () => {
                unsubscribe();
                imageElement.removeEventListener('error', handleError);
            };
        };
        this.type = type;
        this.id = id;
        this.cid = `${type}:${id}`;
        this.ringingSubject = new rxjs.BehaviorSubject(ringing);
        this.watching = watching;
        this.streamClient = streamClient;
        this.clientStore = clientStore;
        this.streamClientBasePath = `/call/${this.type}/${this.id}`;
        this.logger = getLogger(['Call']);
        const callTypeConfig = CallTypes.get(type);
        const participantSorter = sortParticipantsBy || callTypeConfig.options.sortParticipantsBy;
        if (participantSorter) {
            this.state.setSortParticipantsBy(participantSorter);
        }
        this.state.setMembers(members || []);
        this.state.setOwnCapabilities(ownCapabilities || []);
        this.state.setCallingState(ringing ? exports.CallingState.RINGING : exports.CallingState.IDLE);
        this.on('all', (event) => {
            // update state with the latest event data
            this.state.updateFromEvent(event);
        });
        this.leaveCallHooks.add(registerEventHandlers(this, this.state, this.dispatcher));
        this.registerEffects();
        this.leaveCallHooks.add(createSubscription(this.trackSubscriptionsSubject.pipe(rxjs.debounce((v) => rxjs.timer(v.type)), rxjs.map((v) => v.data)), (subscriptions) => this.sfuClient?.updateSubscriptions(subscriptions).catch((err) => {
            this.logger('debug', `Failed to update track subscriptions`, err);
        })));
        this.camera = new CameraManager(this);
        this.microphone = new MicrophoneManager(this);
        this.speaker = new SpeakerManager(this);
        this.screenShare = new ScreenShareManager(this);
    }
    registerEffects() {
        this.leaveCallHooks.add(
        // handles updating the permissions context when the settings change.
        createSubscription(this.state.settings$, (settings) => {
            if (!settings)
                return;
            this.permissionsContext.setCallSettings(settings);
        }));
        this.leaveCallHooks.add(
        // handle the case when the user permissions are modified.
        createSubscription(this.state.ownCapabilities$, (ownCapabilities) => {
            // update the permission context.
            this.permissionsContext.setPermissions(ownCapabilities);
            if (!this.publisher)
                return;
            // check if the user still has publishing permissions and stop publishing if not.
            const permissionToTrackType = {
                [OwnCapability.SEND_AUDIO]: TrackType.AUDIO,
                [OwnCapability.SEND_VIDEO]: TrackType.VIDEO,
                [OwnCapability.SCREENSHARE]: TrackType.SCREEN_SHARE,
            };
            for (const [permission, trackType] of Object.entries(permissionToTrackType)) {
                const hasPermission = this.permissionsContext.hasPermission(permission);
                if (!hasPermission &&
                    (this.publisher.isPublishing(trackType) ||
                        this.publisher.isLive(trackType))) {
                    // Stop tracks, then notify device manager
                    this.stopPublish(trackType)
                        .catch((err) => {
                        this.logger('error', `Error stopping publish ${trackType}`, err);
                    })
                        .then(() => {
                        if (trackType === TrackType.VIDEO &&
                            this.camera.state.status === 'enabled') {
                            this.camera
                                .disable()
                                .catch((err) => this.logger('error', `Error disabling camera after permission revoked`, err));
                        }
                        if (trackType === TrackType.AUDIO &&
                            this.microphone.state.status === 'enabled') {
                            this.microphone
                                .disable()
                                .catch((err) => this.logger('error', `Error disabling microphone after permission revoked`, err));
                        }
                    });
                }
            }
        }));
        this.leaveCallHooks.add(
        // handles the case when the user is blocked by the call owner.
        createSubscription(this.state.blockedUserIds$, async (blockedUserIds) => {
            if (!blockedUserIds || blockedUserIds.length === 0)
                return;
            const currentUserId = this.currentUserId;
            if (currentUserId && blockedUserIds.includes(currentUserId)) {
                this.logger('info', 'Leaving call because of being blocked');
                await this.leave({ reason: 'user blocked' });
            }
        }));
        this.leaveCallHooks.add(
        // watch for auto drop cancellation
        createSubscription(this.state.callingState$, (callingState) => {
            if (!this.ringing)
                return;
            if (callingState === exports.CallingState.JOINED ||
                callingState === exports.CallingState.JOINING ||
                callingState === exports.CallingState.LEFT) {
                clearTimeout(this.dropTimeout);
                this.dropTimeout = undefined;
            }
        }));
        this.leaveCallHooks.add(
        // "ringing" mode effects and event handlers
        createSubscription(this.ringingSubject, (isRinging) => {
            if (!isRinging)
                return;
            this.scheduleAutoDrop();
            if (this.state.callingState === exports.CallingState.IDLE) {
                this.state.setCallingState(exports.CallingState.RINGING);
            }
            this.leaveCallHooks.add(registerRingingCallEventHandlers(this));
        }));
    }
    /**
     * A flag indicating whether the call is "ringing" type of call.
     */
    get ringing() {
        return getCurrentValue(this.ringingSubject);
    }
    /**
     * Retrieves the current user ID.
     */
    get currentUserId() {
        return this.clientStore.connectedUser?.id;
    }
    /**
     * A flag indicating whether the call was created by the current user.
     */
    get isCreatedByMe() {
        return this.state.createdBy?.id === this.currentUserId;
    }
    async initCamera(options) {
        // Wait for any in progress camera operation
        await this.camera.statusChangePromise;
        if (this.state.localParticipant?.videoStream ||
            !this.permissionsContext.hasPermission('send-video')) {
            return;
        }
        // Set camera direction if it's not yet set
        if (!this.camera.state.direction && !this.camera.state.selectedDevice) {
            let defaultDirection = 'front';
            const backendSetting = this.state.settings?.video.camera_facing;
            if (backendSetting) {
                defaultDirection = backendSetting === 'front' ? 'front' : 'back';
            }
            this.camera.state.setDirection(defaultDirection);
        }
        // Set target resolution
        const targetResolution = this.state.settings?.video.target_resolution;
        if (targetResolution) {
            await this.camera.selectTargetResolution(targetResolution);
        }
        if (options.setStatus) {
            // Publish already that was set before we joined
            if (this.camera.state.status === 'enabled' &&
                this.camera.state.mediaStream &&
                !this.publisher?.isPublishing(TrackType.VIDEO)) {
                await this.publishVideoStream(this.camera.state.mediaStream, {
                    preferredCodec: this.camera.preferredCodec,
                });
            }
            // Start camera if backend config specifies, and there is no local setting
            if (this.camera.state.status === undefined &&
                this.state.settings?.video.camera_default_on) {
                await this.camera.enable();
            }
        }
    }
    async initMic(options) {
        // Wait for any in progress mic operation
        await this.microphone.statusChangePromise;
        if (this.state.localParticipant?.audioStream ||
            !this.permissionsContext.hasPermission('send-audio')) {
            return;
        }
        if (options.setStatus) {
            // Publish media stream that was set before we joined
            if (this.microphone.state.status === 'enabled' &&
                this.microphone.state.mediaStream &&
                !this.publisher?.isPublishing(TrackType.AUDIO)) {
                await this.publishAudioStream(this.microphone.state.mediaStream);
            }
            // Start mic if backend config specifies, and there is no local setting
            if (this.microphone.state.status === undefined &&
                this.state.settings?.audio.mic_default_on) {
                await this.microphone.enable();
            }
        }
    }
}

class InsightMetrics {
    constructor() {
        this.connectionStartTimestamp = null;
        this.wsTotalFailures = 0;
        this.wsConsecutiveFailures = 0;
        this.instanceClientId = randomId();
    }
}
/**
 * postInsights is not supposed to be used by end users directly within chat application, and thus is kept isolated
 * from all the client/connection code/logic.
 *
 * @param insightType
 * @param insights
 */
const postInsights = async (insightType, insights) => {
    const maxAttempts = 3;
    for (let i = 0; i < maxAttempts; i++) {
        try {
            await axios.post(`https://chat-insights.getstream.io/insights/${insightType}`, insights);
        }
        catch (e) {
            await sleep((i + 1) * 3000);
            continue;
        }
        break;
    }
};
function buildWsFatalInsight(connection, event) {
    return {
        ...event,
        ...buildWsBaseInsight(connection),
    };
}
function buildWsBaseInsight(connection) {
    const { client } = connection;
    return {
        ready_state: connection.ws?.readyState,
        url: connection._buildUrl(),
        api_key: client.key,
        start_ts: client.insightMetrics.connectionStartTimestamp,
        end_ts: new Date().getTime(),
        auth_type: client.getAuthType(),
        token: client.tokenManager.token,
        user_id: client.userID,
        user_details: client._user,
        // device: client.options.device,
        device: 'browser',
        client_id: connection.connectionID,
        ws_details: connection.ws,
        ws_consecutive_failures: client.insightMetrics.wsConsecutiveFailures,
        ws_total_failures: client.insightMetrics.wsTotalFailures,
        request_id: connection.requestID,
        online: typeof navigator !== 'undefined' ? navigator?.onLine : null,
        user_agent: typeof navigator !== 'undefined' ? navigator?.userAgent : null,
        instance_client_id: client.insightMetrics.instanceClientId,
    };
}
function buildWsSuccessAfterFailureInsight(connection) {
    return buildWsBaseInsight(connection);
}

// Type guards to check WebSocket error type
const isCloseEvent = (res) => res.code !== undefined;
const isErrorEvent = (res) => res.error !== undefined;
/**
 * StableWSConnection - A WS connection that reconnects upon failure.
 * - the browser will sometimes report that you're online or offline
 * - the WS connection can break and fail (there is a 30s health check)
 * - sometimes your WS connection will seem to work while the user is in fact offline
 * - to speed up online/offline detection you can use the window.addEventListener('offline');
 *
 * There are 4 ways in which a connection can become unhealthy:
 * - websocket.onerror is called
 * - websocket.onclose is called
 * - the health check fails and no event is received for ~40 seconds
 * - the browser indicates the connection is now offline
 *
 * There are 2 assumptions we make about the server:
 * - state can be recovered by querying the channel again
 * - if the servers fails to publish a message to the client, the WS connection is destroyed
 */
class StableWSConnection {
    constructor(client) {
        this._log = (msg, extra = {}, level = 'info') => {
            this.client.logger(level, 'connection:' + msg, {
                ...extra,
            });
        };
        this.setClient = (client) => {
            this.client = client;
        };
        /**
         * Builds and returns the url for websocket.
         * @private
         * @returns url string
         */
        this._buildUrl = () => {
            const params = new URLSearchParams();
            // const qs = encodeURIComponent(this.client._buildWSPayload(this.requestID));
            // params.set('json', qs);
            params.set('api_key', this.client.key);
            params.set('stream-auth-type', this.client.getAuthType());
            params.set('X-Stream-Client', this.client.getUserAgent());
            // params.append('authorization', this.client._getToken()!);
            return `${this.client.wsBaseURL}/connect?${params.toString()}`;
        };
        /**
         * onlineStatusChanged - this function is called when the browser connects or disconnects from the internet.
         *
         * @param {Event} event Event with type online or offline
         *
         */
        this.onlineStatusChanged = (event) => {
            if (event.type === 'offline') {
                // mark the connection as down
                this._log('onlineStatusChanged() - Status changing to offline');
                // we know that the app is offline so dispatch the unhealthy connection event immediately
                this._setHealth(false, true);
            }
            else if (event.type === 'online') {
                // retry right now...
                // We check this.isHealthy, not sure if it's always
                // smart to create a new WS connection if the old one is still up and running.
                // it's possible we didn't miss any messages, so this process is just expensive and not needed.
                this._log(`onlineStatusChanged() - Status changing to online. isHealthy: ${this.isHealthy}`);
                if (!this.isHealthy) {
                    this._reconnect({ interval: 10 });
                }
            }
        };
        this.onopen = (wsID) => {
            if (this.wsID !== wsID)
                return;
            const user = this.client.user;
            if (!user) {
                this.client.logger('error', `User not set, can't connect to WS`);
                return;
            }
            const token = this.client._getToken();
            if (!token) {
                this.client.logger('error', `Token not set, can't connect authenticate`);
                return;
            }
            const authMessage = {
                token,
                user_details: {
                    id: user.id,
                    name: user.name,
                    image: user.image,
                    custom: user.custom,
                },
            };
            this.authenticationSent = true;
            this.ws?.send(JSON.stringify(authMessage));
            this._log('onopen() - onopen callback', { wsID });
        };
        this.onmessage = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this._log('onmessage() - onmessage callback', { event, wsID });
            const data = typeof event.data === 'string'
                ? JSON.parse(event.data)
                : null;
            // we wait till the first message before we consider the connection open.
            // the reason for this is that auth errors and similar errors trigger a ws.onopen and immediately
            // after that a ws.onclose.
            if (!this.isResolved && data && data.type === 'connection.error') {
                this.isResolved = true;
                if (data.error) {
                    // @ts-expect-error - the types of _errorFromWSEvent are incorrect
                    this.rejectPromise?.(this._errorFromWSEvent(data, false));
                    return;
                }
            }
            // trigger the event..
            this.lastEvent = new Date();
            if (data &&
                (data.type === 'health.check' || data.type === 'connection.ok')) {
                // the initial health-check should come from the client
                this.scheduleNextPing();
            }
            if (data && data.type === 'connection.ok') {
                this.resolvePromise?.(data);
                this._setHealth(true);
            }
            if (data && data.type === 'connection.error' && data.error) {
                const { code } = data.error;
                this.isHealthy = false;
                this.isConnecting = false;
                this.consecutiveFailures += 1;
                if (code === KnownCodes.TOKEN_EXPIRED &&
                    !this.client.tokenManager.isStatic()) {
                    clearTimeout(this.connectionCheckTimeoutRef);
                    this._log('connect() - WS failure due to expired token, so going to try to reload token and reconnect');
                    this._reconnect({ refreshToken: true });
                }
            }
            if (data) {
                this.client.dispatchEvent(data);
            }
            this.scheduleConnectionCheck();
        };
        this.onclose = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this._log('onclose() - onclose callback - ' + event.code, { event, wsID });
            if (event.code === KnownCodes.WS_CLOSED_SUCCESS) {
                // this is a permanent error raised by stream..
                // usually caused by invalid auth details
                const error = new Error(`WS connection reject with error ${event.reason}`);
                error.reason = event.reason;
                error.code = event.code;
                error.wasClean = event.wasClean;
                error.target = event.target;
                this.rejectPromise?.(error);
                this._log(`onclose() - WS connection reject with error ${event.reason}`, {
                    event,
                });
            }
            else {
                this.consecutiveFailures += 1;
                this.totalFailures += 1;
                this._setHealth(false);
                this.isConnecting = false;
                this.rejectPromise?.(this._errorFromWSEvent(event));
                this._log(`onclose() - WS connection closed. Calling reconnect ...`, {
                    event,
                });
                // reconnect if its an abnormal failure
                this._reconnect();
            }
        };
        this.onerror = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this.consecutiveFailures += 1;
            this.totalFailures += 1;
            this._setHealth(false);
            this.isConnecting = false;
            this.rejectPromise?.(this._errorFromWSEvent(event));
            this._log(`onerror() - WS connection resulted into error`, { event });
            this._reconnect();
        };
        /**
         * _setHealth - Sets the connection to healthy or unhealthy.
         * Broadcasts an event in case the connection status changed.
         *
         * @param {boolean} healthy boolean indicating if the connection is healthy or not
         * @param {boolean} dispatchImmediately boolean indicating to dispatch event immediately even if the connection is unhealthy
         *
         */
        this._setHealth = (healthy, dispatchImmediately = false) => {
            if (healthy === this.isHealthy)
                return;
            this.isHealthy = healthy;
            if (this.isHealthy || dispatchImmediately) {
                this.client.dispatchEvent({
                    type: 'connection.changed',
                    online: this.isHealthy,
                });
                return;
            }
            // we're offline, wait few seconds and fire and event if still offline
            setTimeout(() => {
                if (this.isHealthy)
                    return;
                this.client.dispatchEvent({
                    type: 'connection.changed',
                    online: this.isHealthy,
                });
            }, 5000);
        };
        /**
         * _errorFromWSEvent - Creates an error object for the WS event
         *
         */
        this._errorFromWSEvent = (event, isWSFailure = true) => {
            let code;
            let statusCode;
            let message;
            if (isCloseEvent(event)) {
                code = event.code;
                statusCode = 'unknown';
                message = event.reason;
            }
            if (isErrorEvent(event)) {
                code = event.error.code;
                statusCode = event.error.StatusCode;
                message = event.error.message;
            }
            // Keeping this `warn` level log, to avoid cluttering of error logs from ws failures.
            this._log(`_errorFromWSEvent() - WS failed with code ${code}`, { event }, 'warn');
            const error = new Error(`WS failed with code ${code} and reason - ${message}`);
            error.code = code;
            /**
             * StatusCode does not exist on any event types but has been left
             * as is to preserve JS functionality during the TS implementation
             */
            error.StatusCode = statusCode;
            error.isWSFailure = isWSFailure;
            return error;
        };
        /**
         * _setupPromise - sets up the this.connectOpen promise
         */
        this._setupConnectionPromise = () => {
            this.isResolved = false;
            /** a promise that is resolved once ws.open is called */
            this.connectionOpen = new Promise((resolve, reject) => {
                this.resolvePromise = resolve;
                this.rejectPromise = reject;
            });
        };
        /**
         * Schedules a next health check ping for websocket.
         */
        this.scheduleNextPing = () => {
            if (this.healthCheckTimeoutRef) {
                clearTimeout(this.healthCheckTimeoutRef);
            }
            // 30 seconds is the recommended interval (messenger uses this)
            this.healthCheckTimeoutRef = setTimeout(() => {
                // send the healthcheck..., server replies with a health check event
                const data = [{ type: 'health.check', client_id: this.client.clientID }];
                // try to send on the connection
                try {
                    this.ws?.send(JSON.stringify(data));
                }
                catch (e) {
                    // error will already be detected elsewhere
                }
            }, this.pingInterval);
        };
        /**
         * scheduleConnectionCheck - schedules a check for time difference between last received event and now.
         * If the difference is more than 35 seconds, it means our health check logic has failed and websocket needs
         * to be reconnected.
         */
        this.scheduleConnectionCheck = () => {
            if (this.connectionCheckTimeoutRef) {
                clearTimeout(this.connectionCheckTimeoutRef);
            }
            this.connectionCheckTimeoutRef = setTimeout(() => {
                const now = new Date();
                if (this.lastEvent &&
                    now.getTime() - this.lastEvent.getTime() > this.connectionCheckTimeout) {
                    this._log('scheduleConnectionCheck - going to reconnect');
                    this._setHealth(false);
                    this._reconnect();
                }
            }, this.connectionCheckTimeout);
        };
        this.client = client;
        /** consecutive failures influence the duration of the timeout */
        this.consecutiveFailures = 0;
        /** keep track of the total number of failures */
        this.totalFailures = 0;
        /** We only make 1 attempt to reconnect at the same time.. */
        this.isConnecting = false;
        /** True after the auth payload is sent to the server */
        this.authenticationSent = false;
        /** To avoid reconnect if client is disconnected */
        this.isDisconnected = false;
        /** Boolean that indicates if the connection promise is resolved */
        this.isResolved = false;
        /** Boolean that indicates if we have a working connection to the server */
        this.isHealthy = false;
        /** Incremented when a new WS connection is made */
        this.wsID = 1;
        /** Store the last event time for health checks */
        this.lastEvent = null;
        /** Send a health check message every 25 seconds */
        this.pingInterval = 25 * 1000;
        this.connectionCheckTimeout = this.pingInterval + 10 * 1000;
        addConnectionEventListeners(this.onlineStatusChanged);
    }
    /**
     * connect - Connect to the WS URL
     * the default 15s timeout allows between 2~3 tries
     * @return {ConnectAPIResponse<ConnectedEvent>} Promise that completes once the first health check message is received
     */
    async connect(timeout = 15000) {
        if (this.isConnecting) {
            throw Error(`You've called connect twice, can only attempt 1 connection at the time`);
        }
        this.isDisconnected = false;
        try {
            const healthCheck = await this._connect();
            this.consecutiveFailures = 0;
            this._log(`connect() - Established ws connection with healthcheck: ${healthCheck}`);
        }
        catch (error) {
            this.isHealthy = false;
            this.consecutiveFailures += 1;
            if (
            // @ts-ignore
            error.code === KnownCodes.TOKEN_EXPIRED &&
                !this.client.tokenManager.isStatic()) {
                this._log('connect() - WS failure due to expired token, so going to try to reload token and reconnect');
                this._reconnect({ refreshToken: true });
            }
            else {
                // @ts-ignore
                if (!error.isWSFailure) {
                    // API rejected the connection and we should not retry
                    throw new Error(JSON.stringify({
                        // @ts-ignore
                        code: error.code,
                        // @ts-ignore
                        StatusCode: error.StatusCode,
                        // @ts-ignore
                        message: error.message,
                        // @ts-ignore
                        isWSFailure: error.isWSFailure,
                    }));
                }
            }
        }
        return await this._waitForHealthy(timeout);
    }
    /**
     * _waitForHealthy polls the promise connection to see if its resolved until it times out
     * the default 15s timeout allows between 2~3 tries
     * @param timeout duration(ms)
     */
    async _waitForHealthy(timeout = 15000) {
        return Promise.race([
            (async () => {
                const interval = 50; // ms
                for (let i = 0; i <= timeout; i += interval) {
                    try {
                        return await this.connectionOpen;
                    }
                    catch (error) {
                        if (i === timeout) {
                            throw new Error(JSON.stringify({
                                code: error.code,
                                StatusCode: error.StatusCode,
                                message: error.message,
                                isWSFailure: error.isWSFailure,
                            }));
                        }
                        await sleep(interval);
                    }
                }
            })(),
            (async () => {
                await sleep(timeout);
                this.isConnecting = false;
                throw new Error(JSON.stringify({
                    code: '',
                    StatusCode: '',
                    message: 'initial WS connection could not be established',
                    isWSFailure: true,
                }));
            })(),
        ]);
    }
    /**
     * disconnect - Disconnect the connection and doesn't recover...
     *
     */
    disconnect(timeout) {
        this._log(`disconnect() - Closing the websocket connection for wsID ${this.wsID}`);
        this.wsID += 1;
        this.isConnecting = false;
        this.isDisconnected = true;
        // start by removing all the listeners
        if (this.healthCheckTimeoutRef) {
            clearInterval(this.healthCheckTimeoutRef);
        }
        if (this.connectionCheckTimeoutRef) {
            clearInterval(this.connectionCheckTimeoutRef);
        }
        removeConnectionEventListeners(this.onlineStatusChanged);
        this.isHealthy = false;
        // remove ws handlers...
        if (this.ws && this.ws.removeAllListeners) {
            this.ws.removeAllListeners();
        }
        let isClosedPromise;
        // and finally close...
        // Assigning to local here because we will remove it from this before the
        // promise resolves.
        const { ws } = this;
        if (ws && ws.close && ws.readyState === ws.OPEN) {
            isClosedPromise = new Promise((resolve) => {
                const onclose = (event) => {
                    this._log(`disconnect() - resolving isClosedPromise ${event ? 'with' : 'without'} close frame`, { event });
                    resolve();
                };
                ws.onclose = onclose;
                // In case we don't receive close frame websocket server in time,
                // lets not wait for more than 1 second.
                setTimeout(onclose, timeout != null ? timeout : 1000);
            });
            this._log(`disconnect() - Manually closed connection by calling client.disconnect()`);
            ws.close(KnownCodes.WS_CLOSED_SUCCESS, 'Manually closed connection by calling client.disconnect()');
        }
        else {
            this._log(`disconnect() - ws connection doesn't exist or it is already closed.`);
            isClosedPromise = Promise.resolve();
        }
        delete this.ws;
        return isClosedPromise;
    }
    /**
     * _connect - Connect to the WS endpoint
     *
     * @return {ConnectAPIResponse<ConnectedEvent>} Promise that completes once the first health check message is received
     */
    async _connect() {
        if (this.isConnecting ||
            (this.isDisconnected && this.client.options.enableWSFallback))
            return; // simply ignore _connect if it's currently trying to connect
        this.isConnecting = true;
        this.requestID = randomId();
        this.client.insightMetrics.connectionStartTimestamp = new Date().getTime();
        let isTokenReady = false;
        try {
            this._log(`_connect() - waiting for token`);
            await this.client.tokenManager.tokenReady();
            isTokenReady = true;
        }
        catch (e) {
            // token provider has failed before, so try again
        }
        try {
            if (!isTokenReady) {
                this._log(`_connect() - tokenProvider failed before, so going to retry`);
                await this.client.tokenManager.loadToken();
            }
            this._setupConnectionPromise();
            const wsURL = this._buildUrl();
            this._log(`_connect() - Connecting to ${wsURL}`, {
                wsURL,
                requestID: this.requestID,
            });
            this.ws = new WebSocket(wsURL);
            this.ws.onopen = this.onopen.bind(this, this.wsID);
            this.ws.onclose = this.onclose.bind(this, this.wsID);
            this.ws.onerror = this.onerror.bind(this, this.wsID);
            this.ws.onmessage = this.onmessage.bind(this, this.wsID);
            const response = await this.connectionOpen;
            this.isConnecting = false;
            if (response) {
                this.connectionID = response.connection_id;
                this.client.resolveConnectionId?.(this.connectionID);
                if (this.client.insightMetrics.wsConsecutiveFailures > 0 &&
                    this.client.options.enableInsights) {
                    postInsights('ws_success_after_failure', buildWsSuccessAfterFailureInsight(this));
                    this.client.insightMetrics.wsConsecutiveFailures = 0;
                }
                return response;
            }
        }
        catch (err) {
            this.isConnecting = false;
            // @ts-ignore
            this._log(`_connect() - Error - `, err);
            if (this.client.options.enableInsights) {
                this.client.insightMetrics.wsConsecutiveFailures++;
                this.client.insightMetrics.wsTotalFailures++;
                const insights = buildWsFatalInsight(this, convertErrorToJson(err));
                postInsights?.('ws_fatal', insights);
            }
            this.client.rejectConnectionId?.();
            throw err;
        }
    }
    /**
     * _reconnect - Retry the connection to WS endpoint
     *
     * @param {{ interval?: number; refreshToken?: boolean }} options Following options are available
     *
     * - `interval`	{int}			number of ms that function should wait before reconnecting
     * - `refreshToken` {boolean}	reload/refresh user token be refreshed before attempting reconnection.
     */
    async _reconnect(options = {}) {
        this._log('_reconnect() - Initiating the reconnect');
        // only allow 1 connection at the time
        if (this.isConnecting || this.isHealthy) {
            this._log('_reconnect() - Abort (1) since already connecting or healthy');
            return;
        }
        // reconnect in case of on error or on close
        // also reconnect if the health check cycle fails
        let interval = options.interval;
        if (!interval) {
            interval = retryInterval(this.consecutiveFailures);
        }
        // reconnect, or try again after a little while...
        await sleep(interval);
        // Check once again if by some other call to _reconnect is active or connection is
        // already restored, then no need to proceed.
        if (this.isConnecting || this.isHealthy) {
            this._log('_reconnect() - Abort (2) since already connecting or healthy');
            return;
        }
        if (this.isDisconnected && this.client.options.enableWSFallback) {
            this._log('_reconnect() - Abort (3) since disconnect() is called');
            return;
        }
        this._log('_reconnect() - Destroying current WS connection');
        // cleanup the old connection
        this._destroyCurrentWSConnection();
        if (options.refreshToken) {
            await this.client.tokenManager.loadToken();
        }
        try {
            await this._connect();
            this._log('_reconnect() - Waiting for recoverCallBack');
            // await this.client.recoverState();
            this._log('_reconnect() - Finished recoverCallBack');
            this.consecutiveFailures = 0;
        }
        catch (error) {
            this.isHealthy = false;
            this.consecutiveFailures += 1;
            if (error.code === KnownCodes.TOKEN_EXPIRED &&
                !this.client.tokenManager.isStatic()) {
                this._log('_reconnect() - WS failure due to expired token, so going to try to reload token and reconnect');
                return this._reconnect({ refreshToken: true });
            }
            // reconnect on WS failures, don't reconnect if there is a code bug
            if (error.isWSFailure) {
                this._log('_reconnect() - WS failure, so going to try to reconnect');
                this._reconnect();
            }
        }
        this._log('_reconnect() - == END ==');
    }
    /**
     * _destroyCurrentWSConnection - Removes the current WS connection
     *
     */
    _destroyCurrentWSConnection() {
        // increment the ID, meaning we will ignore all messages from the old
        // ws connection from now on.
        this.wsID += 1;
        try {
            this?.ws?.removeAllListeners();
            this?.ws?.close();
        }
        catch (e) {
            // we don't care
        }
    }
}

function isString(arrayOrString) {
    return typeof arrayOrString === 'string';
}
function isMapStringCallback(arrayOrString, callback) {
    return !!callback && isString(arrayOrString);
}
function map(arrayOrString, callback) {
    const res = [];
    if (isString(arrayOrString) && isMapStringCallback(arrayOrString, callback)) {
        for (let k = 0, len = arrayOrString.length; k < len; k++) {
            if (arrayOrString.charAt(k)) {
                const kValue = arrayOrString.charAt(k);
                const mappedValue = callback(kValue, k, arrayOrString);
                res[k] = mappedValue;
            }
        }
    }
    else if (!isString(arrayOrString) &&
        !isMapStringCallback(arrayOrString, callback)) {
        for (let k = 0, len = arrayOrString.length; k < len; k++) {
            if (k in arrayOrString) {
                const kValue = arrayOrString[k];
                const mappedValue = callback(kValue, k, arrayOrString);
                res[k] = mappedValue;
            }
        }
    }
    return res;
}
const encodeBase64 = (data) => base64Js.fromByteArray(new Uint8Array(map(data, (char) => char.charCodeAt(0))));
// base-64 decoder throws exception if encoded string is not padded by '=' to make string length
// in multiples of 4. So gonna use our own method for this purpose to keep backwards compatibility
// https://github.com/beatgammit/base64-js/blob/master/index.js#L26
const decodeBase64 = (s) => {
    const e = {}, w = String.fromCharCode, L = s.length;
    let i, b = 0, c, x, l = 0, a, r = '';
    const A = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    for (i = 0; i < 64; i++) {
        e[A.charAt(i)] = i;
    }
    for (x = 0; x < L; x++) {
        c = e[s.charAt(x)];
        b = (b << 6) + c;
        l += 6;
        while (l >= 8) {
            ((a = (b >>> (l -= 8)) & 0xff) || x < L - 2) && (r += w(a));
        }
    }
    return r;
};

/**
 *
 * @param {string} userId the id of the user
 * @return {string}
 */
function DevToken(userId) {
    return [
        'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9', //{"alg": "HS256", "typ": "JWT"}
        encodeBase64(JSON.stringify({ user_id: userId })),
        'devtoken', // hardcoded signature
    ].join('.');
}
function UserFromToken(token) {
    const fragments = token.split('.');
    if (fragments.length !== 3) {
        return '';
    }
    const b64Payload = fragments[1];
    const payload = decodeBase64(b64Payload);
    const data = JSON.parse(payload);
    return data.user_id;
}

/**
 * TokenManager
 *
 * Handles all the operations around user token.
 */
class TokenManager {
    /**
     * Constructor
     *
     * @param {Secret} secret
     */
    constructor(secret) {
        /**
         * Set the static string token or token provider.
         * Token provider should return a token string or a promise which resolves to string token.
         *
         * @param {TokenOrProvider} tokenOrProvider - the token or token provider.
         * @param {UserResponse} user - the user object.
         * @param {boolean} isAnonymous - whether the user is anonymous or not.
         */
        this.setTokenOrProvider = async (tokenOrProvider, user, isAnonymous) => {
            this.validateToken(tokenOrProvider, user, isAnonymous);
            this.user = user;
            if (isFunction(tokenOrProvider)) {
                this.tokenProvider = tokenOrProvider;
                this.type = 'provider';
            }
            if (typeof tokenOrProvider === 'string') {
                this.token = tokenOrProvider;
                this.type = 'static';
            }
            await this.loadToken();
        };
        /**
         * Resets the token manager.
         * Useful for client disconnection or switching user.
         */
        this.reset = () => {
            this.token = undefined;
            this.user = undefined;
            this.loadTokenPromise = null;
        };
        // Validates the user token.
        this.validateToken = (tokenOrProvider, user, isAnonymous) => {
            // allow empty token for anon user
            if (user && isAnonymous && !tokenOrProvider)
                return;
            // Don't allow empty token for non-server side client.
            if (!this.secret && !tokenOrProvider) {
                throw new Error('UserWithId token can not be empty');
            }
            if (tokenOrProvider &&
                typeof tokenOrProvider !== 'string' &&
                !isFunction(tokenOrProvider)) {
                throw new Error('user token should either be a string or a function');
            }
            if (typeof tokenOrProvider === 'string') {
                // Allow empty token for anonymous users
                if (isAnonymous && tokenOrProvider === '')
                    return;
                const tokenUserId = UserFromToken(tokenOrProvider);
                if (tokenOrProvider != null &&
                    (tokenUserId == null ||
                        tokenUserId === '' ||
                        (!isAnonymous && tokenUserId !== user.id))) {
                    throw new Error('userToken does not have a user_id or is not matching with user.id');
                }
            }
        };
        // Resolves when token is ready. This function is simply to check if loadToken is in progress, in which
        // case a function should wait.
        this.tokenReady = () => this.loadTokenPromise;
        // Fetches a token from tokenProvider function and sets in tokenManager.
        // In case of static token, it will simply resolve to static token.
        this.loadToken = () => {
            // eslint-disable-next-line no-async-promise-executor
            this.loadTokenPromise = new Promise(async (resolve, reject) => {
                if (this.type === 'static') {
                    return resolve(this.token);
                }
                if (this.tokenProvider && typeof this.tokenProvider !== 'string') {
                    try {
                        this.token = await this.tokenProvider();
                    }
                    catch (e) {
                        return reject(new Error(`Call to tokenProvider failed with message: ${e}`));
                    }
                    resolve(this.token);
                }
            });
            return this.loadTokenPromise;
        };
        // Returns a current token
        this.getToken = () => {
            if (this.token) {
                return this.token;
            }
            if (this.user && !this.token) {
                return this.token;
            }
            throw new Error(`Both secret and user tokens are not set. Either client.connectUser wasn't called or client.disconnect was called`);
        };
        this.isStatic = () => this.type === 'static';
        this.loadTokenPromise = null;
        if (secret) {
            this.secret = secret;
        }
        this.type = 'static';
    }
}

const APIErrorCodes = {
    '-1': { name: 'InternalSystemError', retryable: true },
    '2': { name: 'AccessKeyError', retryable: false },
    '3': { name: 'AuthenticationFailedError', retryable: true },
    '4': { name: 'InputError', retryable: false },
    '6': { name: 'DuplicateUsernameError', retryable: false },
    '9': { name: 'RateLimitError', retryable: true },
    '16': { name: 'DoesNotExistError', retryable: false },
    '17': { name: 'NotAllowedError', retryable: false },
    '18': { name: 'EventNotSupportedError', retryable: false },
    '19': { name: 'ChannelFeatureNotSupportedError', retryable: false },
    '20': { name: 'MessageTooLongError', retryable: false },
    '21': { name: 'MultipleNestingLevelError', retryable: false },
    '22': { name: 'PayloadTooBigError', retryable: false },
    '23': { name: 'RequestTimeoutError', retryable: true },
    '24': { name: 'MaxHeaderSizeExceededError', retryable: false },
    '40': { name: 'AuthErrorTokenExpired', retryable: false },
    '41': { name: 'AuthErrorTokenNotValidYet', retryable: false },
    '42': { name: 'AuthErrorTokenUsedBeforeIssuedAt', retryable: false },
    '43': { name: 'AuthErrorTokenSignatureInvalid', retryable: false },
    '44': { name: 'CustomCommandEndpointMissingError', retryable: false },
    '45': { name: 'CustomCommandEndpointCallError', retryable: true },
    '46': { name: 'ConnectionIDNotFoundError', retryable: false },
    '60': { name: 'CoolDownError', retryable: true },
    '69': { name: 'ErrWrongRegion', retryable: false },
    '70': { name: 'ErrQueryChannelPermissions', retryable: false },
    '71': { name: 'ErrTooManyConnections', retryable: true },
    '99': { name: 'AppSuspendedError', retryable: false },
};
function isAPIError(error) {
    return error.code !== undefined;
}
function isErrorRetryable(error) {
    if (!error.code)
        return false;
    const err = APIErrorCodes[`${error.code}`];
    if (!err)
        return false;
    return err.retryable;
}
function isConnectionIDError(error) {
    return error.code === 46; // ConnectionIDNotFoundError
}
function isWSFailure(err) {
    if (typeof err.isWSFailure === 'boolean') {
        return err.isWSFailure;
    }
    try {
        return JSON.parse(err.message).isWSFailure;
    }
    catch (_) {
        return false;
    }
}
function isErrorResponse(res) {
    return !res.status || res.status < 200 || 300 <= res.status;
}

var ConnectionState;
(function (ConnectionState) {
    ConnectionState["Closed"] = "CLOSED";
    ConnectionState["Connected"] = "CONNECTED";
    ConnectionState["Connecting"] = "CONNECTING";
    ConnectionState["Disconnected"] = "DISCONNECTED";
    ConnectionState["Init"] = "INIT";
})(ConnectionState || (ConnectionState = {}));
class WSConnectionFallback {
    constructor(client) {
        /** @private */
        this._onlineStatusChanged = (event) => {
            this._log(`_onlineStatusChanged() - ${event.type}`);
            if (event.type === 'offline') {
                this._setState(ConnectionState.Closed);
                this.cancelToken?.cancel('disconnect() is called');
                this.cancelToken = undefined;
                return;
            }
            if (event.type === 'online' && this.state === ConnectionState.Closed) {
                this.connect(true);
            }
        };
        /** @private */
        this._req = async (params, config, retry) => {
            if (!this.cancelToken && !params.close) {
                this.cancelToken = axios.CancelToken.source();
            }
            try {
                const res = await this.client.doAxiosRequest('get', this.client.baseURL.replace(':3030', ':8900') + '/longpoll', // replace port if present for testing with local API
                undefined, {
                    config: { ...config, cancelToken: this.cancelToken?.token },
                    params,
                    publicEndpoint: true,
                });
                this.consecutiveFailures = 0; // always reset in case of no error
                return res;
            }
            catch (err) {
                this.consecutiveFailures += 1;
                // @ts-ignore
                if (retry && isErrorRetryable(err)) {
                    this._log(`_req() - Retryable error, retrying request`);
                    await sleep(retryInterval(this.consecutiveFailures));
                    return this._req(params, config, retry);
                }
                throw err;
            }
        };
        /** @private */
        this._poll = async () => {
            while (this.state === ConnectionState.Connected) {
                try {
                    const data = await this._req({}, {
                        timeout: 30000,
                    }, true); // 30s => API responds in 20s if there is no event
                    if (data.events?.length) {
                        for (let i = 0; i < data.events.length; i++) {
                            this.client.dispatchEvent(data.events[i]);
                        }
                    }
                }
                catch (err) {
                    if (axios.isCancel(err)) {
                        this._log(`_poll() - axios canceled request`);
                        return;
                    }
                    /** client.doAxiosRequest will take care of TOKEN_EXPIRED error */
                    // @ts-ignore
                    if (isConnectionIDError(err)) {
                        this._log(`_poll() - ConnectionID error, connecting without ID...`);
                        this._setState(ConnectionState.Disconnected);
                        this.connect(true);
                        return;
                    }
                    // @ts-ignore
                    if (isAPIError(err) && !isErrorRetryable(err)) {
                        this._setState(ConnectionState.Closed);
                        return;
                    }
                    await sleep(retryInterval(this.consecutiveFailures));
                }
            }
        };
        /**
         * connect try to open a longpoll request
         * @param reconnect should be false for first call and true for subsequent calls to keep the connection alive and call recoverState
         */
        this.connect = async (reconnect = false) => {
            if (this.state === ConnectionState.Connecting) {
                this._log('connect() - connecting already in progress', { reconnect }, 'warn');
                return;
            }
            if (this.state === ConnectionState.Connected) {
                this._log('connect() - already connected and polling', { reconnect }, 'warn');
                return;
            }
            this._setState(ConnectionState.Connecting);
            this.connectionID = undefined; // connect should be sent with empty connection_id so API creates one
            try {
                const { event } = await this._req({ json: this.client._buildWSPayload() }, {
                    timeout: 8000, // 8s
                }, reconnect);
                this._setState(ConnectionState.Connected);
                this.connectionID = event.connection_id;
                this.client.resolveConnectionId?.();
                // @ts-expect-error
                this.client.dispatchEvent(event);
                this._poll();
                return event;
            }
            catch (err) {
                this._setState(ConnectionState.Closed);
                this.client.rejectConnectionId?.();
                throw err;
            }
        };
        /**
         * isHealthy checks if there is a connectionID and connection is in Connected state
         */
        this.isHealthy = () => {
            return !!this.connectionID && this.state === ConnectionState.Connected;
        };
        this.disconnect = async (timeout = 2000) => {
            removeConnectionEventListeners(this._onlineStatusChanged);
            this._setState(ConnectionState.Disconnected);
            this.cancelToken?.cancel('disconnect() is called');
            this.cancelToken = undefined;
            const connection_id = this.connectionID;
            this.connectionID = undefined;
            try {
                await this._req({ close: true, connection_id }, {
                    timeout,
                }, false);
                this._log(`disconnect() - Closed connectionID`);
            }
            catch (err) {
                this._log(`disconnect() - Failed`, { err }, 'error');
            }
        };
        this.client = client;
        this.state = ConnectionState.Init;
        this.consecutiveFailures = 0;
        addConnectionEventListeners(this._onlineStatusChanged);
    }
    _log(msg, extra = {}, level = 'info') {
        this.client.logger(level, 'WSConnectionFallback:' + msg, {
            ...extra,
        });
    }
    _setState(state) {
        this._log(`_setState() - ${state}`);
        // transition from connecting => connected
        if (this.state === ConnectionState.Connecting &&
            state === ConnectionState.Connected) {
            this.client.dispatchEvent({ type: 'connection.changed', online: true });
        }
        if (state === ConnectionState.Closed ||
            state === ConnectionState.Disconnected) {
            this.client.dispatchEvent({ type: 'connection.changed', online: false });
        }
        this.state = state;
    }
}

const logger = getLogger(['location']);
const HINT_URL = `https://hint.stream-io-video.com/`;
const getLocationHint = async (hintUrl = HINT_URL, timeout = 2000) => {
    const abortController = new AbortController();
    const timeoutId = setTimeout(() => abortController.abort(), timeout);
    try {
        const response = await fetch(hintUrl, {
            method: 'HEAD',
            signal: abortController.signal,
        });
        const awsPop = response.headers.get('x-amz-cf-pop') || 'ERR';
        logger('debug', `Location header: ${awsPop}`);
        return awsPop.substring(0, 3); // AMS1-P2 -> AMS
    }
    catch (e) {
        logger('warn', `Failed to get location hint from ${hintUrl}`, e);
        return 'ERR';
    }
    finally {
        clearTimeout(timeoutId);
    }
};

class StreamClient {
    /**
     * Initialize a client.
     *
     * @param {string} key - the api key
     * @param {StreamClientOptions} [options] - additional options, here you can pass custom options to axios instance
     * @param {string} [options.secret] - the api secret
     * @param {boolean} [options.browser] - enforce the client to be in browser mode
     * @param {boolean} [options.warmUp] - default to false, if true, client will open a connection as soon as possible to speed up following requests
     * @param {Logger} [options.Logger] - custom logger
     * @param {number} [options.timeout] - default to 3000
     * @param {httpsAgent} [options.httpsAgent] - custom httpsAgent, in node it's default to https.agent()
     */
    constructor(key, options) {
        this.listeners = {};
        this.nextRequestAbortController = null;
        this.devToken = (userID) => {
            return DevToken(userID);
        };
        this.getAuthType = () => {
            return this.anonymous ? 'anonymous' : 'jwt';
        };
        this.setBaseURL = (baseURL) => {
            this.baseURL = baseURL;
            this.wsBaseURL = this.baseURL
                .replace('http', 'ws')
                .replace(':3030', ':8800');
        };
        this.getLocationHint = async (hintUrl, timeout) => {
            const hint = await this.locationHint;
            if (!hint || hint === 'ERR') {
                this.locationHint = getLocationHint(hintUrl ?? this.options.locationHintUrl, timeout ?? this.options.locationHintTimeout);
                return this.locationHint;
            }
            return hint;
        };
        this._getConnectionID = () => this.wsConnection?.connectionID || this.wsFallback?.connectionID;
        this._hasConnectionID = () => Boolean(this._getConnectionID());
        /**
         * connectUser - Set the current user and open a WebSocket connection
         *
         * @param user Data about this user. IE {name: "john"}
         * @param {TokenOrProvider} userTokenOrProvider Token or provider
         *
         * @return {ConnectAPIResponse} Returns a promise that resolves when the connection is setup
         */
        this.connectUser = async (user, userTokenOrProvider) => {
            if (!user.id) {
                throw new Error('The "id" field on the user is missing');
            }
            /**
             * Calling connectUser multiple times is potentially the result of a  bad integration, however,
             * If the user id remains the same we don't throw error
             */
            if (this.userID === user.id && this.setUserPromise) {
                this.logger('warn', 'Consecutive calls to connectUser is detected, ideally you should only call this function once in your app.');
                return this.setUserPromise;
            }
            if (this.userID) {
                throw new Error('Use client.disconnect() before trying to connect as a different user. connectUser was called twice.');
            }
            if ((this._isUsingServerAuth() || this.node) &&
                !this.options.allowServerSideConnect) {
                this.logger('warn', 'Please do not use connectUser server side. connectUser impacts MAU and concurrent connection usage and thus your bill. If you have a valid use-case, add "allowServerSideConnect: true" to the client options to disable this warning.');
            }
            // we generate the client id client side
            this.userID = user.id;
            this.anonymous = false;
            const setTokenPromise = this._setToken(user, userTokenOrProvider, this.anonymous);
            this._setUser(user);
            const wsPromise = this.openConnection();
            this.setUserPromise = Promise.all([setTokenPromise, wsPromise]).then((result) => result[1]);
            try {
                return await this.setUserPromise;
            }
            catch (err) {
                if (this.persistUserOnConnectionFailure) {
                    // cleanup client to allow the user to retry connectUser again
                    this.closeConnection();
                }
                else {
                    this.disconnectUser();
                }
                throw err;
            }
        };
        this._setToken = (user, userTokenOrProvider, isAnonymous) => this.tokenManager.setTokenOrProvider(userTokenOrProvider, user, isAnonymous);
        this._setUser = (user) => {
            /**
             * This one is used by the frontend. This is a copy of the current user object stored on backend.
             * It contains reserved properties and own user properties which are not present in `this._user`.
             */
            this.user = user;
            this.userID = user.id;
            // this one is actually used for requests. This is a copy of current user provided to `connectUser` function.
            this._user = { ...user };
        };
        /**
         * Disconnects the websocket connection, without removing the user set on client.
         * client.closeConnection will not trigger default auto-retry mechanism for reconnection. You need
         * to call client.openConnection to reconnect to websocket.
         *
         * This is mainly useful on mobile side. You can only receive push notifications
         * if you don't have active websocket connection.
         * So when your app goes to background, you can call `client.closeConnection`.
         * And when app comes back to foreground, call `client.openConnection`.
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming succesful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.closeConnection = async (timeout) => {
            if (this.cleaningIntervalRef != null) {
                clearInterval(this.cleaningIntervalRef);
                this.cleaningIntervalRef = undefined;
            }
            await Promise.all([
                this.wsConnection?.disconnect(timeout),
                this.wsFallback?.disconnect(timeout),
            ]);
            return Promise.resolve();
        };
        /**
         * Creates a new WebSocket connection with the current user. Returns empty promise, if there is an active connection
         */
        this.openConnection = async () => {
            if (!this.userID) {
                throw Error('UserWithId is not set on client, use client.connectUser or client.connectAnonymousUser instead');
            }
            if (this.wsConnection?.isConnecting && this.wsPromise) {
                this.logger('info', 'client:openConnection() - connection already in progress');
                return this.wsPromise;
            }
            if ((this.wsConnection?.isHealthy || this.wsFallback?.isHealthy()) &&
                this._hasConnectionID()) {
                this.logger('info', 'client:openConnection() - openConnection called twice, healthy connection already exists');
                return Promise.resolve();
            }
            this.connectionIdPromise = new Promise((resolve, reject) => {
                this.resolveConnectionId = resolve;
                this.rejectConnectionId = reject;
            });
            this.clientID = `${this.userID}--${randomId()}`;
            this.wsPromise = this.connect();
            return this.wsPromise;
        };
        this._normalizeDate = (before) => {
            if (before instanceof Date) {
                before = before.toISOString();
            }
            if (before === '') {
                throw new Error("Don't pass blank string for since, use null instead if resetting the token revoke");
            }
            return before;
        };
        /**
         * Disconnects the websocket and removes the user from client.
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming successful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.disconnectUser = async (timeout) => {
            this.logger('info', 'client:disconnect() - Disconnecting the client');
            // remove the user specific fields
            delete this.user;
            delete this._user;
            delete this.userID;
            this.anonymous = false;
            await this.closeConnection(timeout);
            this.tokenManager.reset();
            this.connectionIdPromise = undefined;
            this.rejectConnectionId = undefined;
            this.resolveConnectionId = undefined;
        };
        this.connectGuestUser = async (user) => {
            this.guestUserCreatePromise = this.doAxiosRequest('post', '/guest', {
                user: {
                    ...user,
                },
            }, { publicEndpoint: true });
            const response = await this.guestUserCreatePromise;
            this.guestUserCreatePromise.finally(() => (this.guestUserCreatePromise = undefined));
            return this.connectUser(response.user, response.access_token);
        };
        /**
         * connectAnonymousUser - Set an anonymous user and open a WebSocket connection
         */
        this.connectAnonymousUser = async (user, tokenOrProvider) => {
            this.connectionIdPromise = new Promise((resolve, reject) => {
                this.resolveConnectionId = resolve;
                this.rejectConnectionId = reject;
            });
            this.anonymous = true;
            await this._setToken(user, tokenOrProvider, this.anonymous);
            this._setUser(user);
            // some endpoints require a connection_id to be resolved.
            // as anonymous users aren't allowed to open WS connections, we just
            // resolve the connection_id here.
            this.resolveConnectionId?.();
        };
        /**
         * on - Listen to events on all channels and users your watching
         *
         * client.on('message.new', event => {console.log("my new message", event, channel.state.messages)})
         *
         * @param eventName The event type to listen for (optional)
         * @param callback The callback to call
         *
         * @return  Returns a function which, when called, unsubscribes the event handler.
         */
        this.on = (eventName, callback) => {
            if (!this.listeners[eventName]) {
                this.listeners[eventName] = [];
            }
            this.logger('debug', `Adding listener for ${eventName} event`);
            this.listeners[eventName]?.push(callback);
            return () => {
                this.off(eventName, callback);
            };
        };
        /**
         * off - Remove the event handler
         */
        this.off = (eventName, callback) => {
            if (!this.listeners[eventName]) {
                this.listeners[eventName] = [];
            }
            this.logger('debug', `Removing listener for ${eventName} event`);
            this.listeners[eventName] = this.listeners[eventName]?.filter((value) => value !== callback);
        };
        this._logApiRequest = (type, url, data, config) => {
            this.logger('trace', `client: ${type} - Request - ${url}`, {
                payload: data,
                config,
            });
        };
        this._logApiResponse = (type, url, response) => {
            this.logger('trace', `client:${type} - Response - url: ${url} > status ${response.status}`, {
                response,
            });
        };
        this._logApiError = (type, url, error) => {
            this.logger('error', `client:${type} - Error - url: ${url}`, {
                url,
                error,
            });
        };
        this.doAxiosRequest = async (type, url, data, options = {}) => {
            if (!options.publicEndpoint) {
                await Promise.all([
                    this.tokenManager.tokenReady(),
                    this.guestUserCreatePromise,
                    this.connectionIdPromise,
                ]);
            }
            const requestConfig = this._enrichAxiosOptions(options);
            try {
                let response;
                this._logApiRequest(type, url, data, requestConfig);
                switch (type) {
                    case 'get':
                        response = await this.axiosInstance.get(url, requestConfig);
                        break;
                    case 'delete':
                        response = await this.axiosInstance.delete(url, requestConfig);
                        break;
                    case 'post':
                        response = await this.axiosInstance.post(url, data, requestConfig);
                        break;
                    case 'put':
                        response = await this.axiosInstance.put(url, data, requestConfig);
                        break;
                    case 'patch':
                        response = await this.axiosInstance.patch(url, data, requestConfig);
                        break;
                    case 'options':
                        response = await this.axiosInstance.options(url, requestConfig);
                        break;
                    default:
                        throw new Error('Invalid request type');
                }
                this._logApiResponse(type, url, response);
                this.consecutiveFailures = 0;
                return this.handleResponse(response);
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
            }
            catch (e /**TODO: generalize error types  */) {
                e.client_request_id = requestConfig.headers?.['x-client-request-id'];
                this.consecutiveFailures += 1;
                if (e.response) {
                    this._logApiError(type, url, e.response);
                    /** connection_fallback depends on this token expiration logic */
                    if (e.response.data.code === KnownCodes.TOKEN_EXPIRED &&
                        !this.tokenManager.isStatic()) {
                        if (this.consecutiveFailures > 1) {
                            await sleep(retryInterval(this.consecutiveFailures));
                        }
                        await this.tokenManager.loadToken();
                        return await this.doAxiosRequest(type, url, data, options);
                    }
                    return this.handleResponse(e.response);
                }
                else {
                    this._logApiError(type, url, e);
                    // eslint-disable-next-line no-throw-literal
                    throw e;
                }
            }
        };
        this.get = (url, params) => {
            return this.doAxiosRequest('get', url, null, {
                params,
            });
        };
        this.put = (url, data, params) => {
            return this.doAxiosRequest('put', url, data, { params });
        };
        this.post = (url, data, params) => {
            return this.doAxiosRequest('post', url, data, { params });
        };
        this.patch = (url, data, params) => {
            return this.doAxiosRequest('patch', url, data, { params });
        };
        this.delete = (url, params) => {
            return this.doAxiosRequest('delete', url, null, {
                params,
            });
        };
        this.errorFromResponse = (response) => {
            let err;
            err = new ErrorFromResponse(`Stream error HTTP code: ${response.status}`);
            if (response.data && response.data.code) {
                err = new Error(`Stream error code ${response.data.code}: ${response.data.message}`);
                err.code = response.data.code;
            }
            err.response = response;
            err.status = response.status;
            return err;
        };
        this.handleResponse = (response) => {
            const data = response.data;
            if (isErrorResponse(response)) {
                throw this.errorFromResponse(response);
            }
            return data;
        };
        this.dispatchEvent = (event) => {
            if (!event.received_at)
                event.received_at = new Date();
            this.logger('debug', `Dispatching event: ${event.type}`, event);
            if (!this.listeners)
                return;
            // call generic listeners
            for (const listener of this.listeners.all || []) {
                listener(event);
            }
            // call type specific listeners
            for (const listener of this.listeners[event.type] || []) {
                listener(event);
            }
        };
        /**
         * @private
         */
        this.connect = async () => {
            if (!this.userID || !this._user) {
                throw Error('Call connectUser or connectAnonymousUser before starting the connection');
            }
            if (!this.wsBaseURL) {
                throw Error('Websocket base url not set');
            }
            if (!this.clientID) {
                throw Error('clientID is not set');
            }
            if (!this.wsConnection &&
                (this.options.warmUp || this.options.enableInsights)) {
                this._sayHi();
            }
            // The StableWSConnection handles all the reconnection logic.
            if (this.options.wsConnection && this.node) {
                // Intentionally avoiding adding ts generics on wsConnection in options since its only useful for unit test purpose.
                this.options.wsConnection.setClient(this);
                this.wsConnection = this.options
                    .wsConnection;
            }
            else {
                this.wsConnection = new StableWSConnection(this);
            }
            try {
                // if fallback is used before, continue using it instead of waiting for WS to fail
                if (this.wsFallback) {
                    return await this.wsFallback.connect();
                }
                this.logger('info', 'StreamClient.connect: this.wsConnection.connect()');
                // if WSFallback is enabled, ws connect should timeout faster so fallback can try
                return await this.wsConnection.connect(this.options.enableWSFallback
                    ? this.defaultWSTimeoutWithFallback
                    : this.defaultWSTimeout);
            }
            catch (err) {
                // run fallback only if it's WS/Network error and not a normal API error
                // make sure browser is online before even trying the longpoll
                if (this.options.enableWSFallback &&
                    // @ts-ignore
                    isWSFailure(err) &&
                    isOnline(this.logger)) {
                    this.logger('warn', 'client:connect() - WS failed, fallback to longpoll');
                    this.dispatchEvent({ type: 'transport.changed', mode: 'longpoll' });
                    this.wsConnection._destroyCurrentWSConnection();
                    this.wsConnection.disconnect().then(); // close WS so no retry
                    this.wsFallback = new WSConnectionFallback(this);
                    return await this.wsFallback.connect();
                }
                throw err;
            }
        };
        /**
         * Check the connectivity with server for warmup purpose.
         *
         * @private
         */
        this._sayHi = () => {
            const client_request_id = randomId();
            const opts = {
                headers: axios.AxiosHeaders.from({
                    'x-client-request-id': client_request_id,
                }),
            };
            this.doAxiosRequest('get', this.baseURL + '/hi', null, opts).catch((e) => {
                if (this.options.enableInsights) {
                    postInsights('http_hi_failed', {
                        api_key: this.key,
                        err: e,
                        client_request_id,
                    });
                }
            });
        };
        this.getUserAgent = () => {
            const version = "1.0.6" ;
            return (this.userAgent ||
                `stream-video-javascript-client-${this.node ? 'node' : 'browser'}-${version}`);
        };
        this.setUserAgent = (userAgent) => {
            this.userAgent = userAgent;
        };
        /**
         * _isUsingServerAuth - Returns true if we're using server side auth
         */
        this._isUsingServerAuth = () => !!this.secret;
        this._enrichAxiosOptions = (options = {
            params: {},
            headers: {},
            config: {},
        }) => {
            const token = options.publicEndpoint && !this.user ? undefined : this._getToken();
            const authorization = token ? { Authorization: token } : undefined;
            let signal = null;
            if (this.nextRequestAbortController !== null) {
                signal = this.nextRequestAbortController.signal;
                this.nextRequestAbortController = null;
            }
            if (!options.headers?.['x-client-request-id']) {
                options.headers = {
                    ...options.headers,
                    'x-client-request-id': randomId(),
                };
            }
            return {
                params: {
                    user_id: this.userID,
                    connection_id: this._getConnectionID(),
                    api_key: this.key,
                    ...options.params,
                },
                headers: {
                    ...authorization,
                    'stream-auth-type': options.publicEndpoint && !this.user
                        ? 'anonymous'
                        : this.getAuthType(),
                    'X-Stream-Client': this.getUserAgent(),
                    ...options.headers,
                },
                ...(signal ? { signal } : {}),
                ...options.config,
                ...this.options.axiosRequestConfig,
            };
        };
        this._getToken = () => {
            if (!this.tokenManager)
                return null;
            return this.tokenManager.getToken();
        };
        /**
         * encode ws url payload
         * @private
         * @returns json string
         */
        this._buildWSPayload = (client_request_id) => {
            return JSON.stringify({
                user_id: this.userID,
                user_details: this._user,
                client_request_id,
            });
        };
        /**
         * creates an abort controller that will be used by the next HTTP Request.
         */
        this.createAbortControllerForNextRequest = () => {
            return (this.nextRequestAbortController = new AbortController());
        };
        // set the key
        this.key = key;
        // set the secret
        this.secret = options?.secret;
        // set the options... and figure out defaults...
        const inputOptions = options
            ? options
            : {
                browser: typeof window !== 'undefined',
            };
        this.browser = inputOptions.browser || typeof window !== 'undefined';
        this.node = !this.browser;
        if (this.browser) {
            this.locationHint = getLocationHint(options?.locationHintUrl, options?.locationHintTimeout);
        }
        this.options = {
            timeout: 5000,
            withCredentials: false, // making sure cookies are not sent
            warmUp: false,
            ...inputOptions,
        };
        if (this.node && !this.options.httpsAgent) {
            this.options.httpsAgent = new https.Agent({
                keepAlive: true,
                keepAliveMsecs: 3000,
            });
        }
        this.setBaseURL(this.options.baseURL || 'https://video.stream-io-api.com/video');
        if (typeof process !== 'undefined' && process.env.STREAM_LOCAL_TEST_RUN) {
            this.setBaseURL('http://localhost:3030/video');
        }
        if (typeof process !== 'undefined' && process.env.STREAM_LOCAL_TEST_HOST) {
            this.setBaseURL(`http://${process.env.STREAM_LOCAL_TEST_HOST}/video`);
        }
        this.axiosInstance = axios.create({
            ...this.options,
            baseURL: this.baseURL,
        });
        // WS connection is initialized when setUser is called
        this.wsConnection = null;
        this.wsPromise = null;
        this.setUserPromise = null;
        // mapping between channel groups and configs
        this.anonymous = false;
        this.persistUserOnConnectionFailure =
            this.options?.persistUserOnConnectionFailure;
        // If it is a server-side client, then lets initialize the tokenManager, since token will be
        // generated from secret.
        this.tokenManager = new TokenManager(this.secret);
        this.consecutiveFailures = 0;
        this.insightMetrics = new InsightMetrics();
        this.defaultWSTimeoutWithFallback = 6000;
        this.defaultWSTimeout = 15000;
        this.logger = isFunction(inputOptions.logger)
            ? inputOptions.logger
            : () => null;
    }
}

/**
 * A `StreamVideoClient` instance lets you communicate with our API, and authenticate users.
 */
class StreamVideoClient {
    constructor(apiKeyOrArgs, opts) {
        this.logLevel = 'warn';
        this.eventHandlersToUnregister = [];
        /**
         * Disconnects the currently connected user from the client.
         *
         * If the connection is successfully disconnected, the connected user [state variable](#readonlystatestore) will be updated accordingly
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming successful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.disconnectUser = async (timeout) => {
            if (!this.streamClient.user && !this.connectionPromise) {
                return;
            }
            const disconnectUser = () => this.streamClient.disconnectUser(timeout);
            this.disconnectionPromise = this.connectionPromise
                ? this.connectionPromise.then(() => disconnectUser())
                : disconnectUser();
            this.disconnectionPromise.finally(() => (this.disconnectionPromise = undefined));
            await this.disconnectionPromise;
            this.eventHandlersToUnregister.forEach((unregister) => unregister());
            this.eventHandlersToUnregister = [];
            this.writeableStateStore.setConnectedUser(undefined);
        };
        /**
         * You can subscribe to WebSocket events provided by the API.
         * To remove a subscription, call the `off` method or, execute the returned unsubscribe function.
         * Please note that subscribing to WebSocket events is an advanced use-case, for most use-cases it should be enough to watch for changes in the reactive [state store](#readonlystatestore).
         *
         * @param eventName the event name or 'all'.
         * @param callback the callback which will be called when the event is emitted.
         * @returns an unsubscribe function.
         */
        this.on = (eventName, callback) => {
            return this.streamClient.on(eventName, callback);
        };
        /**
         * Remove subscription for WebSocket events that were created by the `on` method.
         *
         * @param eventName the event name.
         * @param callback the callback which was passed to the `on` method.
         */
        this.off = (eventName, callback) => {
            return this.streamClient.off(eventName, callback);
        };
        /**
         * Creates a new call.
         *
         * @param type the type of the call.
         * @param id the id of the call.
         */
        this.call = (type, id) => {
            return new Call({
                streamClient: this.streamClient,
                id: id,
                type: type,
                clientStore: this.writeableStateStore,
            });
        };
        /**
         * Creates a new guest user with the given data.
         *
         * @param data the data for the guest user.
         */
        this.createGuestUser = async (data) => {
            return this.streamClient.doAxiosRequest('post', '/guest', data, { publicEndpoint: true });
        };
        /**
         * Will query the API for calls matching the given filters.
         *
         * @param data the query data.
         */
        this.queryCalls = async (data = {}) => {
            const response = await this.streamClient.post('/calls', data);
            const calls = response.calls.map((c) => {
                const call = new Call({
                    streamClient: this.streamClient,
                    id: c.call.id,
                    type: c.call.type,
                    members: c.members,
                    ownCapabilities: c.own_capabilities,
                    watching: data.watch,
                    clientStore: this.writeableStateStore,
                });
                call.state.updateFromCallResponse(c.call);
                call.applyDeviceConfig();
                if (data.watch) {
                    this.writeableStateStore.registerCall(call);
                }
                return call;
            });
            return {
                ...response,
                calls: calls,
            };
        };
        /**
         * Retrieve the list of available call statistics reports matching a particular condition.
         *
         * @param data Filter and sort conditions for retrieving available call report summaries.
         * @returns List with summary of available call reports matching the condition.
         */
        this.queryCallStats = async (data = {}) => {
            return this.streamClient.post(`/call/stats`, data);
        };
        /**
         * Returns a list of available data centers available for hosting calls.
         */
        this.edges = async () => {
            return this.streamClient.get(`/edges`);
        };
        /**
         * addDevice - Adds a push device for a user.
         *
         * @param {string} id the device id
         * @param {string} push_provider the push provider name (eg. apn, firebase)
         * @param {string} push_provider_name user provided push provider name
         * @param {string} [userID] the user id (defaults to current user)
         * @param {boolean} [voip_token] enables use of VoIP token for push notifications on iOS platform
         */
        this.addDevice = async (id, push_provider, push_provider_name, userID, voip_token) => {
            return await this.streamClient.post('/devices', {
                id,
                push_provider,
                voip_token,
                ...(userID != null ? { user_id: userID } : {}),
                ...(push_provider_name != null ? { push_provider_name } : {}),
            });
        };
        /**
         * getDevices - Returns the devices associated with a current user
         * @param {string} [userID] User ID. Only works on serverside
         */
        this.getDevices = async (userID) => {
            return await this.streamClient.get('/devices', userID ? { user_id: userID } : {});
        };
        /**
         * removeDevice - Removes the device with the given id.
         *
         * @param {string} id The device id
         * @param {string} [userID] The user id. Only specify this for serverside requests
         */
        this.removeDevice = async (id, userID) => {
            return await this.streamClient.delete('/devices', {
                id,
                ...(userID ? { user_id: userID } : {}),
            });
        };
        /**
         * A callback that can be used to create ringing calls from push notifications. If the call already exists, it will do nothing.
         * @param call_cid
         * @returns
         */
        this.onRingingCall = async (call_cid) => {
            // if we find the call and is already ringing, we don't need to create a new call
            // as client would have received the call.ring state because the app had WS alive when receiving push notifications
            let call = this.readOnlyStateStore.calls.find((c) => c.cid === call_cid && c.ringing);
            if (!call) {
                // if not it means that WS is not alive when receiving the push notifications and we need to fetch the call
                const [callType, callId] = call_cid.split(':');
                call = new Call({
                    streamClient: this.streamClient,
                    type: callType,
                    id: callId,
                    clientStore: this.writeableStateStore,
                    ringing: true,
                });
                await call.get();
            }
            return call;
        };
        /**
         * Connects the given anonymous user to the client.
         *
         * @param user the user to connect.
         * @param tokenOrProvider a token or a function that returns a token.
         */
        this.connectAnonymousUser = async (user, tokenOrProvider) => {
            const connectAnonymousUser = () => this.streamClient.connectAnonymousUser(user, tokenOrProvider);
            this.connectionPromise = this.disconnectionPromise
                ? this.disconnectionPromise.then(() => connectAnonymousUser())
                : connectAnonymousUser();
            this.connectionPromise.finally(() => (this.connectionPromise = undefined));
            return this.connectionPromise;
        };
        let logger = logToConsole;
        let logLevel = 'warn';
        if (typeof apiKeyOrArgs === 'string') {
            logLevel = opts?.logLevel || logLevel;
            logger = opts?.logger || logger;
        }
        else {
            logLevel = apiKeyOrArgs.options?.logLevel || logLevel;
            logger = apiKeyOrArgs.options?.logger || logger;
        }
        setLogger(logger, logLevel);
        this.logger = getLogger(['client']);
        if (typeof apiKeyOrArgs === 'string') {
            this.streamClient = new StreamClient(apiKeyOrArgs, {
                persistUserOnConnectionFailure: true,
                ...opts,
                logLevel,
                logger: this.logger,
            });
        }
        else {
            this.streamClient = new StreamClient(apiKeyOrArgs.apiKey, {
                persistUserOnConnectionFailure: true,
                ...apiKeyOrArgs.options,
                logLevel,
                logger: this.logger,
            });
            const sdkInfo = getSdkInfo();
            if (sdkInfo) {
                this.streamClient.setUserAgent(this.streamClient.getUserAgent() +
                    `-video-${SdkType[sdkInfo.type].toLowerCase()}-sdk-${sdkInfo.major}.${sdkInfo.minor}.${sdkInfo.patch}`);
            }
        }
        this.writeableStateStore = new StreamVideoWriteableStateStore();
        this.readOnlyStateStore = new StreamVideoReadOnlyStateStore(this.writeableStateStore);
        if (typeof apiKeyOrArgs !== 'string') {
            const user = apiKeyOrArgs.user;
            const token = apiKeyOrArgs.token || apiKeyOrArgs.tokenProvider;
            if (user) {
                this.connectUser(user, token);
            }
        }
    }
    /**
     * Return the reactive state store, use this if you want to be notified about changes to the client state
     */
    get state() {
        return this.readOnlyStateStore;
    }
    /**
     * Connects the given user to the client.
     * Only one user can connect at a time, if you want to change users, call `disconnectUser` before connecting a new user.
     * If the connection is successful, the connected user [state variable](#readonlystatestore) will be updated accordingly.
     *
     * @param user the user to connect.
     * @param token a token or a function that returns a token.
     */
    async connectUser(user, token) {
        if (user.type === 'anonymous') {
            user.id = '!anon';
            return this.connectAnonymousUser(user, token);
        }
        let connectUser = () => {
            return this.streamClient.connectUser(user, token);
        };
        if (user.type === 'guest') {
            connectUser = async () => {
                return this.streamClient.connectGuestUser(user);
            };
        }
        this.connectionPromise = this.disconnectionPromise
            ? this.disconnectionPromise.then(() => connectUser())
            : connectUser();
        this.connectionPromise?.finally(() => (this.connectionPromise = undefined));
        const connectUserResponse = await this.connectionPromise;
        // connectUserResponse will be void if connectUser called twice for the same user
        if (connectUserResponse?.me) {
            this.writeableStateStore.setConnectedUser(connectUserResponse.me);
        }
        this.eventHandlersToUnregister.push(this.on('connection.changed', (event) => {
            if (event.online) {
                const callsToReWatch = this.writeableStateStore.calls
                    .filter((call) => call.watching)
                    .map((call) => call.cid);
                this.logger('info', `Rewatching calls after connection changed ${callsToReWatch.join(', ')}`);
                if (callsToReWatch.length > 0) {
                    this.queryCalls({
                        watch: true,
                        filter_conditions: {
                            cid: { $in: callsToReWatch },
                        },
                        sort: [{ field: 'cid', direction: 1 }],
                    }).catch((err) => {
                        this.logger('error', 'Failed to re-watch calls', err);
                    });
                }
            }
        }));
        this.eventHandlersToUnregister.push(this.on('call.created', (event) => {
            const { call, members } = event;
            if (user.id === call.created_by.id) {
                this.logger('warn', 'Received `call.created` sent by the current user');
                return;
            }
            this.logger('info', `New call created and registered: ${call.cid}`);
            const newCall = new Call({
                streamClient: this.streamClient,
                type: call.type,
                id: call.id,
                members,
                clientStore: this.writeableStateStore,
            });
            newCall.state.updateFromCallResponse(call);
            this.writeableStateStore.registerCall(newCall);
        }));
        this.eventHandlersToUnregister.push(this.on('call.ring', async (event) => {
            const { call, members } = event;
            if (user.id === call.created_by.id) {
                this.logger('debug', 'Received `call.ring` sent by the current user so ignoring the event');
                return;
            }
            // The call might already be tracked by the client,
            // if `call.created` was received before `call.ring`.
            // In that case, we cleanup the already tracked call.
            const prevCall = this.writeableStateStore.findCall(call.type, call.id);
            await prevCall?.leave({ reason: 'cleaning-up in call.ring' });
            // we create a new call
            const theCall = new Call({
                streamClient: this.streamClient,
                type: call.type,
                id: call.id,
                members,
                clientStore: this.writeableStateStore,
                ringing: true,
            });
            theCall.state.updateFromCallResponse(call);
            // we fetch the latest metadata for the call from the server
            await theCall.get();
            this.writeableStateStore.registerCall(theCall);
        }));
        return connectUserResponse;
    }
    /**
     * addDevice - Adds a push device for a user.
     *
     * @param {string} id the device id
     * @param {string} push_provider the push provider name (eg. apn, firebase)
     * @param {string} push_provider_name user provided push provider name
     * @param {string} [userID] the user id (defaults to current user)
     */
    async addVoipDevice(id, push_provider, push_provider_name, userID) {
        return await this.addDevice(id, push_provider, push_provider_name, userID, true);
    }
}

Object.defineProperty(exports, 'AxiosError', {
    enumerable: true,
    get: function () { return axios.AxiosError; }
});
exports.AudioSettingsDefaultDeviceEnum = AudioSettingsDefaultDeviceEnum;
exports.AudioSettingsRequestDefaultDeviceEnum = AudioSettingsRequestDefaultDeviceEnum;
exports.Browsers = browsers;
exports.Call = Call;
exports.CallState = CallState;
exports.CallType = CallType;
exports.CallTypes = CallTypes;
exports.CameraManager = CameraManager;
exports.CameraManagerState = CameraManagerState;
exports.CreateDeviceRequestPushProviderEnum = CreateDeviceRequestPushProviderEnum;
exports.DynascaleManager = DynascaleManager;
exports.ErrorFromResponse = ErrorFromResponse;
exports.InputMediaDeviceManager = InputMediaDeviceManager;
exports.InputMediaDeviceManagerState = InputMediaDeviceManagerState;
exports.MicrophoneManager = MicrophoneManager;
exports.MicrophoneManagerState = MicrophoneManagerState;
exports.NoiseCancellationSettingsModeEnum = NoiseCancellationSettingsModeEnum;
exports.NoiseCancellationSettingsRequestModeEnum = NoiseCancellationSettingsRequestModeEnum;
exports.OwnCapability = OwnCapability;
exports.RecordSettingsRequestModeEnum = RecordSettingsRequestModeEnum;
exports.RecordSettingsRequestQualityEnum = RecordSettingsRequestQualityEnum;
exports.RxUtils = rxUtils;
exports.ScreenShareManager = ScreenShareManager;
exports.ScreenShareState = ScreenShareState;
exports.SfuEvents = events;
exports.SfuModels = models;
exports.SpeakerManager = SpeakerManager;
exports.SpeakerState = SpeakerState;
exports.StreamSfuClient = StreamSfuClient;
exports.StreamVideoClient = StreamVideoClient;
exports.StreamVideoReadOnlyStateStore = StreamVideoReadOnlyStateStore;
exports.StreamVideoWriteableStateStore = StreamVideoWriteableStateStore;
exports.TranscriptionSettingsModeEnum = TranscriptionSettingsModeEnum;
exports.TranscriptionSettingsRequestModeEnum = TranscriptionSettingsRequestModeEnum;
exports.VideoSettingsCameraFacingEnum = VideoSettingsCameraFacingEnum;
exports.VideoSettingsRequestCameraFacingEnum = VideoSettingsRequestCameraFacingEnum;
exports.ViewportTracker = ViewportTracker;
exports.checkIfAudioOutputChangeSupported = checkIfAudioOutputChangeSupported;
exports.combineComparators = combineComparators;
exports.conditional = conditional;
exports.createSoundDetector = createSoundDetector;
exports.defaultSortPreset = defaultSortPreset;
exports.descending = descending;
exports.deviceIds$ = deviceIds$;
exports.disposeOfMediaStream = disposeOfMediaStream;
exports.dominantSpeaker = dominantSpeaker;
exports.getAudioDevices = getAudioDevices;
exports.getAudioOutputDevices = getAudioOutputDevices;
exports.getAudioStream = getAudioStream;
exports.getClientDetails = getClientDetails;
exports.getDeviceInfo = getDeviceInfo;
exports.getLogger = getLogger;
exports.getOSInfo = getOSInfo;
exports.getScreenShareStream = getScreenShareStream;
exports.getSdkInfo = getSdkInfo;
exports.getVideoDevices = getVideoDevices;
exports.getVideoStream = getVideoStream;
exports.getWebRTCInfo = getWebRTCInfo;
exports.hasAudio = hasAudio;
exports.hasScreenShare = hasScreenShare;
exports.hasScreenShareAudio = hasScreenShareAudio;
exports.hasVideo = hasVideo;
exports.isPinned = isPinned;
exports.livestreamOrAudioRoomSortPreset = livestreamOrAudioRoomSortPreset;
exports.logLevels = logLevels;
exports.logToConsole = logToConsole;
exports.name = name;
exports.noopComparator = noopComparator;
exports.paginatedLayoutSortPreset = paginatedLayoutSortPreset;
exports.pinned = pinned;
exports.publishingAudio = publishingAudio;
exports.publishingVideo = publishingVideo;
exports.reactionType = reactionType;
exports.role = role;
exports.screenSharing = screenSharing;
exports.setDeviceInfo = setDeviceInfo;
exports.setLogLevel = setLogLevel;
exports.setLogger = setLogger;
exports.setOSInfo = setOSInfo;
exports.setSdkInfo = setSdkInfo;
exports.setWebRTCInfo = setWebRTCInfo;
exports.speakerLayoutSortPreset = speakerLayoutSortPreset;
exports.speaking = speaking;
//# sourceMappingURL=index.cjs.js.map
